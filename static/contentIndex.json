{"00｜开篇词":{"title":"00｜开篇词","links":[],"tags":["Redis"],"content":"Redis 的两大维度，三大主线 §\n\nRedis 问题画像图 §\n"},"01｜基础架构：一个键值数据库包含什么？":{"title":"01｜基础架构：一个键值数据库包含什么？","links":[],"tags":["Redis"],"content":"\n\n操作模块\n\nPUT：新写入或更新一个 key-value 对，如 PUT hello world\nGET：根据 K 读取 V\nDELETE：根据 K 删除整个 KV 对\nSCAN：根据一段 key 的范围返回相应的 value 值\n\n\n\n访问模式\n\n通过函数库调用的方式供外部应用使用\n通过网络框架以 Socket 通信的形式对外提供键值对操作\n\n\n\nI/O 模型设计\n\n单线程、多线程、多进程\n\n\n\n索引模块\n\n让键值数据库根据 key 找到 value 的存储位置，进而执行操作\nMemcached 和 Redis 采用哈希表作为 key-value 索引\n内存的高性能随机访问特性和哈希表 O(1) 的操作复杂度相匹配\n\n\n\n存储模块\n\n\n分配器\n\n内存：读写快，掉电数据丢失\n外存：读写慢，数据持久化\n\n\n\n持久化\n\n\n对于每个键值对都进行落盘保存\n\n数据可靠\n性能差\n\n\n\n周期性把内存中的键值数据保存到文件\n\n数据可能丢失\n性能较好\n\n\n\n\n\n\n\n从 SimpleKV 到 Redis 的架构图转变\n\n\n\n\n\n从键值数据库开发和运维的辅助工具上做对比\n\n\n\n\n"},"01｜基础架构：一条-SQL-查询语句是如何执行的？":{"title":"01｜基础架构：一条 SQL 查询语句是如何执行的？","links":[],"tags":["MySQL"],"content":"MySQL 的逻辑链接架构图 §\n\n1. 客户端连接数据库 §\n\nwait_timeout 参数控制连接器长时间没操作自动断开的时间\n只有新建的连接才会使用新的权限设置\n尽量使用长连接\n\n使用长连接的问题：可能内存疯涨，因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面，在连接断开的时候才释放\n两个解决方案\n\n定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，主动断开连接，之后要查询再重连\nMySQL 5.7 或更新版本，可以在执行一个比较大的操作后，执行 mysql_reset_connection 重新初始化连接资源\n\n这个过程不需要重连和重新做权限验证，会将连接恢复到刚刚创建完时的状态\n\n\n\n\n\n\n\n2. 查询缓存 §\n\n建议不使用查询缓存，弊大于利\n\n对一个表的更新，表上所有的查询缓存都会被清空\n设置 query_cache_type = DEMAND，对于默认的 SQL 语句都不使用查询缓存，用 SQL_CACHE 显示置顶要使用查询缓存的语句 select SQL_CACHE * from T;\n\n\n⚠️ MySQL 8.0 版本删除此功能\n\n3. 分析器 §\n\n词法分析\n语法分析\n\n关注紧接“use near”的内容\n\n\n\n4. 优化器 §\n\n决定使用哪个索引\n决定各个表的连接顺序\n后面的文章会单独展开说明优化器的内容\n\n5. 执行器 §\n\n判断执行权限\n根据表的引擎定义，使用引擎提供的接口\n关于慢查询日志中的 rows_examined 字段\n\n执行器每次调用引擎获取数据行的时候累加\n跟引擎扫描行数并不是完全相同的\n\n可能执行器调用一次，引擎内部扫描了多行\n\n\n后面有实战文章单独展开讲存储引擎的内部机制\n\n\n\n思考题 §\n\n如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误：“Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？\n\n分析器\n\n\n"},"02｜数据结构：快速的-Redis-有哪些慢操作？":{"title":"02｜数据结构：快速的 Redis 有哪些慢操作？","links":[],"tags":["Redis"],"content":"\n\nRedis 数据类型和底层数据结构的对应关系\n\n\n\n\n\nRedis 使用一个哈希表 O(1) 保存所有键值对\n\n全局哈希表（数组）\n\n\n\n\n每个数组元素称为一个哈希桶（指针）\n每个哈希桶保存多个键值对数据\n计算键的哈希值就可以知道对应的哈希桶位置\n\n\n\n哈希冲突\n\n\n两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。\n\n\n解决方案：链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n\n\n当一个桶中的元素过多，访问时间变长时\n\n\n采用两个全局哈希表，当哈希表 1 不够大时 copy 到更大的哈希表 2\n\n\nrehash：增加现有哈希桶的数量\n\n\n装载因子的大小 = 所有 entry 个数除以哈希表的哈希桶个数\n\n\n&lt; 1 或者在进行 RDB 和 AOF 重写时禁止 rehash\n\n\n\n= 1，且允许进行 rehash 时会进行 rehash\n\n\n\n\n= 5，立马开始 rehash\n\n\n\n\n\n渐进式 rehash（实际）\n\n每次处理请求时，顺带拷贝一部分数据到另一个哈希表。\n定时任务周期性地搬移一些数据到新的哈希表中\n\n\n\n\n\n\n\n压缩列表 ziplist 的结构\n\n\n表头\n\nzlbytes：列表长度\nzltail：列表尾的偏移量\nzllen：entry 个数\n\n\n\n表尾 zlend：列表结束，取值默认是 255\n\n\n元素 entry\n\n\nprev_len 前一个 entry 的长度\n\n1 字节：上一个 entry 的长度 &lt; 254 字节\n5 字节：1 字节以外的情况\nprev_len的第一个字节表示一个entry的开始，如果等于255表示列表结束，如果等于254那后四个字节才是prev_len的实际值，如果小于254，那就不需要后四个字节，直接使用这一个字节表示prev_len的实际值\n当前一节点长度大于等于254时，第一个字节为254(1111 1110)作为标志，后面4个字节组成一个整型用来存储长度\n\n\n\nencoding 编码方式，1 字节\n\n\ncontent 实际数据\n\n\n\n\n其他操作同整数数组、双向列表\n\n\n\n\n\n顺序查找 O(N)\n\n\n\n\n跳表 O(logN)：多级索引，通过索引位置的几个跳转，实现数据的快速定位\n\n\n不同操作的复杂度\n\n\n单元素操作是基础\n\n每一种集合类型对单个数据实现的增删改查操作\n\n\n\n范围操作非常耗时\n\n\n集合类型中的遍历操作，可以返回集合中的所有数据\n\n用 SCAN 代替遍历操作\n\n\n\n\n\n统计操作通常高效\n\n集合类型中对集合中所有元素个数的记录\n\n\n\n例外情况只有几个\n\n某些数据结构的特殊记录\n\n\n\n\n"},"02｜日志系统：一条-SQL-更新语句是如何执行的？":{"title":"02｜日志系统：一条 SQL 更新语句是如何执行的？","links":["22｜MySQL有哪些“饮鸩止渴”提高性能的方法？"],"tags":["MySQL"],"content":"Update 语句执行流程 §\n\n重要的日志模块：redo Log §\n\n是 InnoDB 引擎特有的日志\nWAL（Write-Ahead Logging）技术\n\n先写日志，再写磁盘\n当有一条记录需要更新的时候，InnoDB 引擎先把记录写到 redo log，并更新内存，引擎会在适当的时候，将这个操作记录更新到磁盘，这个更新往往是在系统比较空闲的时候做\n\n\nredo log 大小固定，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，所有文件组成一块“粉板”\n\n\nwrite pos 是当前记录的位置，一边写一边后移，写到文件末尾后会回到文件开头\ncheckpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件\nwrite pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。\n如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n\n\ncrash-safe：有了 redo log，InnoDB 可以保证数据库发生异常重启也不丢失数据\n\n重要的日志模块：binlog（归档日志） §\n\n是 Server 层的日志\nstatement 格式：记 SQL 语句\nrow 格式：记录行的内容，记两条，更新前和更新后都有\n\n建议使用\n\n\n\nRedo Log 和 Binlog 的不同 §\n\nredo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\nredo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。\n\n逻辑：其他引擎都能用，都讲得通这个“逻辑”\n物理：只有“我“能用，别人没有共享我的”物理格式“\n\n\nredo log 是循环写，空间固定会用完；binlog 是追加写入。\n\n“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n\n\n两阶段提交 §\n\n提交流程\n\nredolog 的 prepare 阶段\n写 binlog\nredolog 的 commit\n\n\n在 2 之前崩溃时，重启恢复后发现没有 commit，回滚；备份恢复，没有 binlog。一致\n在 3 之前崩溃，重启恢复后发现虽然没有 commit，但满足 prepare 和 binlog 完整，自动 commit；备份恢复，有 binlog。一致\n\n设置建议 §\n\ninnodb_flush_log_at_trx_commit 建议设置成 1，表示每次事务的 redo log 都直接持久化到磁盘，保证 MySQL 异常重启之后数据不丢失\nsync_binlog 建议设置成 1，表示每次事务的 binlog 都持久化到磁盘，保证 MySQL 异常重启之后 binlog 不丢失\n\n答疑文章（一） §\nMySQL 怎么知道 Binlog 是完整的？ §\n\n一个事务的 binlog 有完整格式：\nstatement 格式的 binlog，最后会有 COMMIT；\nrow 格式的 binlog，最后会有一个 XID event。\nMySQL 5.6.2 之后，引入了 binlog-checksum 参数，用于验证 binlog 内容的正确性\n\nRedo Log 和 Binlog 是怎么关联起来的? §\n\n它们有一个共同的数据字段 XID。崩溃恢复的时候，会按顺序扫描 redo log：\n如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；\n如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。\n\n处于 Prepare 阶段的 Redo Log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计? §\n\n与数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。\n\n如果这样的话，为什么还要两阶段提交呢？干脆先 Redo Log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？ §\n\n两阶段提交是经典的分布式系统问题，并不是 MySQL 独有。\n这么做的必要性是事务的持久性问题。\n\n对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志会不一致。\n\n\n\n不引入两个日志，也就没有两阶段提交的必要了。只用 Binlog 来支持崩溃恢复，又能支持归档，不就可以了？ §\n\n\nbinlog 没有崩溃恢复的能力\n\n如果图中标的位置，binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。重启后引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1，系统已经认为提交完成了，不会再应用一次 binlog1。但是，binlog 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。如果在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。\n\n\n如果优化一下 binlog 的内容，让它来记录数据页的更新可以吗？这其实就是又做了一个 redo log 出来。至少现在的 binlog 能力还不支持崩溃恢复。（MySQL 8.0）\n\n那能不能反过来，只用 Redo log，不要 binlog？ §\n\n如果只从崩溃恢复的角度来讲是可以的。把 binlog 关掉，这样就没有两阶段提交，但系统依然是 crash-safe 的。\nbinlog 有着 redo log 无法替代的功能\n\n归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 起不到归档的作用。\nMySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础就是 binlog 复制。\n很多公司有异构系统（比如一些数据分析系统），这些系统靠消费 MySQL 的 binlog 来更新自己的数据。\n\n\n\nRedo Log 一般设置多大？ §\n\nredo log 太小会导致很快就被写满，然后不得不强行刷 redo log，WAL 机制的能力发挥不出来。\n如果是现在常见的几个 TB 的磁盘的话，直接将 redo log 设置为 4 个文件、每个文件 1GB。\n\n正常运行中的实例，数据写入后的最终落盘，是从 Redo Log 更新过来的还是从 Buffer Pool 更新过来的呢？ §\n\nredo log 并没有记录数据页的完整数据，它并没有能力自己去更新磁盘数据页，不存在“数据最终落盘，是由 redo log 更新过去”的情况。\n如果是正常运行的实例，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，与 redo log 毫无关系。\n在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。\n\nRedo Log Buffer 是什么？是先修改内存，还是先写 Redo Log 文件？ §\n\n在一个事务的更新过程中，日志需要写多次。\n\n比如：begin; insert into t1 …; insert into t2 …; commit;\n这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n所以，redo log buffer 就是一块内存，用来先存 redo 日志。\n在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的 IO 消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。这个问题我们会在 22｜MySQL有哪些“饮鸩止渴”提高性能的方法？ 中再详细展开。\n\n\n单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。\n"},"03｜事务隔离：为什么你改了为还看不见？":{"title":"03｜事务隔离：为什么你改了为还看不见？","links":[],"tags":["MySQL"],"content":"隔离型与隔离级别 §\n\n读未提交 read uncommitted\n\n一个事务还没提交时，它做的变更就能被别的事务看到。\n\n\n读提交 read committed\n\n一个事务提交之后，它做的变更才会被其他事务看到。\n\n\n可重复读 repeatable read\n\n一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n\n\n串行化 serializable\n\n对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n\n设置隔离级别\n\nselect @@transaction_isolation;\nset @global transaction isolation level read committed;\n\n\n\n事务隔离的实现 §\n\n以可重复读为例\n每条记录在更新的时候会同时记录一条回滚操作\n\n记录上的最新值，通过回滚操作，都可以得到前一个状态的值\n\n\n\n\n系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志才会被删除\n\n如事务提交之前都可能用到\n⚠️ 不要使用长事务\n\n\nMySQL 5.5 及之前的版本，回滚日志跟数据字典一起放在 ibdata 文件里，即使长事务最终提交，回滚段被清理，文件也不会变小，只能重建整个库进行释放\n\n\n\n事务的启动方式 §\n\n\n\n显式启动事务语句（set autocommit=1），begin 或 start transaction。\n\n\n配套的提交语句是 commit，回滚语句是 rollback。\n如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n\n\n\n\nset autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n\n建议总是使用 set autocommit=1，通过显示语句的方式来启动事务\n\n\n可以在 information_schema 库的 innodb_trx 这个表中查询长事务\n\n查找持续时间超过 60s 的事务\n\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))&gt;60\n\n\n\n\n执行 begin 后面的第一个 SQL 语句时，事务才真正启动，如 select\n\n思考题 §\n\n你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n从应用开发端来看\n\n设置 set autocommit=1\n1 在测试环境看，把 MySQL 的 general_log 开起来，随便跑一个业务逻辑，通过 general_log 的日志确认 autocommit 值\n确认是否有不必要的只读事务\n通过 SET MAX_EXECUTION_TIME 命令控制每个语句执行的最长时间，避免单个语句意外执行太长时间。\n\n\n从数据库端来看\n\n监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警或者 kill\n推荐使用 Percona 的 pt-kill 工具\n在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题\n⚠️ 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便\n\n\ninnodb_undo_tablespaces\n\ninnodb_undo_tablespaces 是控制 undo 是否开启独立的表空间的参数。为 0 表示：undo 使用系统表空间，即 ibdata1。不为 0 表示：使用独立的表空间，一般名称为 undo001 undo002，存放地址的配置项为：innodb_undo_directory。一般 innodb_undo_tablespaces 默认配置为 0，innodb_undo_directory 默认配置为当前数据目录\ninnodb_undo_tablespaces\n\n默认为 0，即回滚段保存在 ibata 文件中\n设置为 2，表示在 undo 目录下创建 2 个文件（每个默认大小 10m），最多创建 126 个，一般名称为 undo001 undo002\n\n\ninnodb_undo_logs：回滚段个数，默认 128\ninnodb_undo_directory：回滚日志存放目录，默认为当前数据目录\n\n\n"},"03｜高性能-IO-模型：为什么单线程-Redis-那么快？":{"title":"03｜高性能 IO 模型：为什么单线程 Redis 那么快？","links":[],"tags":["Redis"],"content":"\n\nRedis 的网络 IO 和键值对读写由一个线程完成\n\n当客户端和 Reids 的网络连接断开时，Redis 不会等待客户端恢复连接\n\n\n\nRedis 的其他功能，比如持久化、异步删除、集群数据同步等，由额外的线程执行\n\n\n单线程设计机制\n\n多线程编程模式：共享资源的并发访问控制问题\n在内存中完成大部分操作 + 高效的数据结构\n\n\n\n多路复用机制（select/epoll 机制）\n\n\n该机制允许内核中同时存在多个监听套接字和已连接套接字\n\n\n内核监听这些套接字上的连接请求或数据请求，一旦有请求到达，就交给 Redis 处理\n\n\n基于事件的回调机制\n\n事件队列\n\n\n\n\n\n基于多路复用的 Redis 高性能 IO 模型\n\n\n\n\n"},"04｜AOF-日志：宕机了，Redis-如何避免数据丢失？":{"title":"04｜AOF 日志：宕机了，Redis 如何避免数据丢失？","links":[],"tags":["Redis"],"content":"\n\nRedis 作为缓存使用\n\n从数据库读取数据恢复\n当需要恢复时数据库压力大、Redis 响应慢\n\n\n\n写后日志：先执行命令把数据写入内存，再记录日志\n\n不会阻塞当前的写操作\n记录的命令没有错误\n没来得及记录时，宕机会丢失数据\n在主线程写，写盘压力大可能导致后续操作无法执行\n\n\n\n日志格式示例\n\n\n执行 set testkey testvalue\n\n\nAOF 文件（Append Only File）\n\n\n\n\n\n*3：命令有三个部分\n\n\n$3：命令、键或值一共有多少字节\n\n\n每个 $n 下一行跟着命令、键或值\n\n\n\n\n三种写回策略\n\nAlways：同步写回\nEverysec：每秒写回\n\n优先使用，在可靠性和性能取了一个平衡\n\n\nNo：操作系统控制的写回\n\n\n\n重写机制\n\n\n多个操作同一个键值的命令合并为一个命令\n\n\n避免重写日志过大\n\n\n直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志\n\n\n一个拷贝\n\n由后台子进程 bgrewiteaof 完成，避免阻塞主线程\n\nfork 创建 bgrewriteaof 子进程时，阻塞主线程，如果实例内存大，执行时间还会更长\n共享主线程内存，主线程执行新写或修改操作时会申请新的内存空间保存新的数据，如果操作的是 bigkey，可能因为申请大空间而面临阻塞风险\n\n\n\n\n\n两处日志\n\n正在使用的 AOF 日志 + 新的重写日志\n避免竞争文件系统的锁\n\n\n\n减小日志大小\n\n\n\n\n\nAOF 非阻塞重写过程\n\n\n\n\n\n\n\n适用于读操作比较多的场景\n\n"},"04｜深入浅出索引（上）":{"title":"04｜深入浅出索引（上）","links":["12｜为什么我的-MySQL-会“抖”一下？"],"tags":["MySQL"],"content":"\n每遇到一个新数据库，先关注它的数据模型，分析数据库的适用场景\n数据库底层存储的核心基于的数据模型：哈希表、有序数组、二叉树、N 叉树等\n\nInnoDB 的索引模型 §\n\n每一个索引在 InnoDB 里面对应一颗 B+ 树\n主键索引也被称为聚簇索引（clustered index）\n\n叶子节点内容是整行数据\n主键查询只需要搜索主键这颗 B+ 树\n整张表的数据存在主键索引中，这就是“聚簇索引”的意思\n\n\n非主键索引也被称为二级索引（secondary index）\n\n叶子节点内容是主键的值\n\n如果主键索引是多个列，二级索引里包含的主键也是多列\n\n\n回表：普通索引查询，先拿到主键，再到主键索引树搜索一次\n\n\n叶子节点是 page（数据页），一个页里面可以存多个行\n\n页大小 16k，则行个数 = 16k/行大小\n\n\n索引维护\n\n页分裂\n\n新增加一个数据页，挪动部分数据过去，空间利用率降低大概 50%\n不挪动数据的新增数据页操作不叫页分裂\n\n\n当相邻的两个数据页利用率很低的时候会做数据页合并\n\n\n主键\n\n建议使用自增主键\n\n建议设置 bigint unsigned\n\n\n使用业务主键的场景（典型的 KV 场景）\n\n只有一个索引\n该索引必须是唯一索引\n\n\n没有主键的表，InnoDB 会默认创建一个 RowId 做主键\n⚠️ 加主键会重建表\n\n\n索引只能定位到 page，page 内部是个有序数组，用二分法\n\n数据页中有页目录，页目录的 key 为 id ，value 为槽位\n二分搜索页目录定位到槽位中的行记录\n内存数据页和磁盘数据页是一一对应的，持久化的时候直接覆盖写进去\n\n\n叶子节点中的数据连接方式\n\n叶子内是单向链表\n叶子间是双向链表\n\n\n\n什么时候需要重建索引 §\n\n索引可能因为删除操作、页分裂等原因，导致数据页有空洞\n\n即空间未释放\n\n\n重建索引的过程会创建一个新的索引，把数据按顺序插入，页面的利用率最高，更省空间\n\n思考题 §\n\n重建普通 k 索引\n\nalter table T drop index k;\nalter table T add index(k);\n\n\n重建主键索引\n\nalter table T drop primary key;\nalter table T add primary key(id);\n\n\n对于上面这两个重建索引的做法，说出你的理解。\n\n重建索引 k 的做法合理，可以达到省空间的目的\n重建主键的过程不合理\n\n\n为什么不合适？\n\n删除或创建主键都会将整个表重建，导致第一个语句白做\n\n\n更好的方法\n\n使用 alter table T engine=InnoDB 代替\n\n触发 MySQL 重建该表，并进行碎片处理\n5.6 版本以后支持 online ddl，没有行锁，有 mdl 读锁\n\n\n在第 12 讲有分析 12｜为什么我的 MySQL 会“抖”一下？\n\n\n"},"05｜内存快照：宕机后，Redis-如何实现快速恢复？":{"title":"05｜内存快照：宕机后，Redis 如何实现快速恢复？","links":[],"tags":["Redis"],"content":"\n\n和 AOF 相比，RDB 记录某一时刻的数据，恢复时直接把 RDB 文件读入内存\n\n全量快照\n\n\n\n生成 RDB 文件的方案\n\n\nsave：在主线程中执行，会导致阻塞\n\n\n（默认）bgsave：创建一个子进程，复制主线程的页表，专门写入 RDB 文件，避免阻塞。\n\n共享主线程的所有内存数据\n\n\n\n\n\n快照时数据能修改吗？\n\n读操作：bgsave 子进程和主线程互不影响\n能\n写操作：生成被修改的一块数据的副本，bgsave 子进程继续写 RDB 文件，主线程在副本上进行修改\n写时复制：主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射\n\n\n\n\n\n\n\n可以每秒做一次快照吗？\n\n磁盘压力\nfork bgsave 子进程的过程会阻塞主线程\n\n\n\n混合使用 AOF 和内存快照\n\nAOF 只保留从最后一次快照开始的改动\n\n\n\n数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择\n\n\n如果允许分钟级别的数据丢失，可以只使用 RDB\n\n\n如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡\n\n\n持久化有关的风险\n\n\n服务器内存不足\n\n写时复制为写、修改操作涉及的数据分配相同大小的内存副本\n\n\n\n子进程也会占用 CPU 资源\n\n\n需要开启定时 RDB 和 AOF 重写时进程一定不要绑定 CPU：子进程会与父进程争夺同一个 CPU 资源（具体搜索关键字找到后面有关绑定 CPU 的章节）\n\n\n\n"},"05｜深入浅出索引（下）":{"title":"05｜深入浅出索引（下）","links":["ElasticSearch","InnoDB"],"tags":["MySQL"],"content":"如何安排联合索引内的字段顺序 §\n\n第一原则：如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n如果既有联合查询，又有基于 a、b 各自的查询，此时要考虑空间\n\n比如 a 比 b 大，就建 (a, b) + 单 b\n\n\n还有其他情况，需要结合业务分析\n\n查询语句的 where 里面各个判断调换顺序不影响 §\n覆盖索引 §\n\n如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果\n要全用上必须是条件 =，不能是 &gt; 或 &lt;\n\n在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？ §\n\n如果有一个高频请求是根据身份证号查询姓名，就有必要\n\n前缀索引 §\n\n最左前缀原则\n\n可以是联合索引的最左 N 个字段\n也可以是字符串索引的最左 M 个字符\n\n\n\n索引下推 §\n\nMySQL 5.6 之后引入\n可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数\n例子：有个 (name, age) 索引\n\nwhere name like &#039;张%&#039; and age=10\n因为最左前缀原则，只能用到 name 索引\n5.6 之前：查找到所有张开头的记录，一个个回表找出数据行，对比 age 字段值\n5.6 之后：索引下推\n\n\n\n思考题 §\n\n已有条件\n\n多个索引\n\nprimary ab (a, b)\nc (c)\nca (c, a)\ncb (c, b)\n\n\nDBA 解释：业务中有两个语句\n\nselect * from geek where c=N order by a limit 1;\nselect * from geek where c=N order by b limit 1;\n\n\n所以需要 ca 和 cb，而不是单个 c\n\n\n问题\n\n这样解释对吗，ca 和 cb 是否都是必须的\n\n只需要 cb\n\n\n为什么\n\n因为存在 ab，普通索引包含主键，即 c + ab =&gt; cab\n\n\n题外话\n\n对于 order by，如果索引合理，数据有序，就不需要排序了\n\n\n\n\n\n评论区 §\n\n面试题：怎么让 MySQL 的 myisam 引擎支持事务\n\n用 lock table 实现，但只能实现串行化隔离级别\n因为 mysiam 不支持崩溃恢复，所以即使用 lock table 硬实现，也是问题多多\nACID 里面，原子性和持久性做不到\n隔离性只能实现基本用不上的串行化\n一致性在正常运行的时候依赖于串行化，在异常崩溃的时候也不能保证\n这样实现的事务不要也罢\n\n\n订单表查询，有多个条件，不选则不传，怎么建索引\n\n老师回复\n\n按照查询的模式，选最常见的创建联合索引。\n\n比如，如果时间 + 客户标志用得最多，就创建这两个的联合索引\n\n\n比较少用的条件，就单独建，然后查 id 出来跟别的字段的查询结果，在客户端取交集\n\n\n跟评\n\n用 ElasticSearch，相当于全建索引\n\n好处是快，减轻数据库压力\n坏处是多维护一个中间件\n\n\n\n\n\n\n使用联合索引的时候，联合索引的多个属性都在同一棵树上\n\nInnoDB 的普通索引，都是这个索引字段 + 主键字段的联合索引\n\n\n用 key 和 index 创建索引没有区别\n什么情况下会一次取出多个主键回表\n\n自动，代码版本支持就会这么做\n\n\n联合索引是怎么存储的\n\n联合索引是依次按照联合字段的先后顺序，依次进行排序。如 a, b, c 三个字段是联合索引，则叶子节点存储的是三个字段的数据，且按照先后顺序进行排序；而非叶子节点存储的是第一个关键字的索引。故当执行查询的时候，因为联合索引中是先根据 a 进行排序的，如果 a 没有先确定，直接对 b 或 c 进行查询的话，就相当于是乱序查询，因此联合索引无法生效，此时就相当于是全表查询。\n\n\nin 速度很快，in 里面的项递增输入的话，理论上会快些\n\n如果太多项，可以拆成多个 in()，分批处理\n⚠️ 不要用 union all\n\n\nb+ 树中的索引节点应该都是由指针和索引组成。但现在要将磁盘索引节点加载到内存中，这些指针地址是怎么映射的（磁盘和内存指针的映射）\n\n首先磁盘的数据和数据页是一样的，\n所以磁盘只能记录 “我的第一个叶子节点在 page_n”\n在内存里面也是，当把 page_n 读到内存以后，内存里面记录的是 page_n 的内存地址在哪里\n\n\n"},"06｜全局锁和表锁：给表加个字段怎么有这么多阻碍？":{"title":"06｜全局锁和表锁：给表加个字段怎么有这么多阻碍？","links":[],"tags":["MySQL"],"content":"全局锁 §\n\n典型使用场景：做全库逻辑备份。\n\n使用 MySQL 提供的加全局读锁的方法\n\nFlush tables with read lock（FTWRL）\n整个库进入只读状态\n执行 FTWRL 命令之后由于客户端发生异常断开，MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。\n\n\n推荐：在可重复读隔离级别下开启一个事务\n\n备份期间可以正常读写数据库\n需要所有的表的引擎都支持（全库备份）\nmysqldump 备份工具使用 -single-transaction 参数，就会开启一个事务，确保拿到一致性视图\n\n\n\n\n⚠️ 为什么不使用 set global readonly=true？建议用 FTWRL\n\n在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。\n将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。\nreadonly 对 super 权限的用户无效\n\n\n\n表级锁 §\n\n表锁\n\n语法：lock tables … read/write\nunlock tables 主动释放锁，或者客户端断开时自动释放\n除了会限制别的线程的读写，也会限定本线程自己接下来的操作对象\n不推荐使用，若引擎不支持事务，安排升级换引擎。\n\n升级后把使用 lock/unlock tables 语法的地方换成 begin 和 commit。\n\n\n\n\n元数据锁 MDL（metadata lock）\n\n不需要显式使用，在访问一个表的时候会被自动加上\nMySQL 5.5 中引入\nMDL 的作用是防止 DDL（加字段等修改表结构的操作）和 DML（增删改数据）冲突\n当对一个表做增删改查时，加 MDL 读锁。\n当对表做结构变更操作时，加 MDL 写锁。\n读锁之间不互斥\n读写锁之间、写锁之间互斥\n\n\n如何安全地给小表加字段？\n\n\n\n解决长事务，事务不提交会一直占着 MDL 锁。\n\n\n在 information_schema 库的 innodb_trx 表可以查到当前执行中的事务。\n可以暂停 DDL 或者 kill 掉这个长事务\n\n\n\n\n热点表，数据量不大的情况\n\n\nkill 事务不一定管用，kill 后立马有新的请求\n在 alter table 语句里面设定等待时间，拿不到 MDL 写锁就先放弃，重试命令重复加字段过程。\n\nMariaDB 已经合并了 AliSQL 的这个功能，这两个开源分支都支持 DDL NOWAIT/WAIT n 语法\n\n\n\n\n\n\n大表加字段：Gh-ost\n\n思考题 §\n\n备份一般在备库上执行\n在用 -single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表加了一列\n这时候在备库上会看到什么现象？\n\nQ2 启动了一致性试图，但一致性视图不包含表结构。此时报错表结构已改变，然后 mysqldump 终止。\n\n\n\n"},"06｜数据同步：主从库如何实现数据一致？":{"title":"06｜数据同步：主从库如何实现数据一致？","links":[],"tags":["Redis"],"content":"\n写操作：首先到主库执行，主库将写操作同步给从库\n\n同步流程 §\n\n\n主从库第一次同步的流程\n\n\n\n\n\n增量复制流程\n\n\n\n\n\n全量复制 §\n\n\n第一次同步无法避免\n\n\n一个实例的数据库不要太大（几 GB 级别合适）\n\n\n通过 RDB 文件\n\n二进制文件\n\n\n\n不用 AOF 的原因\n\n需要打开 AOF 功能\n\n有很多场景数据不敏感不需要开启 AOF 功能\n刷盘策略选择不当会严重影响 Redis 性能\n\n\n比 RDB 文件大\n在从库端进行恢复时，用 RDB 的恢复效率高于用 AOF\n\n\n\n增量复制 §\n\n\n通过命令传播的长连接复制\n\n完成全量复制后，主库通过长连接将后续陆续收到的命令操作同步给从库，可以避免频繁建立连接的开销\n\n\n\n网络断连时\n\nrepl_backlog_buffer\n\n\n\n主 -&gt; 从 -&gt; 从 §\n\n\n\n\n\n从库执行 replicaof IP PORT\n\n\n\nIP 上的实例执行 bgsave 命令生成 RDB 文件后发给从库\n\n\n\n\n从库清空当前数据库\n\n\n\n\n主库会在内存用专门的 replication buffer 记录 RDB 文件生成后收到的所有写操作\n\n\n\n\n将 replication buffer 的修改操作发给从库\n\n\n\n\n\n从 -&gt; 从：分担全量复制时的主库压力\n\n\nreplication buffer 和 repl_backlog_buffer 的区别 §\nreplication buffer：复制缓冲区 §\n\n\n从库也相当于一个客户端，会单独分配一个 client buffer，这里用来传播用户的写命令到从库，通常把它叫做 replication buffer\n\n\n主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区\n\n\n作用：主节点向从节点发送 RDB 文件时，如果又接收写操作，会暂存在缓冲区，等 RDB 文件传输完成，且从节点加载完成后，主节点把缓冲区中的写命令发给从节点进行同步\n\n\n\n\n\n对主从同步的影响：如果传输和加载 RDB 文件耗时长，同时主库接收的写命令操作较多，导致缓冲区写满溢出，主库会强制关闭和从库的网络连接，重新开始全量同步\n\n\n通过 client-output-buffer-limit-slave 配置项增加缓冲区大小\n\n\nclient buffer 超过限制时，主库会强制断开这个 client 连接\n\n\n此时从库再次发起复制请求，可能导致恶性循环\n\n\nrepl_backlog_buffer：复制积压缓冲区 §\n\n\n是一个环形缓冲区：为了在从库断开之后能找到主从差异数据而设计\n\n\n记录写操作\n\n\n所有从库共享\n\n\n不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步\n\n\n主从断开太久，主库写操作节点越过从库在 repl_backlog_buffer 的读节点时，从库只能全量复制\n\n\nrepl_backlog_size\n\n= 缓冲空间大小 * 2\n缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小\n过小可能导致从库复制进度赶不上主库，触发全量复制\n\n\n\nrepl_backlog_buffer 的使用\n\n\n\n\n\n主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步\n\n\n\n\n\n父节点图2\n\n\n\n\n\n\n"},"07｜哨兵机制：主库挂了，如何不间断服务？":{"title":"07｜哨兵机制：主库挂了，如何不间断服务？","links":[],"tags":["Redis"],"content":"\n\n哨兵机制的基本流程\n\n\n\n\n监控：判断主从库下线\n\n\n\n\n主观下线\n\n哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。\n如果哨兵发现主库或从库对 PING 命令的响应超时了，哨兵就会先把它标记为“主观下线”。\n从库会被直接标记为“主观下线”。\n\n\n\n客观下线\n\n大多数的哨兵判断主库主观下线，主库才会标记为客观下线\n\n\n\n减少误判\n\n哨兵集群：哨兵机制通常采用多实例组成的集群模式部署\n\n\n\n\n\n\n\n选主：选出新主库（筛选 + 打分）\n\n\n\n\n\n\n按照一定的筛选条件去掉不符合条件的从库\n\n\n\n\n在线状态\n\n\n网络状态\n\n配置项（ms）down-after-milliseconds * 10\n如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了\n如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好\n此参数可以调节哨兵的敏感程度\n\n\n\n\n\n\n\n按照一定的规则给剩下的从库逐个打分\n\n\n\n\n从库优先级\n\n通过 slave-priority 配置项设置\n\n\n\n从库复制进度\n\n\n和旧主库同步程度最接近的从库得分高\n\nsalve_repl_offset 最大\n\n\n\n\n\n从库 ID 号\n\n在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。\n\n\n\n\n\n\n得分最高的作为新主库\n\n\n\n选择新主库的过程\n\n\n\n\n\n\n\n\n\n通知\n\n\n\n\n\n\n让从库执行 replicaof 与新主库同步\n\n\n\n4.0 之前全量同步，4.0 之后增量同步，了解 psync2\n\n\n\n\n通知客户端与新主库连接\n\n\n\n\n\n\n\n切换过程中，客户端能否正常进行请求操作？\n\n客户端使用了读写分离时不会受到影响\n写请求失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库的时间\n\n\n\n如果想要应用程序不感知服务的中断，还需要哨兵或客户端做些什么？\n\n\n客户端把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新主库，只适合对写入请求返回值不敏感的业务，需要业务层做适配\n\n\n哨兵主动通知客户端\n\n\n\n哨兵将新主库地址写入自己实例的 pub/sub（switch-master 事件）中\n\n\n\n\n客户端订阅 pub/sub，有数据时，客户端能感知到主库变更，同时可以拿到最新的主库地址\n\n\n\n\n\n客户端通过 sentinel get-master-addr-by-name 命令从哨兵集群中获取最新的地址\n\n\n一般 Redis 的 SDK 都提供了通过哨兵拿到实例地址，再访问实例的方式，直接使用即可\n\n\n\n"},"07｜行锁功过：怎么减少锁对性能的影响？":{"title":"07｜行锁功过：怎么减少锁对性能的影响？","links":[],"tags":["MySQL"],"content":"\nMyISAM 不支持行锁\n\nInnoDB 的行锁 §\n\n两阶段锁协议：事务中，行锁在需要的时候才加上，但要等到事务结束时释放。\n如果你的事务中需要锁多个行，要把最可能造成锁冲突、影响并发度的锁尽量往后放。\n当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。\n\n两种策略\n\n\n\n直接进入等待，直到超时。\n\n\n超时时间可以通过 innodb_lock_wait_timeout 设置\n默认 50s。\n\n\n\n\n发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。\n\n\n将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n死锁：每当一个事务被锁，就要看看它所依赖的线程有没有被别的锁住，如此循环，最后判断是否出现连循环等待。\n假设现在已经有 999 个线程在同一行等锁，新来一个请求也要访问这个行，他要判断有没有死锁要判断 1000 次。然后这个结果乘以 1000。\n\n\n正常情况下采用第二种策略，默认也是第二种。\n\n\n\n\n怎么解决热点行更新导致的性能问题？\n\n问题的症结：死锁检测要耗费大量的 CPU 资源。\n\n\n确保业务一定不会出现死锁，关闭死锁检测（不推荐）\n\n\n\n\n控制并发度。\n\n\n\n\n在中间件或修改 MySQL 源码实现：对于相同行的更新，在进入引擎之前排队，这样 InnoDB 就不会有大量的死锁检测工作。\n\n\n\n\n如果做不到第 1 点，可以考虑从设计上优化\n\n\n考虑通过将一行改成逻辑上的多行来减少锁冲突。\n以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。\n\n\n\n\n\n\n\n思考题 §\n\n如果要删除一个表里面的前 1w 行数据，选择哪一种方法（选 2）\n\n\n\n直接执行 delete from T limit 10000;\n\n\n单个语句占用时间长，锁的时间也比较长；\n大事务会导致主从延迟。\n\n\n\n\n在一个连接中循环执行 20 次 delete from T limit 500;\n\n\n\n\n在 20 个连接中同时执行 delete from T limit 500;\n\n\n人为造成锁冲突。\n\n\n\n\n\n评论区 §\n\n关于思考题\n\n第二种方法难道不会引起数据一致性问题吗？如果在 InnoDB 中开启了自动事务并且没有显式用 begin, commit 来做的话，在上一次循环结束和下一次循环开始之间如果有其他事务插入了新数据，而且正好位置也在前面 500条，那不就不一致了么\n\n加个 order by id（假设 id 是表的主键）\n排序后新增的 id 肯定大于要删除的最大 id\n\n\n\n\n如果有多种锁，必须全部不互斥才能并行。\nMySQL 没有嵌套事务，开启下一个会自动提交上一个\n"},"08｜事务到底是隔离的还是不隔离的？":{"title":"08｜事务到底是隔离的还是不隔离的？","links":[],"tags":["MySQL"],"content":"事务的启动时机 §\n\nbegin/start transaction 命令之后的第一个操作 InnoDB 表的语句，事务才真正启动。\n马上启动一个事务：start transaction with consistent snapshot。\n事务自动提交设置，默认为 1，即除非显示声明一个事务的开始，否则每一个查询都会被当做独立的事务被处理。\n整个专栏，如果没有特别说明，都默认 autocommit = 1。\n\nMySQL 里的两个“视图”的概念 §\n\n一个是 view。是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。\n\n创建视图的语法是 create view …，查询方法和表一样。\n\n\n另一个是 InnoDB 在实现 MVCC（多版本并发控制） 时用到的一致性读视图（consistent read view），用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。\n视图没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”\n\n“快照”在 MVCC 里是怎么工作的？ §\n\n秒级创建快照的能力，快照是基于整库的。\nInnoDB 的行数据有多个版本（row），每个版本有自己的 row trx_id（严格递增）。\n\n\n图中的虚线就是 undo log。\n\n\n在实现上，InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。\n\n活跃：启动了但还没提交。\n数组里事务 ID 的最小值记为低水位。\n当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。\n这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。\n数据版本的可见性规则：基于数据的 row trx_id 和一致性视图的对比结果得到的。\n\n\n绿色：表示这个版本是已提交的事务或者是当前事务自己生成的，可见。\n红色：表示是由将来启动的事务生成的，不可见。\n黄色\n\na）若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；\nb）若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。\n\n\n\n\n\n\n翻译：对于一个事务视图，除了自己的更新总是可见以外，有三种情况\n\n版本未提交，不可见；\n版本已提交，但是是在视图创建后提交的，不可见；\n版本已提交，而且是在视图创建前提交的，可见。\n\n\n每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。\n\n对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n\n\n\n更新逻辑 §\n\n更新数据都是先读后写。\n当前读：总是读取已经提交完成的最新版本。\n除了 update 语句，select 语句如果加锁，也是当前读。\n\n加上 lock in share mode 或 for update。\n\n\n\n事务的可重复读是怎么实现的？ §\n\n可重复读的核心是一致性读；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n读提交的逻辑和可重复读的逻辑类似，最主要的区别：\n\n在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；\n在读提交隔离级别下，每一个语句执行前都会重新算出一个新的事务。\n\n\n\n为什么表结构不支持“可重复读”？ §\n\n因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\nMySQL 8.0 可以把表结构放在 InnoDB 字典里，也许以后会支持表结构的可重复读。\n\n思考题 §\n\n表\n\nid 1 2 3 4\nc 1 2 3 4\nInnoDB，主键 id\n\n\n想要把所有字段 c 和 id 值相等的行的 c 值清零，却改不掉\n\n\n\nbegin；2. select * from t；3. update t set c=0 where id=c；4. select * from t；\n\n\n2、4 查到的结果一样。\n\n\n构造出这种情况\n\n\n用另一个事务在更新语句前先进行更新\n\n\n说明原理\n\n更新操作是当前读，被抢先更新后的数据版本号不属于自己，看不到，在可重复读下还是读到旧值，此时就出现：数据正确，却更新不了\n\n\n在实际业务开发中有没有可能碰到这种情况？\n\n有\n\n\n怎么解决？\n\n根据更新语句的 affected_rows 判断是否更新成功\n\n\n\n评论区 §\n\n在同一行数据，最新版本的 row trx_id 是可能会小于旧版本的 row trx_id 的。因为后开启的事务可能先提交。\n只读事务“不分配 trx_id”\n\n5.6 以后的优化\n其实不是不分配，而是随机分配。\n\n\n读提交和当前读\n\n读提交不加锁\n考虑下，一个语句开始执行之后，执行期间别的事务修改了数据的情况。\n\n\n"},"08｜哨兵集群：哨兵挂了，主从库还能切换吗？":{"title":"08｜哨兵集群：哨兵挂了，主从库还能切换吗？","links":[],"tags":["Redis"],"content":"\n\n本质上哨兵就是一个运行在特定模式下的 Redis 实例。\n\n\n基于 pub/sub 机制的哨兵集群组成过程（发布/订阅机制）\n\n只有订阅了同一个频道的应用才能通过发布的消息进行信息交换\n哨兵通过 __sentinel__:hello 频道互相发现、通信\n\n\n\n给主库发送 INFO 命令拿到从库列表，哨兵根据列表上的连接信息和从库建立连接并监控\n\n\n基于哨兵自身的 pub/sub 功能，实现客户端和哨兵之间的事件通知\n\n\n重要的频道汇总图\n\n\n\n\n\n订阅例子：客户端执行 SUBSCRIBE * 订阅所有事件\n\n\n\n\n由哪一个哨兵执行主从切换？\n\n和主库客观下线的判断过程类似，投票仲裁\n\n\n标记主库“主观下线”\n\n\n\n\n向其他哨兵实例要赞成票\n\n\n\n\n获得仲裁所需的赞成票后，就可以标记主库为“客观下线”。\n\n\n\n\n成功标记主库为客观下线的哨兵实例向其他哨兵发送命令，表明希望执行主从切换\n\n\n\n\n\n投票（Y/N），确定 Leader\n\n\n\n\n\n拿到半数以上赞成票\n\n\n\n\n拿到的票数大于等于哨兵配置文件中的 quorum 值\n\n\n每个哨兵只能投一个赞成票，可以给自己投，第一次必投 Y\n所有哨兵同时判断主库主观下线，然后同时得到客观下线的结论时，每个哨兵各自一票（概率极低）\n\n\n\n\n\n要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds\n\n\n思考题\n\n\n配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？\n\n能，两个哨兵都给出主观下线的结果，达到了 quorum 的值\n\n\n\n如果可以的话，还能进行主从库自动切换吗？\n\n不能主从切换，选举 Leader 拿不到超过半数的选票（5/2 + 1 = 3）\n\n\n\n哨兵实例是不是越多越好呢？\n\n不是。通信次数增多，故障风险变大，选举时间变长\n\n\n\n调大 down-after-milliseconds 值，对减少误判有没有好处？\n\n有好处，降低误判的概率，但主从切换时间变长，对业务影响时间变久\n\n\n\n\n"},"09｜切片集群：数据增多了，是该加内存还是加实例？":{"title":"09｜切片集群：数据增多了，是该加内存还是加实例？","links":[],"tags":["Redis"],"content":"纵向扩展 §\n\n升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU\n实施起来简单、直接\n当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞（耗时长）\n不要求持久化保存 Redis 数据时是一个不错的选择\n受到硬件和成本的限制\n\n横向扩展 §\n\n增加当前 Redis 实例的个数\n扩展性更好\n数据切片后，在多个实例之间如何分布？\n客户端怎么确定想要访问的数据在哪个实例上？\n\n切片集群 §\n\n是一种保存大量数据的通用机制，可以有不同的实现方案\n\nRedis Cluster（官方） §\n\n\n采用哈希槽（Hash Slot）处理数据与实例之间的映射关系\n\n\n共有 16384 个哈希槽，个数在客户端和服务端写死\n\n\n\n根据键值对的 key，按照 CRC16 算法 计算一个 16 bit 的值\n\n\n\n\n用值对 16384 取模，得到 0～16383 范围内的模数（哈希槽编号）\n\n\n\n数据映射关系：键的哈希值 =&gt; 哈希槽 =&gt; 不同的实例\n\n\n\n\n\n部署\n\n手动或自动将所有槽分配完后，集群才能正常工作\ncluster create 命令创建集群，自动将槽平均分布在实例上\ncluster meet 手动建立实例间的连接形成集群，再使用 cluster addslots 制定每个实例上的哈希槽个数\n\n\n\n客户端如何定位数据？\n\nRedis 实例会把自己的哈希槽信息发给和它相连接的其他实例，实例相互连接后每个实例都有所有哈希槽的映射关系\n客户端将哈希槽信息缓存在本地\n先计算键对应的哈希槽\n然后给相应的哈希槽发送请求\n\n\n\n运维人员手动触发进行负载均衡和数据迁移\n\n\n常见的变化\n\n在集群中，实例有新增或删除，Redis 需要重新分配哈希槽\n为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍\n\n\n\n重定向机制\n\n\n当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，这个实例就会给客户端返回 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址\n\n\n响应结果示例：GET hello:key｜(error) MOVED 13320 172.16.19.5:6379\n\n\n（实例上的数据已全部迁移完成）\n\n\n\n\n\n会更新客户端缓存的哈希槽分配信息\n\n\n\n\n当请求的实例只有一部分迁移到另一个实例，刚好请求的哈希槽已迁移，客户端会收到一条 ASK 报错信息\n\n响应结果示例：GET hello:key｜(error) ASK 13320 172.16.19.5:6379\n（实例上的数据只有部分迁移完成）\n\n\n\n\n不会更新客户端缓存的哈希槽分配信息\n\n\n\n\n\n迁移数据是同步的，如迁移一个 key 时，会阻塞源节点和目标节点\n\n\n基于客户端分区 §\n\nSharededJedis\n\n基于代理（proxy） §\n\n\nCodis\n\n\n支持在线扩容\n\n客户端无感知\n\n\n\n数据迁移是异步的\n\n速度更快，对性能影响小\n\n\n\n\n\nTwemproxy\n\n\n不支持在线扩容\n\n\n思考题 §\n\n\nRedis Cluster 方案的映射流程有什么好处？\n\n哈希槽把数据和节点解耦，key 通过 Hash 计算，只需要关心映射到哪个哈希槽，再通过哈希槽和节点的映射表找到节点，且数据分布更均匀\n数据迁移时以哈希槽为基本单位，简化了节点扩容、缩容的难度\n\n\n\nRedis 为什么不用表直接记录键值对和实例的对应关系？\n\nkey 的数量无法预估\nRedis Cluster 采用无中心化模式（无 proxy，客户端和服务端直连），客户端需要能正确路由到正确节点，所有节点都要有完整的路由关系，帮助矫正客户端保存的路由关系\n发生数据迁移时，需要修改每个 key 的对应关系，维护成本高\n基于单个表的单线程操作表需要串行执行，性能低\n多线程操作表，涉及加锁开销\n\n\n"},"09｜普通索引和唯一索引，应该怎么选择？":{"title":"09｜普通索引和唯一索引，应该怎么选择？","links":[],"tags":["MySQL"],"content":"查询性能 §\n\n「where = 」时，唯一索引找到了立马返回，普通索引需要找到下一个不等于的值\n因为 InnoDB 的数据是按数据页为单位读写，所以性能差距微乎其微\n\n对于整形字段，一个 16KB 的数据页可以放近千个 key\n\n\n\nChange Buffer §\n\n\n当需要更新一个数据页时，如果数据页在内存中就直接更新\n\n\n如果数据页还没有在内存中，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中\n\n\n下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行第 2 步缓存在 change buffer 中与这个页有关的操作\n\n这个过程称为 merge\n除了访问数据页会触发 merge，系统有后台线程会定期 merge\n在数据库正常关闭的过程中，也会执行 merge 操作\n\n\n\nchange buffer 是可以被持久化的数据\n\n在内存中有拷贝，也会被写到磁盘上\n\n\n\n减少读磁盘的次数，语句的执行速度得到明显提升\n\n\n数据读入内存需要占用 buffer pool，所以 change buffer 这种方式还能够避免占用内存，提高内存利用率\n\n\n什么条件下可以使用 change buffer？\n\n只有普通索引可以使用\n唯一索引的更新不能使用\n\n所有的更新操作都要先判断是否违反唯一性约，必须要将数据页读入内存才能判断\n\n\n\n\n\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大\n\n通过参数 innodb_change_buffer_max_size 动态设置，如 50 表示只能占用 buffer pool 的 50%\n\n\n\n更新数据的处理流程\n\n更新的目标页在内存中\n\n唯一索引：找到要插入的位置，判断没有冲突，插入\n普通索引：找到要插入的位置，插入\n\n\n不在内存\n\n唯一索引：读入内存，判断没有冲突，插入\n普通索引：将更新记录在 change buffer，完成\n\n\n\n\n\n使用场景\n\n写多读少的业务：效果最好，如账单类、日志类的系统\n\n视情况可以尽量开大\n\n\n写完马上做查询的业务：不适用，起反作用\n\n\n\nchange buffer 和 redo log\n\nredo log 主要节省随机写磁盘的 IO 消耗（转成顺序写）\nchange buffer 主要节省随机读磁盘的 IO 消耗\n\n\n\nMerge 的执行流程 §\n\n从磁盘读入数据页到内存（老版本的数据页）；\n从 change buffer 里找出这个数据页的 change buffer 记录（可能有多个），依次应用，得到新版数据页；\n写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。\na. 此时 merge 过程结束，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据的操作属于另外一个过程。\nb. 因为 redo log 也记录了 change buffer 的操作，所以崩溃恢复的时候能找回。\n\n评论区 §\n\n系统表空间和数据表空间两个概念\n\n系统表空间用来放系统信息，比如数据字典，对应的磁盘文件是 ibdata1\n数据表空间是一个个的表数据文件，对应的磁盘文件就是 表名.ibd\n\n\nchange buffer 相当于推迟了更新操作，那对并发控制是否有影响，比如加锁？我一直以为加锁需要把具体的数据页读到内存中来，才能加锁，然而并不是？\n\n锁是一个单独的数据结构，如果数据页上有锁，change buffer 在判断“是否能用”的时候，就会认为否\n\n\n在 change buffer 中有此行记录的情况下，再次更改，增加一条记录\nmerge 行为之后应该不会再产生 redo log 了吧？\n\n分成两步考虑\n\nmerge 是从磁盘读数据页到内存，然后应用，这一步是更新内存，同时写 redolog\n内存变成脏页，跟磁盘数据不一样。之后就走刷脏页的流程\n\n\n\n\nchange buffer 跟普通数据页一样存在磁盘里，区别在于 change buffer 是在共享表空间 ibdata1 里。\nredo log 有两种，一种记录普通数据页的改动，一种记录 change buffer 的改动。\n对数据的修改记录在 change buffer 里的时候，内存里没有这个物理页，不存在脏页。\n真正对磁盘数据页的修改是通过内存里脏页的数据刷回磁盘来完成的，而不是根据 redo log。\nchange buffer 和数据页一样，也是物理页的一个组成部分，数据结构也是一颗 B+ 树，这棵 B+ 树放在共享表空间，默认在 ibdata1 中。\nchange buffer 的写盘策略跟数据一样，内存放不下会触发落盘，还有 checkpoint 推进的时候也可能会触发。\n"},"10｜MySQL-为什么有时候会选错索引？":{"title":"10｜MySQL 为什么有时候会选错索引？","links":[],"tags":["MySQL"],"content":"优化器的逻辑 §\n\n扫描行数\n\n一个索引上不同的值越多，这个索引的区分度越好\n基数（cardinality）：一个索引上不同的值的个数。\n\n采样统计：InnoDB 默认选择索引的 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面树，就得到这个索引的基数。\n当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。\n两种存储索引统计的方式，通过设置参数 innodb_stats_persistent 的值选择\n\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n\n\n\n\n从普通索引拿到一个值后，回到主键索引查出整行数据的代价也要算。\n由于索引统计信息不准确导致的问题，用 analyze table 命令来解决。\n\n\n是否使用临时表\n是否排序\n\n解决其他优化器误判的情况 §\n\n可以在应用端用 force index 来强行指定索引；\n也可以通过修改语句来引导优化器；\n\n如，当 xxx order by b limit 1; 最终选择 b 索引而不是 a 索引，可能是因为判断使用 b 就可以不用再排序，此时将语句改成 xxx order by b, a limit 1; 是一个可考虑的解决方法\n前提是 SQL 语句语义不变\n\n\n还可以增加或者删除索引绕过问题\n\n思考题 §\n\n前面我们在构造第一个例子的过程中，通过 session A 的配合，让 session B 删除数据后又重新插入了一遍数据，然后就发现 explain 结果中，rows 字段从 10001 变成 37000 多。而如果没有 session A 的配合，只是单独执行 delete from t、call idata()、explain 这三句话，会看到 rows 字段其实还是 10000 左右。你可以自己验证一下这个结果。\n这是什么原因呢？也请你分析一下吧。\n\nsession A 还没有提交，所以之前插入的 10 万行数据还不能删除。\n所以之前的数据每一行都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。\n因为这个是主键，主键是直接按照表的行数来估计的，而表的行数，优化器直接用的是 show table status 的值（后面有章节详细讲解）。\n\n\n"},"11｜“万金油”的-String，为什么不好用了？":{"title":"11｜“万金油”的 String，为什么不好用了？","links":[],"tags":["Redis"],"content":"\n\nRedis 容量预估工具\n\n\nString 类型\n\n\n元数据：内存空间记录数据长度、空间使用等信息\n\n\nint 编码方式：当保存 64 位有符号整数时，会保存为 8 字节的 Long 类型整数\n\n\n简单动态字符串（Simple Dynamic String，SDS）结构体的组成\n\nbuf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\\0”，这就会额外占用 1 个字节的开销\nlen：占 4 个字节，表示 buf 的已用长度\nalloc：也占 4 个字节，表示 buf 的实际分配长度，一般大于 len\n\n\n\n\nRedisObject 结构体\n\n包含了 8 字节的元数据和一个 8 字节指针\n指针指向实际数据，如 SDS\nint 编码：当保存 Long 类型整数时，指针直接赋值为整数数据\nembstr 编码：保存 &lt;= 44 字节的字符串数据，元数据、指针和 SDS 是一块连续的内存区域\nraw 编码：保存 &gt; 44 字节的字符串数据，给 SDS 分配独立的空间\n\n\n\n\n\n\n哈希表的每一项是一个 dictEntry 的结构体，指向一个键值对\n\n有三个 8 字节的指针\n分别指向 key、value和下一个 dictEntry\n\n\n\nRedis 使用的内存分配库 jemalloc\n\n\n根据申请的字节数 N，找一个比 N 大的最接近 N 的 2 的幂次数作为分配的空间\n\n减少频繁分配的次数\n\n\n\n\n\n压缩列表 ziplist\n\n\n示例：用集合类型保存单值的键值对\n\n\n图片 ID 1101000060\n\n\n对象 ID 3302000080\n\n\n二级编码：hset 1101000 060 3302000080\n\n\n查找时会遍历压缩列表\n\n\nSorted Set 也可以达到类似的效果，不过插入时性能没 Hash 高\n\n需排序，而 Hash 直接插入尾部\n\n\n\n\n\nHash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据\n\nhash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数\nhash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度\n数据一旦用了哈希表保存就不会自动转回成压缩列表\n\n\n\n选用 Hash 和 Sorted Set 存储时，节省空间，但设置过期会变得困难\n\n\n选用 String 存储时，可以单独设置每个 key 的过期时间，还可以设置 maxmemory 和淘汰策略，以这种方式控制整个实例的内存上限\n\n"},"11｜怎么给字符串字段加索引？":{"title":"11｜怎么给字符串字段加索引？","links":[],"tags":["MySQL"],"content":"\n直接创建完整索引，比较占用空间；\n创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\na. 在索引上找到数据后需要回到主键上拿到完整数据进行判断\nb. 即使前缀完全覆盖了字段内容也会回表，因为不确定是不是真的完整数据\n倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题，不支持范围扫描；\na. index index_name(email(6));\n创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，需要多一个字段保存 hash 字段，不支持范围扫描。\na. 比如通过 crc32() 函数得到 hash 值\n"},"12｜为什么我的-MySQL-会“抖”一下？":{"title":"12｜为什么我的 MySQL 会“抖”一下？","links":[],"tags":["MySQL"],"content":"概念 §\n\n脏页：跟磁盘数据页内容不一致的内存数据页\n干净页：跟磁盘数据页内容一致的内存数据页\n\n何时内存中的脏页往硬盘上刷？ §\n\nredo log 满\na. \nb. 把绿色部分的日志对应的所有脏页都 flush 到磁盘上\nc. 之后，write pos 到 cp’ 之间是可以再写入的 redo log 的区域\n当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘\n\n不直接把内存淘汰掉，下次需求请求的时候从磁盘读入数据页，然后拿 redo log 出来应用的原因：为了保证每个数据页有两种状态\n\n内存里存在，内存里肯定是正确的结果，直接返回；\n内存里没有数据，可以肯定数据文件上是正确的结果，读入内存后返回。\n\n\n\n\nMySQL 认为系统“空闲”的时候会刷，忙的时候也会找机会刷\n正常关闭数据库时，会把内存的脏页都 flush 到磁盘上，下次启动时直接从磁盘读数据，启动速度快\n\n\n第 2 种情况是常态\n\nInnoDB 用缓冲池管理内存，缓冲池中的内存页有三种状态\n\n还没有使用：很少\n使用了并且是干净页\n使用了并且是脏页。\n\n\n\n\n当要读入的数据页没有在内存的时候，必须到缓冲池申请一个数据页\n\n把最久不使用的数据页从内存中淘汰掉\n影响性能的情况\n\n一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；\n日志写满，更新全部堵住，写性能跌为 0\n\n\n\n\nInnoDB 刷脏页的控制策略\n\ninnodb_io_capacity\n\n建议设置成磁盘的 IOPS\n通过 fio 工具测试 IOPS\n\nfio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest\n\n\n\n\nInnoDB 刷盘速度主要参考两个因素\n\n脏页比例\n\ninnodb_max_dirty_pages_pct 脏页比例，默认值 75%\n平时多关注脏页比例，不要让它经常接近 75%\n脏页比例通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到，具体的命令参考下面的代码\n\nmysql&gt; select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = &#039;Innodb_buffer_pool_pages_dirty&#039;;select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = &#039;Innodb_buffer_pool_pages_total&#039;;select @a/@b;\n\n\nInnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样\n\n伪代码\n\nF1(M){ if M&gt;=innodb_max_dirty_pages_pct then return 100; return 100*M/innodb_max_dirty_pages_pct;}\n\n\n\n\n\n\nredo log 写盘速度\n\nInnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。\n根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。\n\n\n\n\n\n\n\n在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。\n\n使用 SSD 这类 IOPS 比较高的设备时，建议设为 0\nMySQL 8.0 中默认值为 0\n\n\n\n思考题 §\n\n一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。\n但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？\n\n每次事务提交都要写 redo log，如果设置太小，很快就会被写满，write pos 一直追着 CP\n系统不得不停止所有更新，推进 checkpoint\n现象：磁盘压力很小，但是数据库出现间歇性的性能下跌\n\n\n\n评论区 §\n\nredo log 在“重放”的时候，如果一个数据页已经刷过，会识别出来并跳过\n\n基于 LSN（log sequence number 日志序列号）\n每个数据页头部有 LSN，8 字节，每次修改都会变大。\n对比这个 LSN 跟 checkpoint 的 LSN，比 checkpoint 小的一定是干净页\n\n\n将脏页 flush 到磁盘上是直接将脏页数据覆盖到对应磁盘上的数据\n断电重启后从 checkpoint 的位置往后扫，已经扫过盘的不会重复应用 redo log\n名词解释\n\nplush：刷脏页\npurge：清 undo log\nmerge：应用 change buffer\n\nchange buffer 只对非唯一索引有效\n\n\n\n\n常见的误用场景\n\n很多测试人员在做压力测试的时候 出现刚开始 insert update 很快 一会 就出现很慢,并且延迟很大，大部分是因为 redo log 设置太小（跟上面思考题相同原理）\n\n\n"},"12｜有一亿个-keys-要统计，应该用哪种集合？":{"title":"12｜有一亿个 keys 要统计，应该用哪种集合？","links":[],"tags":["Redis"],"content":"数据类型汇总表格 §\n\n\n\n聚合统计 §\n\n\n统计多个集合元素的聚合结果，包括：\n\n统计多个集合的共有元素（交集统计）\n把两个集合相比，统计其中一个集合独有的元素（差集统计）\n统计多个集合的所有元素（并集统计）\n\n\n\n使用 Set\n\n并集：SUNIONSTORE user:new user:id user:id:20200803\n差集：SDIFFSTORE user:new user:id:20200804 user:id\n交集：SINTERSTORE user:id:rem user:id:20200803 user:id:20200804\n计算复杂度较高，数据量较大时会导致 Redis 实例阻塞\n三个命令都会生成新 key，但从库一般是 readonly（不建议开写），想在从库操作需使用 SUNION、SDIFF、SINTER，这些命令可以计算出结果，但不会生成新 key\n可以从主从集群中选择一个从库专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了\n\n\n\n排序统计 §\n\n使用有序集合：List、Sorted Set\nList 是按照元素进入 List 的顺序进行排序，而 Sorted Set 可以根据元素的权重来排序\n数据更新频繁或需要分页显示，优先考虑使用 Sorted Set\n\n二值状态统计 §\n\n\n指集合元素的取值就只有 0 和 1 两种\n\n\nBitmap\n\n\n对多个以日期为 key，位值为每个学生签到情况的 Bitmap，执行按位与操作可以统计出连续签到的学生数量\n\n\n\n\n\n亦或者 uid:sign:3000:202008 2 1 可以统计学生在某段时间的签到情况\n\n\n优势：节省内存空间\n\n\n\n\n基数统计 §\n\n\n指统计一个集合中不重复的元素个数，如统计网页的 UV\n\n\nSet 和 Hash 消耗比较多的内存空间\n\n\nHyperLogLog\n\n用于统计基数的数据类型\n会用就行\n标准误算率：0.81%\n最大优势：即使集合元素非常多，所需空间总是固定，很小\nPFADD page1:uv user1 user2 user3\nPFCOUNT page1:uv page2:uv = 统计结果总和\n\n\n\n注意事项 §\n\n多个实例之间无法做聚合运算，可能会直接报错或者得到的结果是错误的\n统计数据与在线业务数据拆分开，实例单独部署，防止在做统计操作时影响到在线业务\n"},"13｜GEO-是什么？还可以定义新的数据类型吗？":{"title":"13｜GEO 是什么？还可以定义新的数据类型吗？","links":[],"tags":["Redis"],"content":"\n\nLBS：位置信息服务（Location-Based Service）\n\n\nGEO：数据类型\n\n\n底层数据结构：Sorted Set\n\n\nGeoHash 编码方法\n\n\n基本原理：二分区间，区间编码\n\n对经纬度分别编码，再组合\n经度范围 [-180, 180]，纬度范围 [-90, 90]\n\n\n做 N 次二分区操作，N 可以自定义\n\n\n\n\n\n\n\n根据经纬度值落在左还是右分区得到 1 位编码值\n\n\n\n\n\n重复 N 次，得到一个 N bit 的数\n\n\n\n例：116.37 =&gt; 11010\n\n\n\n\n：最终编码值的组合规则\n\n\n\n\n\n\n偶数位依次是经度的编码值\n\n\n奇数位依次是纬度的编码值\n\n\n\n\n\n\n经纬度 =&gt; Sorted Set 元素的权重分数\n\n\n\n\n\n"},"13｜为什么表数据删掉一半，表文件大小不变？":{"title":"13｜为什么表数据删掉一半，表文件大小不变？","links":[],"tags":["MySQL"],"content":"参数 innodb_file_per_table §\n\nOFF：表的数据放在系统共享表空间，跟数据字典放在一起\nON：每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中\n\n从 5.6.6 版本开始是默认值\n\n\n建议无论使用哪个版本都将这个值设置为 ON\n因为一个表单独存储为一个文件更容易管理\n在不需要这个表的时候，通过 drop table 命令可以直接删除这个文件，而如果放在共享表空间，即使表删掉了，空间也不会回收。\n下面的内容基于 ON 展开\n\n数据删除流程 §\n\n删除一行记录，InnoDB 引擎只会把这个记录标记为删除\n\n当再插入一个在被删记录位置的记录时，可能复用该位置\n\n\n如果删掉一整个数据页上的所有记录，则整个数据页可以被复用\n数据页的复用跟记录的复用不同\n\n记录的复用只限于符合范围条件的数据\n数据页的复用可以复用到任何位置\n\n\n如果相邻的两个数据页利用率都很小，系统会把两个页的数据合到其中一个页，另一个被标记为可复用\n如果用 delete 命令删除整个表的数据，则所有的数据页都会被标记为可复用，但是磁盘上文件不会变小\n\n重建表 §\n\nalter table A engine=InnoDB\n\n起到收缩表 A 的作用\n\n\n5.5 版本之前\n\n新建跟 A 结构相同的表 B，将 A 的数据按照主键 ID 递增的顺序一行行地读出来插入表 B，然后用 B 替换 A\n隐含意思：alter table t engine=innodb, ALGORITHM=copy;\n\n\n5.6 版本开始引入 Online DDL，对上面的流程做了优化\n\n\n\n\n\n\n建立一个临时文件，扫描表 A 主键的所有数据页；\n\n\n\n\n用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n\n\n\n\n生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n\n\n\n\n临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n\n\n\n\n用临时文件替换表 A 的数据文件。\n\n\n\n隐含意思：alter table t engine=innodb, ALGORITHM=inplace;\n\n\n\nDDL 之前需要拿 MDL 写锁\n\n在真正拷贝数据之前会退化成读锁\nMDL 读锁不会阻塞增删改操作\n不直接解锁的原因是为了禁止其他线程对这个表同时做 DDL\n写锁时间很短，对业务来说可以认为是 Online 的\n\n\n⚠️ 上述操作都会扫描原表数据和构建临时文件，对于大表，很消耗 IO 和 CPU 资源\n\n如果是线上服务，要小心地控制操作时间\n推荐使用 gh-ost\n\n\n\nOnline 和 Inplace §\n\n5.6 版本之后，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n\n临时文件也要占用临时空间\n\n\n关系\n\n\n\nDDL 过程如果是 Online 的，就一定是 inplace 的；\n\n\n\n\n反过来未必，inplace 的 DDL，有可能不是 Online 的。\n\n截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引（SPATIAL index）就属于这种情况\n\n\n\n\n\n\noptimize table、analyze table 和 alter table 这三种方式重建表的区别\n从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就是上面优化后的流程了；\nanalyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\noptimize table t 等于 recreate + analyze。\n\n新的表基本上统计信息是全新的，建议直接用 alter\n\n\n\n思考题 §\n\n\n\n一个表 t 文件大小为 1TB；\n\n\n\n\n对这个表执行 alter table t engine=InnoDB；\n\n\n\n\n发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。\n\n\n原因\n\n本来就很紧凑，没能整出多少剩余空间。重新收缩的过程中，页会按 90% 满的比例来重新整理页数据（10% 留给 UPDATE 使用），未整理之前页已经占用 90% 以上，收缩之后，文件就反而变大了。\n\n\n\n评论区 §\n\n既然 MySQL 支持了打包数据排序模式，能够更紧凑的分配内存进行排序，那定义表结构的时候，varchar(10) 存储 hello 和 varchar(100) 存储 hello 的优势在哪里呢？\n\n以前不支持紧凑排序的时候有，现在没啥了差别了，小于256都差不多\n\n\n"},"14｜count(*)-这么慢，我该怎么办？":{"title":"14｜count(*) 这么慢，我该怎么办？","links":[],"tags":["MySQL"],"content":"count(*) 的实现方式 §\n\nMyISAM 引擎把一个表的总行数存在磁盘上，执行时直接返回这个数\nInnoDB 引擎每次都需要把数据一行行地从引擎里面读出来，累计行数\n以上都是在说没有过滤条件的 `count(*)\ncount 是一行行读数据，是一致性读（快照读），不加锁\n\n其他计数方式 §\n\n在数据库保存计数\n\n新建一个表专门用于计数\n全部用 InnoDB 引擎\n在修改计数时使用事务\n\n\nshow table status 命令：输出结果有一个 TABLE_ROWS 用于显示这个表当前行数，执行很快，但这个结果是采样估算的（误差可能达到 40% 到 50%）\n用缓存系统保存计数\n\n比如用 Redis\n将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。\n\n两个系统间存在数据不一致的时刻\n\n\n\n\n\n不同的 Count 用法（InnoDB） §\n\ncount() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\ncount(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段） 则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n分析性能差别的时候的原则\n\nserver 层要什么就给什么；\nInnoDB 只给必要的值；\n现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。\n\ncount(主键 id)：遍历整张表，把每一行的 id 值都取出来，返回给 server 层，server 层拿到后判断是不可能为空的，就按行累加。\ncount(1)：遍历整张表，但不取值，server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\ncount(字段)\n\n如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n\n\ncount(*)：例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。\n\nMySQL 版本 &gt;= 5.5\n\n\n效率：count(*) ≈ count(1) &gt; count(主键 id) &gt; count(字段)\n\n\n\n\n\n思考题 §\n\n在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？\n\n应该先插入记录再更新计数表\n因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。\n\n\n"},"14｜如何在-Redis-中保存时间序列数据？":{"title":"14｜如何在 Redis 中保存时间序列数据？","links":[],"tags":["Redis"],"content":"\n\n要求\n\n写要快\n查询模式多\n\n\n\n一、同时使用 Hash 和 Sorted Set\n\n\n{1: a, 2: b, 3: c} + setKey: {1: a, 2: b, 3: c}\n\nHash 负责单键查询，Sorted Set 负责范围查询\n\n\n\n多个写操作的原子性\n\n\nMULTI 命令：表示一系列原子性操作的开始\n\n\n\n\n\nEXEC 命令：表示一系列原子性操作的结束\n\n\n建议客户端使用 pipeline，一次性批量发送命令给服务端，减少网络 IO 次数\n\n\n\n\n聚合计算需要借助客户端，数据量大时比较耗资源\n\n\n\n\n二、RedisTimeSeries\n\n是专门为时间序列数据访问设计的扩展模块\n支持聚合计算\n可以按标签属性过滤查询数据集合\n不属于内建功能模块，需要先把它的源码单独编译成动态链接库 redistimeseries.so，再使用 loadmodule 命令进行加载\n\n\n\n方案选择建议\n\n部署环境中网络带宽高、Redis 实例内存大，可以优先考虑第一种方案\n部署环境中，网络、内存资源有限，而且数据量大，聚合计算频繁，需要按数据集合属性查询，可以优先考虑第二种方案\n更好的选择：使用时序数据库\n\n\n\n思考题\n\n\n使用 Sorted Set 保存时序数据，把时间戳作为 score，把实际的数据作为 member，有什么潜在的风险？\n\n如果对某一个对象的时序数据记录很频繁的话，这个 key 很容易变成一个 bigkey，在 key 过期释放内存时可能引发阻塞风险\n存在 member 重复的问题\n\n\n\n如果你是 Redis 的开发维护者，你会把聚合计算也设计为 Sorted Set 的内在功能吗？\n\n不会。\n因为聚合计算是 CPU 密集型任务，Redis 在处理请求时是单线程的，也就是它在做聚合计算时无法利用到多核 CPU 来提升计算速度\n如果计算量太大，也会导致 Redis 的响应延迟变长，影响 Redis 的性能\n\n\n\n\n"},"15｜消息队列的考验：Redis-有哪些解决方案？":{"title":"15｜消息队列的考验：Redis 有哪些解决方案？","links":[],"tags":["Redis"],"content":"\n\n消息队列的三大需求：消息保序、重复消息处理、消息可靠性保证\n\n\nList\n\n支持阻塞获取数据\n不支持消费组\n\n\n\nStream\n\nRedis 5.0 之后专门为消息队列设计的数据类型\n不同消费组的消费者可以消费同一个消息\n同一消费组的消费者不消费同一消息\n自动生成全局唯一 ID\n\n\n\n两者比较\n\n\n\n\n\n⚠️ 不能丢数据的场景应该采用专业的队列中间件：Kafka + Zookeeper、RabbitMQ\n\n"},"15｜答疑文章（一）：日志和索引相关问题":{"title":"15｜答疑文章（一）：日志和索引相关问题","links":["08｜事务到底是隔离的还是不隔离的？"],"tags":["MySQL"],"content":"业务设计问题 §\n\n业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 like 表，一个是 friend 表，like 表有 user_id、liker_id 两个字段，我设置为复合唯一索引 uk_user_id_liker_id。语句执行逻辑是这样的：以 A 关注 B 为例：第一步，先查询对方有没有关注自己（B 有没有关注 A）select * from like where user_id = B and liker_id = A; 如果有，则成为好友insert into friend; 没有，则只是单向关注关系 insert into like; 但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？\n\nCREATE TABLElike(idint(11) NOT NULL AUTO_INCREMENT,user_idint(11) NOT NULL,liker_idint(11) NOT NULL, PRIMARY KEY (id), UNIQUE KEYuk_user_id_liker_id(user_id,liker_id)) ENGINE=InnoDB;CREATE TABLEfriend(idint(11) NOT NULL AUTO_INCREMENT,friend_1_idint(11) NOT NULL,friend_2_idint(11) NOT NULL, UNIQUE KEYuk_friend(friend_1_id,friend_2_id), PRIMARY KEY (id)) ENGINE=InnoDB;\n\n\n首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值 1、2、3。值是 1 的时候，表示 user_id 关注 liker_id；值是 2 的时候，表示 liker_id 关注 user_id；值是 3 的时候，表示互相关注。\n然后，当 A 关注 B 的时候，逻辑改成如下所示的样子：应用代码里面，比较 A 和 B 的大小，如果 A &lt; B，就执行下面的逻辑\n\nmysql&gt; begin; /*启动事务*/insert intolike(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;select relation_ship fromlikewhere user_id=A and liker_id=B;/*代码中判断返回的 relation_ship， 如果是1，事务结束，执行 commit 如果是3，则执行下面这两个语句： */insert ignore into friend(friend_1_id, friend_2_id) values(A,B);commit;\n\n\n如果 A &gt; B，则执行下面的逻辑\n\nmysql&gt; begin; /*启动事务*/insert intolike(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;select relation_ship fromlikewhere user_id=B and liker_id=A;/*代码中判断返回的 relation_ship， 如果是2，事务结束，执行 commit 如果是3，则执行下面这两个语句：*/insert ignore into friend(friend_1_id, friend_2_id) values(B,A);commit;\n\n\n这个设计里，让“like”表里的数据保证 user_id &lt; liker_id，这样不论是 A 关注 B，还是 B 关注 A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。然后，insert … on duplicate 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 select 判断 relation_ship 这个逻辑时就确保了是在行锁保护下的读操作。操作符 “|” 是按位或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 like 表里面有一条关于 A 和 B 的记录，而且 relation_ship 的值是 3， 并且 friend 表里面也有了 A 和 B 的这条记录。\n\n思考题 §\n\n\n创建一个简单的表 t，并插入一行，然后对这一行做修改。\n\nmysql&gt; CREATE TABLEt(idint(11) NOT NULL primary key auto_increment,aint(11) DEFAULT NULL) ENGINE=InnoDB;\ninsert into t values(1,2);\n\n\n\n假设，执行：mysql&gt; update t set a=2 where id=1;\n\n\n\n\n\n仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：\n\n\n\n更新都是先读后写的，MySQL 读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；\n\n\n\nsession B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。\n\n\n\n\nMySQL 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；\n\n\n\nsession A 的第二个 select 语句是一致性读（快照读)，它是不能看见 session B 的更新的。\n现在它返回的是 (1,3)，表示它看见了某个新的版本，这个版本只能是 session A 自己的 update 语句做更新的时候生成。所以排除选项 2。\n\n可以回顾 08｜事务到底是隔离的还是不隔离的？\n\n\n\n\n\n\nInnoDB 认真执行了“把这个值修改成 (1,2)“这个操作，该加锁的加锁，该更新的更新。\n\n\n\n\n\n\n\n\n你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步地，可以思考一下，MySQL 为什么要选择这种策略呢？\n\n验证结果都在 binlog_format=statement 格式下进行\n\n\n"},"16｜“order-by”是怎么工作的？":{"title":"16｜“order by”是怎么工作的？","links":["13｜为什么表数据删掉一半，表文件大小不变？"],"tags":["MySQL"],"content":"\n\nMySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer\n\n\nselect city,name,age from t where city=&#039;杭州&#039; order by name limit 1000;\n\n\ncity varchar 16，name varchar 16，age int 11，city 有索引\n\n\n\n初始化 sort_buffer，确定放入 name、city、age 这三个字段；\n\n\n\n\n从索引 city 找到第一个满足 city=&#039;杭州&#039; 条件的主键 id；\n\n\n\n\n到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；\n\n\n\n\n从索引 city 取下一个记录的主键 id；\n\n\n\n\n重复步骤 3、4 直到 city 的值不满足查询条件为止；\n\n\n\n\n\n对 sort_buffer 中的数据按照字段 name 做快速排序；\n\n\n\n可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\n\n\n\n\n按照排序结果取前 1000 行返回给客户端。\n\n\n\n全字段排序\n\n\n\n\n\n\n\nsort_buffer_size，是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n\n\n确定一个排序语句是否使用了临时文件\n\n\n/* 打开 optimizer_trace，只对本线程有效 */\nSET optimizer_trace=&#039;enabled=on&#039;;\n\n/* @a 保存 Innodb_rows_read 的初始值 */\nselect VARIABLE_VALUE into @a from  performance_schema.session_status where variable_name = &#039;Innodb_rows_read&#039;;\n\n/* 执行语句 */\nselect city, name,age from t where city=&#039;杭州&#039; order by name limit 1000;\n\n/* 查看 OPTIMIZER_TRACE 输出 */\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n\n/* @b 保存 Innodb_rows_read 的当前值 */\nselect VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = &#039;Innodb_rows_read&#039;;\n\n/* 计算 Innodb_rows_read 差值 */\nselect @b-@a;\n\n\n外部排序时，一般使用归并排序算法\n\n\n如果 MySQL 认为排序的单行长度太大会怎么做呢？\n\n\nmax_length_for_sort_data，在 MySQL 中控制用于排序的行数据的长度。如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\n\n如果只算 rowid 还是小于此设置，一样是 rowid 排序，但是会转用磁盘排序\n\n\n\n设置值为 16，小于前面查询语句排序的三个字段的总和\n\n\n此时因为无法直接返回了，整个执行流程变成下面的样子\n\n\n\n初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n\n\n\n\n从索引 city 找到第一个满足 city=&#039;杭州&#039; 条件的主键 id；\n\n\n\n\n到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n\n\n\n\n从索引 city 取下一个记录的主键 id；\n\n\n\n\n重复步骤 3、4 直到不满足 city=&#039;杭州&#039; 条件为止；\n\n\n\n\n对 sort_buffer 中的数据按照字段 name 进行排序；\n\n\n\n\n\n遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n\n\n\n不需要在服务端再耗费内存存储结果，直接返回给客户端\n\n\n\nrowid 排序\n\n\n\n\n\n\n\n全字段排序 VS rowid 排序\n\nMySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。\n\n\n\n如果数据天然有序，则 order by 并不需要上面的排序操作，会执行快很多\n\n比如将 city 索引改成 city + name 的联合索引\n\n\n\n如果建立三个字段的联合索引，还能省去回表过程\n\nExplain 结果的 Extra 字段如果有 Using index 则表示使用了覆盖索引\n回表的操作是随机 IO，会造成大量的随机读，不一定比全字段排序对磁盘的访问少\n\n\n\n思考题 §\n\n假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：\nmysql&gt; select * from t where city in (&#039;杭州&#039;,&quot;苏州&quot;) order by name limit 100;\n这个语句执行的时候会有排序过程吗，为什么？\n\n有，单个 city 内部的 name 才是递增的\n\n\n如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？\n\n分成两个查询语句分别查一百条，然后在业务代码中合并查询结果\n\n\n进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？\n\nselect * from t where city=&quot;杭州&quot; order by name limit 10100; select * from t where city=&quot;苏州&quot; order by name limit 10100。\n\n数据量太大时可以把 * 改写成只返回必要的数据\n\n\n\n\n\n评论区 §\n\n\nvarchar(n)，n 的值中，255 是个边界，小于等于 255 需要一个字节记录长度，超过就需要两个字节\n\n\n排序相关的内存在排序后就会被释放\n\n\n假设给一行的 a 值加 1，执行器先找引擎取行，此时已经加了写锁\n\n\n引擎内部自己调用，读取行，不加扫描行数\n\n对于 using index condition 的场景，执行器只调用了一次查询接口，回表是由存储层来完成的，所以扫描行数只算一次，即只算走索引搜索的过程中扫描的行数。\n加索引的时候，要扫描全表，但如果是inplace DDL（13｜为什么表数据删掉一半，表文件大小不变？），你会看到扫描行数是 0，也是因为这些扫描动作都是引擎内部自己调用的。\n\n\n\nUsing where 包含了一个“值比较”的过程。\n\nusing index condiction 索引下推\nusing index 索引覆盖\nusing where 代表过滤元组，可以理解为使用了 where\nusing where 和 using index一起出现代表使用了索引过滤数据\n\n\n"},"16｜异步机制：如何避免单线程模型的阻塞？":{"title":"16｜异步机制：如何避免单线程模型的阻塞？","links":[],"tags":["Redis"],"content":"\n\n4 类交互对象和具体的操作之间的关系\n\n\n\n\n\n和客户端交互时的阻塞点\n\n\n\n集合的全量查询和聚合操作\n\n\n\n\n删除 bigkey\n\n\n\n\n清空数据库\n\n\n\n\n\n和磁盘交互时的阻塞点\n\n\n\n同步写 AOF 日志\n\n\n\n\n\n主从节点交互时的阻塞点\n\n\n\n\n加载 RDB 文件\n\n\n\n从库接收 RDB 文件后会清空当前数据库\n然后加载 RDB 到内存，文件越大越慢\n\n\n\n\n\n切片集群实例交互时的阻塞点\n\n\n\n\n使用 Redis Cluster 方案，并迁移 bigkey\n\n\n\nRedis Cluster 方案使用了同步迁移\n当没有 bigkey 时，切片集群的各实例在进行交互时不会阻塞主线程\n\n\n\n\n\n可以异步操作的阻塞点：2、3、4\n\n\n如果一个操作能被异步执行，就意味着，它并不是 Redis 主线程的关键路径上的操作\n\n客户端把请求发送给 Redis 后，等着 Redis 返回数据结果的操作\n读操作是典型的关键路径操作\n\n\n\n异步的键值对删除和数据库清空操作是 Redis 4.0 后提供的功能，Redis 也提供了新的命令来执行这两个操作\n\n键值对删除：当集合类型中有大量元素（百万或千万级别）需要删除时，使用 UNLINK 命令\n清空数据库：在 FLUSHDB 和 FLUSHALL 命令后加上 ASYNC 选项\n\n\n\n小建议\n\n4.0 之前删除 bigkey：先使用集合类型提供的 SCAN 命令读取数据，然后再进行删除\n集合的全量查询和聚合操作：可以使用 SCAN 命令，分批读取数据，再在客户端进行聚合计算\n从库加载 RDB 文件：把主库的数据量大小控制在 2~4GB，以保证 RDB 文件能以较快的速度加载\n\n\n\nlazy-free（惰性删除）\n\n\n\n4.0 新增功能，默认关闭\n\n\n\n\n\n4 个控制选项\n\n\n\na) lazyfree-lazy-expire：key 在过期删除时尝试异步释放内存\nb) lazyfree-lazy-eviction：内存达到 maxmemory 并设置了淘汰策略时尝试异步释放内存\nc) lazyfree-lazy-server-del：执行 RENAME/MOVE 等命令或需要覆盖一个 key 时，删除旧 key 尝试异步释放内存\nd) replica-lazy-flush：主从全量同步，从库清空数据库时异步释放内存\n\n\n\n\n即使开启了lazy-free，如果直接使用 DEL 命令还是会同步删除 key，只有使用 UNLINK 命令才可能会异步删除 key\n\n\n\n\n最关键的一点，上面提到开启 lazy-free 的场景，除了 d）replica-lazy-flush，其他情况都只是 可能 去异步释放 key 的内存，并不是每次必定异步释放内存的\n\n\n\n真正异步释放内存的情况：与 key 的类型、编码方式、元素数量都有关系\n\na) 当 Hash/Set 底层采用哈希表存储（非 ziplist/int 编码存储）时，并且元素数量超过64个\nb) 当 ZSet 底层采用跳表存储（非 ziplist 编码存储）时，并且元素数量超过64个\nc) 当 List 链表节点数量超过 64 个（注意，不是元素数量，而是链表节点的数量，List 的实现是在每个节点包含了若干个元素的数据，这些元素采用 ziplist 存储）\n其他情况一律还是在主线程操作\n\n\n\n\n"},"17｜为什么-CPU-结构也会影响-Redis-的性能？":{"title":"17｜为什么 CPU 结构也会影响 Redis 的性能？","links":[],"tags":["Redis"],"content":"NUMA 架构（Non-Uniform Memory Access 非统一内存访问架构） §\n\n\n图\n\n\n第一步\n\n\n\n\n\n第二步\n\n\n\n\n\n\n\n文字描述\n\n\n多个 CPU 处理器（多 CPU Socket）\n\n\n每个都有自己的：\n\n\n多个物理核（包括 L1、L2 缓存）\n\n\n每个物理核私有的 L1、L2 大小受限于处理器的制造基数，KB 级别大小\n\n缓存应用程序访问最频繁的指令和数据\n\n\n\n\n\nL3 缓存\n\n多个物理核共用\n几 MB 到几十 MB 大小\n在 L1、L2 缓存中没有数据缓存时被访问，尽可能避免访问内存\n\n\n\n连接的内存\n\n\n\n\n不同处理器间通过总线连接\n\n\n\n\n\n\nCPU 架构对应用程序运行的影响 §\n\nL1、L2 缓存中的指令和数据的访问速度很快，充分利用 L1、L2 缓存，可以有效缩短应用程序的执行时间\n在 NUMA 架构下，如果应用程序从一个 Socket 上调度到另一个 Socket 上，就可能会出现远端内存访问的情况，这会直接增加应用程序的执行时间\n\nECS 主机提供的 vCPU  §\n\n虚拟核，一般对应一个物理核心上的一个超线程，这是因为底层服务器一般会开启超线程\n通常，一个物理核心会对应 2 个超线程，每个超线程对应一个 vCPU\n多个 vCPU 一般在同一个 NUMA 节点上\n如果希望减少 CPU 超线程对性能的影响，可以通过阿里云 SDK 的选项关闭超线程\n同一个物理核的逻辑核会共享使用 L1、L2 缓存\n\nCPU 多核对 Redis 性能的影响 §\n\n\n99% 尾延迟：99% 的请求延迟小于的值\n\n\ncontext switch：一个线程先在一个 CPU 核上运行，之后又切换到另一个 CPU 核上运行，这时就会发生 context switch\n\n此时 Redis 主线程的运行时信息需要被加载到另一个 CPU 核上\n\n\n\nCPU 的 NUMA 架构对 Redis 性能的影响 §\n\n\n把操作系统的网络中断处理程序和 CPU 核绑定\n\n\n网络中断处理程序\n\n操作系统内核中用来处理网卡中断事件、把数据从内核的缓冲区拷贝到应用程序缓冲区的程序。\n当网卡接收到数据后，会触发网卡中断，用来通知操作系统内核进行数据处理。\n\n\n\n避免网络中断处理程序在不同核上来回调度执行，能有效提升 Redis 的网络处理性能\n\n\n\n\n为了避免 Redis 跨 CPU Socket 访问网络数据，最好把网络中断程序和 Redis 实例绑在同一个 CPU Socket 的不同核上\n\n\n在 CPU 的 NUMA 架构下，对 CPU 核的编号规则，并不是先把一个 CPU Socket 中的所有逻辑核编完，再对下一个 CPU Socket 中的逻辑核编码，而是先给每个 CPU Socket 中每个物理核的第一个逻辑核依次编号，再给每个 CPU Socket 中的物理核的第二个逻辑核依次编号\n\n执行 lscpu 命令 查看核的编号\n\n\n\n绑核的风险和解决方案 §\n\n\n风险\n\n把 Redis 实例绑到一个 CPU 逻辑核上时，会导致子进程、后台线程和 Redis 主线程竞争 CPU 资源，一旦子进程或后台线程占用 CPU 时，主线程就会被阻塞，导致 Redis 请求延迟增加\n\n\n\n解决方案\n\n\n一个 Redis 实例对应绑一个物理核\n\n将实例绑到一个物理核上的所有逻辑核\nRedis 的主线程、子进程和后台线程可以共享使用一个物理核上的两个逻辑核，缓解 CPU 资源竞争\n\n\n\n优化 Redis 源码\n\n避免切换核带来的性能影响\n让子进程、后台线程核主线程不在同一个核上运行，避免 CPU 资源竞争\n\n\n\nRedis 6.0 之后支持 CPU 核绑定的配置操作\n\n\n\n"},"17｜如何正确地显示随机消息？":{"title":"17｜如何正确地显示随机消息？","links":[],"tags":["MySQL"],"content":"内存临时表 §\n\n\nexplain 结果中 extra 包含 Using temporary，表示需要使用临时表\n\n\nUsing filesort 表示需要执行排序操作\n\n\n比如执行 order by rand() 的时候就需要用到上面两个\n\n\n随机排序完整执行流程图\n\n\n\n\n\npos 是数据的位置信息\n\n\n\n\n对于内存表，回表过程只是简单地根据数据行的位置直接访问内存得到数据，MySQL 优化器没有多访问磁盘的顾虑，会直接选择 rowid 排序（排序的行越小越好）\n\n\n学习技巧：先通过原理分析算出扫描行数，然后再通过查看慢查询日志，来验证自己的结论\n\n\nrowid 的含义：每个引擎用来唯一标识数据行的信息\n\n对于有主键的 InnoDB 表，rowid 是主键 ID；\n对于没有主键的 InnoDB 表，rowid 是由系统生成的；\nMEMORY 引擎不是索引组织表。在这个例子里面，可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。\n\n\n\n磁盘临时表 §\n\n\ntmp_table_size 配置限制内存表的大小，默认值 16M\n\n\n如果临时表过大，就会转成磁盘临时表\n\n\n当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n\n\n对于使用磁盘临时表的 order by rand()，MySQL 5.6 版本引入了一个新的排序算法：优先队列排序算法\n \nset tmp_table_size=1024;\nset sort_buffer_size=32768;\nset max_length_for_sort_data=16;\n \n/*打开 optimizer_trace，只对本线程有效*/\nSET optimizer_trace=&#039;enabled=on&#039;;\n \n/*执行语句*/\nselect word from words order by rand() limit 3;\n \n/*查看 OPTIMIZER_TRACE 输出*/\nSELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n \n\n\n结果中，chosen 表示使用了优先队列排序算法\n\n因为没用到临时文件，所以 number_of_tmp_files 是 0\n\n\n1 对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；\n\n如果构成的堆大小超过 sort_buffer_size 的大小，只能使用归并排序算法\n\n\n2 取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n3 重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n\n\n\n不用 order by rand() 的随机排序方法（推荐）\n\n\n随机算法 1\nmysql&gt; select max(id),min(id) into @M,@N from t ;\nset @X= floor((@M-@N+1)*rand() + @N);\nselect * from t where id &gt;= @X limit 1;\n\n1 取得表的主键的最大和最小值；\n\n此操作不需要扫描索引\n\n\n2 用随机函数生成一个最大到最小值之间的数 X = (M-N)*rand() + N；\n3 取不小于 X 的第一个 ID 的行。\n\n可以用索引快速定位\n\n\n效率高，适用于 ID 严格递增的情况\n\n即没有空洞\n可以人为对数据进行处理，使数据符合条件\n\n\n\n\n\n随机算法 2\nmysql&gt; select count(*) into @C from t;\nset @Y = floor(@C * rand());\nset @sql = concat(&quot;select * from t limit &quot;, @Y, &quot;,1&quot;);\nprepare stmt from @sql;\nexecute stmt;\nDEALLOCATE prepare stmt;\n\n1 取得整个表的行数，记为 C；\n2 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。\n3 再用 limit Y,1 取得一行。\n比算法 1 代价高，但还是比 order by rand() 小很多\n\n\n\n随机算法 3\nmysql&gt; select count(*) into @C from t;\nset @Y1 = floor(@C * rand());\nset @Y2 = floor(@C * rand());\nset @Y3 = floor(@C * rand());\nselect * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行\nselect * from t limit @Y2，1；\nselect * from t limit @Y3，1；\n\n\n\n\n思考题 §\n\n优化算法 3\n\n将三个 Y 排序，从小的开始查，下一个 Y 从中断的地方接着查\n也可以先取回 id 值，在应用中确定三个 id 值以后，执行三次 where id=X 的语句\n下一章给的答案\n\n取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：mysql&gt; select * from t limit N, M-N+1; 取出来后再拿到三个 Y；再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。\n\n\n\n\n\n评论区 §\n\n排序操作是在 server 层做的\n排序过程本身不增加扫描行数，扫描原表和内存表会增加\n只要 sort buffer 足够，就采用优先队列排序，而不用管到底是全字段排序还是 rowid 排序，前提是有 limit 子句\n"},"18｜为什么这些-SQL-语句逻辑相同，性能却差异巨大？":{"title":"18｜为什么这些 SQL 语句逻辑相同，性能却差异巨大？","links":[],"tags":["MySQL"],"content":"案例一：条件字段函数操作 §\n\n原语句：mysql&gt; select count(*) from tradelog where month(t_modified)=7;\n\n字段值如：2017-7-1\n\n\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能\n但是，优化器并不是要放弃使用这个索引，还可以选择遍历主键索引，也可以选择遍历索引 t_modified\n优化方案：mysql&gt; select count(*) from tradelog where    -&gt; (t_modified &gt;= &#039;2016-7-1&#039; and t_modified&lt;&#039;2016-8-1&#039;) or    -&gt; (t_modified &gt;= &#039;2017-7-1&#039; and t_modified&lt;&#039;2017-8-1&#039;) or     -&gt; (t_modified &gt;= &#039;2018-7-1&#039; and t_modified&lt;&#039;2018-8-1&#039;);\n\n案例二：隐式类型转换 §\n\nmysql&gt; select * from tradelog where tradeid=110717;\n\n相当于：mysql&gt; select * from tradelog where CAST(tradid AS signed int) = 110717;\n\n\n因为 tradeid 的字段类型是 varchar(32)，输入的参数是整形，所以该语句需要走全表扫描\n\n如果字段是整形，输入是字符串，则可以走索引\n\n\n数据类型转换的规则\n为什么有数据类型转换就需要走全索引扫描\n\n这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n\n\n\n案例三：隐式字符编码转换 §\n\n两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引\n\nutf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。\n例子：select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value;\n\n\n优化方案\n\n把两个表的字段的字符集改成 utf8mb4\n\n推荐做法\n\n\n如果表数据量太大，或者业务上暂时不能做这个 DDL 的话，只能采用修改 SQL 语句的方法\n\n\nmysql&gt; select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2;\n\n\n\n案例说明 §\n\n案例都在说同一件事：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还要做一轮判断。\n\n评论区 §\n\n表的访问顺序与连接方式、条件字段有关，跟书写顺序无关\n\n可参考《数据库索引设计与优化》第八章的表访问顺序对索引设计的影响\n\n\n先 where，再 order by，最后 limit。\n字符串都选 utf8mb4\n"},"18｜波动的响应延迟：如何应对变慢的-Redis？（上）":{"title":"18｜波动的响应延迟：如何应对变慢的 Redis？（上）","links":[],"tags":["Redis"],"content":"\n\nRedis 真的变慢了吗？\n\n\n\n\n查看 Redis 的响应延迟\n\n\n\nredis-cli —latency -h host -p port\n\n\n\n\n\n基于当前环境下的 Redis 基线性能做判断\n\n\n\n\n基线性能：一个系统在低压力、无干扰下的基本性能，这个性能只由当前的软硬件配置决定\n\n\nredis-cli 命令提供的 -intrinsic-latency 选项可以用来检测和统计测试期间的最大延迟，这个延迟可以作为基线性能\n\n要在服务器端运行，只考虑服务器端软硬件环境的影响\n\n\n\nRedis 运行时延迟是其基线性能的 2 倍及以上表示 Redis 变慢了\n\n\n\n\n\n\n如何应对 Redis 变慢？\n\n从慢查询命令开始排查，并且根据业务需求替换慢查询命令\n在客户端进行排序、交集、并集操作，不使用 SORT、SUNION、SINTER 命令，避免拖慢 Redis 实例\n排查过期 key 的时间设置，并根据实际使用需求，设置不同的过期时间，给过期时间加上随机数\n\n\n\n在 Redis 中，还有哪些其他命令可以代替 KEYS 命令，实现同样的功能呢？这些命令的复杂度会导致 Redis 变慢吗？\n\n\n使用 SCAN 命令获取整个实例所有 key\n\n\nSCAN cursorCOUNTcount\n\n一次最多返回 count 个数的 key，数量不会超过 count\n\n\n\n不会漏 key\n\nSCAN 采用高位进位法的方式遍历哈希桶，当哈希表扩容后，通过此算法遍历，旧哈希表中的数据映射到新哈希表，依旧会保留原来的先后顺序，此时不会遗漏也不会重复 key\n\n\n\n可能会返回重复的 key\n\n与 Redis 的 Rehash 机制有关，哈希表缩容时，已经遍历过的哈希表会映射到新哈希表没有遍历到的位置\n\n\n\n\n\nRedis 针对 Hash/Set/Sorted Set 提供了 HSCAN/SSCAN/ZSCAN 命令，用于遍历一个 key 中的所有元素，建议在获取一个 bigkey 的所有数据时使用，避免发生阻塞风险\n\nkey 的元素较少时，底层采用 intset/ziplist 方式存储，会无视命令的 count 参数\n\n\n\nRedis 4.0 之后可以使用异步线程机制减少主线程阻塞\n\n\n\n"},"19｜为什么我只查一行的语句，也执行这么慢？":{"title":"19｜为什么我只查一行的语句，也执行这么慢？","links":[],"tags":["MySQL"],"content":"\n有个表 t：mysql&gt; CREATE TABLEt(idint(11) NOT NULL,cint(11) DEFAULT NULL,  PRIMARY KEY (id)) ENGINE=InnoDB;\n\n第一类：查询长时间不返回 §\n等 MDL 锁 §\n\n\n使用 show processlist 命令查看 Waiting for table metadata lock 的示意图\n\n\n\n\n\n出现这个状态表示的是，现在有一个线程正在表 t 上请求或持有 MDL 写锁，把 select 语句堵住了\n\n\n简单的复现步骤\n\n\n\n\n\n处理方式：找到谁持有 MDL 写锁，kill 掉\n\n\n但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)\n\n\n通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。\n\n\n\n\n\n等 flush §\n\n\nmysql&gt; select * from information_schema.processlist where id=1;\n\n\nWaiting for table flush 状态示意图\n\n\n\n\n\n现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：\n\n\nflush tables t with read lock;\n\n\nflush tables with read lock;\n\n\n如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。\n\n\n但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。\n\n\n所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。\n\n\n\n\n排查\n\n\n图 7\n\n\n\n\n\n这个例子的排查也很简单，你看到这个 show processlist 的结果，肯定就知道应该怎么做了。\n\n\n\n\n等行锁 §\n\n\nmysql&gt; select * from t where id=1 lock in share mode;\n\n\n由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。\n\n\n\n\n\n行锁 show processlist\n\n\nsession A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。\n\n\n\nMySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到是谁占着行锁 mysql&gt; select * from t sys.innodb_lock_waits where locked_table=&#039;test.t&#039;\\G\n\n\n\n\n\n可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。\n\n\n第二类：查询慢 §\n\n在连接后执行 set long_query_time=0 可以将慢查询日志的时间阈值设置为 0\n一个例子\n\n\n800 毫秒 mysql&gt; select * from t where id=1\n\nid 上有索引\n\n\n\n0.2 毫秒 mysql&gt; select * from t where id=1 lock in share mode\n\n\n提示\n\n\n\n\n\n复现\n\n\n\n\n\n带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。\n\n\n\n\n思考题 §\n\n\nbegin;select * from t where c=5 for update;commit;\n\nc 上没索引\n\n\n\n这个语句序列是怎么加锁的呢？\n\nRR 隔离级别下，为保证 binlog 记录顺序，非索引更新会锁住全表记录，且事务结束前不会对不符合条件记录有逐步释放的过程。\n在 Read Committed 隔离级别下，会锁上聚簇索引中的所有记录；\n在 Repeatable Read 隔离级别下，会锁上聚簇索引（主键索引）中的所有记录，并且会锁上聚簇索引内的所有 GAP（间隙锁）；\n\n\n\n加的锁又是什么时候释放呢？\n\ncommit 的时候释放\n在上面两个隔离级别的情况下，如果设置了 innodb_locks_unsafe_for_binlog 开启 semi-consistent read 的话，对于不满足查询条件的记录，MySQL 会提前放锁，不过加锁的过程是不可避免的。\n\n\n"},"19｜波动的响应延迟：如何应对变慢的-Redis？（下）":{"title":"19｜波动的响应延迟：如何应对变慢的 Redis？（下）","links":["32｜Redis-主从同步与故障切换，有哪些坑？"],"tags":["Redis"],"content":"\n\n文件系统：AOF 模式\n\n\n\n\n\nAOF 重写会对磁盘进行大量 IO 操作，fsync 需要等到数据写到磁盘后才能返回\n\n\n\n\n\neverysec 时，使用后台子线程调用 fsync 写日志\n\n虽然 fsync 由后台子线程负责执行，但主线程会监控 fsync 的执行进度\n上次 fsync 未执行完时，下次 fsync 会被阻塞\n\n\n\nalways 时，主线程中调用 fsync\n\n\n\n\n避免使用操作系统的 swap\n\n\n增加机器的内存\n\n\n使用 Redis 集群\n\n\n查看 Redis 进程的 swap 使用情况\n\n\n\nredis-cli info | grep process_id\n\n\n\n\ncd /proc/{process_id}\n\n\n\n\ncat smaps | egrep ’^(Swap|Size)’\n\n\n\n\n\n\n\n操作系统：内存大页\n\n\n写时复制：一旦数据要被修改，Redis 不会直接修改内存中的数据，会先拷贝一份再进行修改\n\n\n常规内存机制只用拷贝 4KB，内存大页需要拷贝 2MB\n\n\n关闭即可\n\n\n\ncat /sys/kernel/mm/transparent_hugepage/enabled 查看是否 always 打开\n\n\n\n\n关闭：echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled\n\n\n\n\n\n\n\nChecklist\n\n\n\n获取 Redis 实例在当前环境下的基线性能\n\n\n\n\n是否用了慢查询命令？使用其他命令替代慢查询命令，或者把聚合计算命令放在客户端做\n\n\n\n\n是否对过期 key 设置了相同的过期时间？对于批量删除的 key，可以在每个 key 的过期时间上加一个随机数，避免同时删除\n\n\n\n\n是否存在 bigkey？ 对于 bigkey 的删除操作，如果你的 Redis 是 4.0 及以上的版本，可以直接利用异步线程机制减少主线程阻塞；如果是 Redis 4.0 以前的版本，可以使用 SCAN 命令迭代删除；对于 bigkey 的集合查询和聚合操作，可以使用 SCAN 命令在客户端完成\n\n\n\n\nRedis AOF 配置级别是什么？业务层面是否的确需要这一可靠性级别？如果我们需要高性能，同时也允许数据丢失，可以将配置项 no-appendfsync-on-rewrite 设置为 yes，避免 AOF 重写和 fsync 竞争磁盘 IO 资源，导致 Redis 延迟增加\n\n\n\n\nRedis 实例的内存使用是否过大？发生 swap 了吗？增加机器内存，或者是使用 Redis 集群，分摊单机 Redis 的键值对数量和内存压力。同时，要避免出现 Redis 和其他内存需求大的应用共享机器的情况\n\n\n\n\n在 Redis 实例的运行环境中，是否启用了透明大页机制？直接关闭内存大页机制就行了\n\n\n\n\n是否运行了 Redis 主从集群？如果是的话，把主库实例的数据量大小控制在 2~4GB，以免主从复制时，从库因加载大的 RDB 文件而阻塞\n\n\n\n\n是否使用了多核 CPU 或 NUMA 架构的机器运行 Redis 实例？使用多核 CPU 时，可以给 Redis 实例绑定物理核；使用 NUMA 架构时，注意把 Redis 实例和网络中断处理程序运行在同一个 CPU Socket 上\n\n\n\n\nRedis 所在的机器上有没有一些其他占内存、磁盘 IO 和网络 IO 的程序，比如说数据库程序或者数据采集程序。如果有的话，建议将这些程序迁移到其他机器上运行\n\n\n\n\n避免存储 bigkey，Redis 4.0+ 可开启 lazy-free 机制\n\n\n\n\n使用长连接\n\n\n\n\n\n生成 RDB 和 AOF 重写 fork 耗时严重\n\n\n\na. 实例尽量小\nb. 尽量部署在物理机上\nc. 优化备份策略\nd. 合理配置 repl-backlog 和 slave-clent-output-buffer-limit 避免全量同步\ne. 视情况关闭 AOF\nf. 监控 latest_fork_usec 耗时是否变长\n\n\n\n32｜Redis 主从同步与故障切换，有哪些坑？\n\n\n\n"},"20｜删除数据后，为什么内存占用率还是很高？":{"title":"20｜删除数据后，为什么内存占用率还是很高？","links":[],"tags":["Redis"],"content":"\n\n内存碎片\n\n\n现象：内存空间闲置\n\n\n生成原因：操作系统的内存分配机制 + Redis 的负载特征\n\n\n操作系统按固定大小分配内存，而不是完全按照应用程序申请的内存空间大小给程序分配\n\n\n当程序申请的内存最接近某个固定值时，Redis 使用的 jemalloc 会给它分配相应大小的空间\n\n为了减少分配次数\n\n\n\n\n\n判断是否有内存碎片\n\n\n\n\n执行 INFO memory\n\n\n\nused_memory_rss：操作系统实际分配的物理内存空间，包含了碎片\nused_memory：保存数据实际申请使用的空间\nmem_fragmentation_ratio：当前的内存碎片率\nmem_fragmentation_ratio = used_memory_rss / used_memory\n\n\n\n经验阈值\n\n合理情况：mem_fragmentation_ratio 大于 1 但小于 1.5\n需要采取措施：mem_fragmentation_ratio 大于 1.5\n小于 1 时在使用 Swap，应该升级服务器配置或增加集群实例数量\n\n\n\n\n\n清理\n\n\n\n\n\n暴力：重启 Redis 实例\n\n\n4.0-RC3 之后提供了内存碎片自动清理的方法\n\n“搬家让位，合并空间”\n启用：config set activedefrag yes\nactive-defrag-ignore-bytes 100mb：表示内存碎片的字节数达到 100MB 时，开始清理\nactive-defrag-threshold-lower 10：表示内存碎片空间占操作系统分配给 Redis 的总空间比例达到 10% 时，开始清理\nactive-defrag-cycle-min 25： 表示自动清理过程所用 CPU 时间的比例不低于 25%，保证清理能正常开展\nactive-defrag-cycle-max 75：表示自动清理过程所用 CPU 时间的比例不高于 75%，一旦超过，就停止清理，从而避免在清理时，大量的内存拷贝阻塞 Redis，导致响应延迟升高\n\n\n\n\n"},"20｜幻读是什么，幻读有什么问题？":{"title":"20｜幻读是什么，幻读有什么问题？","links":[],"tags":["MySQL"],"content":"\n\nInnoDB 的默认事务隔离级别是可重复读\n\n\n和下一章共用的表：\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL, \n  `c` int(11) DEFAULT NULL, \n  `d` int(11) DEFAULT NULL, \n  PRIMARY KEY (`id`), \n  KEY `c` (`c`)\n) ENGINE=InnoDB;\ninsert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n\n\n幻读 §\n\n\n幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n⚠️ 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n幻读专指“新插入的行”。\n\n\n\n原因：行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”\n\n\n幻读有什么问题？\n\n语义上被破坏，比如，假设只把所有 d = 5 的行锁住，不准别的事务进行读写操作，此时更新别的未被锁住的 d != 5 的行，让 d = 5\n数据一致性问题\n\n即使把即将要改成 d = 5 的行也锁住，还是拦不住插入 d = 5 的行\n\n\n\n\n\n解决 §\n\n\nInnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n\n\n间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。\n\n\n\n\n\n间隙锁记为开区间\n\n\n\n\n跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n\n\n间隙锁和行锁合称 next-key lock，是前开后闭区间。\n\n如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。\n\n\n\n间隙锁和 next-key lock 的引入带来的问题\n\n加大了加锁范围，降低并发度\n\n\n\n上面的讨论都是在可重复度隔离级别下的，间隙锁在此级别下才会生效\n\n\n如果改成读提交，就没有间隙锁，同时也不会有上面的问题，但同时也需要把 binlog 格式设置为 row\n\n常见的配置组合：读提交 + binlog_format=row\n\n\n\n思考题 §\n\n\n\nB 和 C 都会进入锁等待状态\n\n\n原因是什么\n\ndesc，向右扫描变成向左扫描\n前开后闭没变\n加锁范围\n\n(20, 25) (15, 20] (5, 10]\n\n\n\n\n\n评论区 §\n\nMySQL 里单引号双引号一样\n&lt;= 是间隙锁还是行锁？\n\n找第一个值是，按等值，找下一个值，按范围查找\n\n\n"},"21｜为什么我只改一行的语句，锁这么多？":{"title":"21｜为什么我只改一行的语句，锁这么多？","links":[],"tags":["MySQL"],"content":"\n\n此章节的规则有效的前提\n\n加锁策略可能改变，下面的只限于\n\n5.x 系列 &lt;= 5.7.24\n8.0 系列 &lt;= 8.0.13\n\n\n\n\n\n间隙锁在可重复读隔离级别下才有效\n\n读提交在外键场景下也有\n\n\n\n两个原则、两个优化、一个 bug\n\n原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n原则 2：查找过程中访问到的对象才会加锁。逐个加\n优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\nMySQL 8.0.18 版本已修复\n\n\n\n\n\n八个案例\n\nlock in share mode 只锁覆盖索引，而执行 for update 时，系统认为接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁；\n\n说明锁是加在索引上的\n\n\n要用 lock in share mode 给行加读锁避免数据被更新的话，必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段\n\n比如，将查询语句 select id from t where c=5; 改成 select d from t where c=5 lock in share mode;\n\n\n等价的语句加锁范围不一定相同\n\n比如等值查询和范围查询\n\n\ndelete 语句加锁的逻辑跟 select … for update 类似\n⚠️ 在删除数据的时候尽量加 limit\n\n不仅可以控制删除数据的条数，还可以减小加锁的范围\n\n\n加 next-key lock 实际上是分成来两步，先加间隙锁，然后再加行锁\n\n\n\n小结\n\n读提交隔离级别下还有一个优化：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放，不需要等到事务提交\n\n锁的范围更小，锁的时间更短\n不少业务默认使用读提交隔离级别的原因\n只对 update 有效，delete 无效\n\n\n\n\n"},"21｜缓冲区：一个可能引发“惨案”的地方":{"title":"21｜缓冲区：一个可能引发“惨案”的地方","links":[],"tags":["Redis"],"content":"\n\n客户端输入和输出缓冲区\n\n\n避免客户端和服务端的请求发送和处理速度不匹配\n\n\n输入缓冲区会先把客户端发送过来的命令暂存起来，Redis 主线程再从输入缓冲区中读取命令，进行处理。当 Redis 主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端\n\n\n\n\n\n查看输入缓冲区的内存使用情况：CLIENT LIST 命令\n\ncmd：最新执行的命令\nqbuf：输入缓冲区已经使用的大小\nqbuf-free：尚未使用的大小\n\n\n\n服务端允许为每个客户端最多暂存 1GB 的命令和数据，上限阈值在代码中设定 1GB，不可变（输入缓冲区）\n\n\n输出缓冲区会溢出的情况\n\n\n返回 bigkey 的大量结果\n\n\n执行了 MONITOR 命令：检测 Redis 执行\n\n\n缓冲区大小设置不合理\n\n大小上限阈值\n持续写入数据的数量上限阈值\n\n\n\n\n\n普通客户端通用设置 - 配置文件：client-output-buffer-limit normal 0 0 0\n\n\n订阅客户端 - 配置文件：client-output-buffer-limit pubsub 8mb 2mb 60\n\n\n\n\n主从集群中的缓冲区\n\n\n复制缓冲区的溢出问题\n\n\n\n\n\n在主节点执行：config set client-output-buffer-limit slave 512mb 128mb 60 进行设置\n\n\nslave 表示该配置项是针对复制缓冲区的\n\n\n每个从节点各一个\n\n\n\n\n复制积压缓冲区（repl_backlog_buffer）的溢出问题\n\n\n\n\n\n导致数据丢失\n\n\n其他缓冲区导致网络连接关闭\n\n\n\n\n\n\n应用程序中使用的客户端需要使用缓冲区时\n\n在 buffer 中拼装好数据，一次性由操作系统发送给服务端\n使用 Pipeline 批量发送命令到服务端\n主库上的从库输出缓冲区 slave-client-output-buffer 不计算在 Redis 使用的总内存中，不会超过 maxmemory 导致淘汰数据，只有普通和订阅客户端的输出缓冲区内存增长，超过 maxmemory 时，才会淘汰数据\n\n\n"},"22｜MySQL有哪些“饮鸩止渴”提高性能的方法？":{"title":"22｜MySQL有哪些“饮鸩止渴”提高性能的方法？","links":[],"tags":["MySQL"],"content":"短连接风暴 §\n\n\nmax_connections 参数控制一个 MySQL 实例同时存在的连接数上限\n\n超过这个数，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”\n只要连着就会计数\n\n\n\n解决方案\n\n\n一、先处理掉那些占着连接但是不工作的线程\n\n\nwait_timeout 参数设置一个线程在多少秒后会被 MySQL 直接断开连接\n\n\n在服务端执行命令：kill connection + id\n\n直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。\n\n\n\n在 show processlist 的结果里找到可以踢掉的连接\n\n\n先断开事务外空闲的连接\n\n\n还不够的情况下再考虑断开事务内空闲太久的连接\n\n\n会导致事务回滚\n\n\n查看事务具体状态\n\n\n查 information_schema 库的 innodb_trx 表\n\n\n\n\n\n\n二、减少连接过程的消耗\n\n使用 —skip-grant-tables 参数启动 MySQL，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内\n风险极高，MySQL 8.0 会默认把 —skip-networking 参数打开，表示只能被本地客户端连接\n\n\n\n\n\n慢查询性能问题 §\n\n\n\n\n索引没有设计好\n\n\n\n\nMySQL 5.6 后创建索引支持 Online DDL，对于高峰期数据库，最高效的做法是直接 alter table\n\n\n理想流程\n\n在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；\n执行主备切换；\n这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。\n\n\n\n\n\n会有大量 binlog 日志，所以需要先关闭\n\n\n⚠️ （待整理出最近方案）但是，会导致 binlog 缺少这个 DDL 语句，需要另一个知识点（主备同步协议），在后面的文章有说明\n\n\n假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样：\n\n\n在实例 X 上执行 stop slave。\n\n\n在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。\n\n\n执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。\n\n\n到实例 X 上执行以下语句序列：\n \n\n\nset GTID_NEXT=“server_uuid_of_Y:gno”;\nbegin;commit;\nset gtid_next=automatic;\nstart slave;\n```\n\n这样做的目的在于，既可以让实例 Y 的更新有 binlog 记录，同时也可以确保不会在实例 X 上执行这条更新。接下来，执行完主备切换，然后照着上述流程再执行一遍即可。\n\n\n\n\n\n更稳妥的做法是考虑类似 gh-ost 的方案\n\n\n\n\n\n\nSQL 语句没写好\n\n\n\n5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式\n查看是否重写成功\n\n\n\n\n\n\n\n\n\nMySQL 选错了索引\n\n\n\n在原语句加上 force index\n使用查询重写功能给语句加上 force index\n\n\n\n通过以下操作可以预先发现问题\n\n\n\n上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；\n\n\n\n\n在测试表里插入模拟线上的数据，做一遍回归测试；\n\n\n\n\n观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。\n\n\n\n\n\n全量测试时，使用工具检查所有的 SQL 语句的返回结果\n\n比如 pt-query-digest\n\n\n\nQPS 突增问题 §\n\n\n最理想的情况是让业务把功能下掉\n\n\n对于从数据库端处理\n\n\n\n一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。\n\n\n\n\n如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。\n\n\n\n\n\n如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成”select 1”返回。\n\n\n\na. 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；\nb. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。\n\n\n\n\n\n思考题 §\n\n\n你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？\n\n\n如果一个数据库是被客户端的压力打满导致无法响应的，重启数据库是没用的。因为重启之后，业务请求还会再发。而且由于是重启，buffer pool 被清空，可能会导致语句执行得更慢。\n\n\n有时候一个表上会出现多个单字段索引（而且往往这是因为运维工程师对索引原理不够清晰做的设计），这样就可能出现优化器选择索引合并算法的现象。但实际上，索引合并算法的效率并不好。而通过将其中的一个索引改成联合索引的方法，是一个很好的应对方案。\n\n\n客户端程序的连接器，连接完成后会做一些诸如 show columns 的操作，在短连接模式下这个影响就非常大了。\n\n这个提醒我们，在 review 项目的时候，不止要 review 我们自己业务的代码，也要 review 连接器的行为。一般做法就是在测试环境，把 general_log 打开，用业务行为触发连接，然后通过 general log 分析连接器的行为。\n\n\n\n⚠️ 如果你的数据库请求模式直接对应于客户请求，这往往是一个危险的设计。因为客户行为不可控，可能突然因为你们公司的一个运营推广，压力暴增，这样很容易把数据库打挂。在设计模型里面设计一层，专门负责管理请求和数据库服务资源，对于比较重要和大流量的业务，是一个好的设计方向。\n\n\n\n"},"22｜第-11～21-讲课后思考题答案及常见问题答疑":{"title":"22｜第 11～21 讲课后思考题答案及常见问题答疑","links":[],"tags":["Redis"],"content":"\n\n问题 1：如何使用慢查询日志和 latency monitor 排查执行慢的操作？\n\n\n\n设置 slowlog-log-slower-than：对执行时间大于多少微妙的命令进行记录\n\n\n\n\n设置 slowlog-max-len：日志最多记录多少调命令\n\n\n\n\n使用 SLOWLOG GET 命令查看慢查询日志\n\n\n\n\n\n也可以使用 latency monitor 监控工具\n\n\n\n监控 Redis 运行过程中的峰值延迟情况\n从 2.8.13 版本开始提供\n使用 latency latest查看最新和最大的超过阈值的延迟情况\n\n\n\n\n\n问题 2：如何排查 Redis 的 bigkey？\n\n\n执行 ./redis-cli —bigkeys\n\n\n对整个数据库中的键值对大小情况进行统计分析\n\n\n输出每种数据类型中最大的 bigkey 的信息\n\nString 类型的最大 bigkey 的字节长度\n集合类型的最大 bigkey 的元素个数\n\n\n\n执行时会扫描数据库，应在低峰期或者从节点使用\n\n\n使用 -i 参数控制扫描间隔，单位秒\n\n\n\n\n命令有限制\n\n只能返回每种类型最大的一个\n集合元素多不一定占用内存大\n\n\n\n自己开发统计内存占用和排在前 N 位的 key\n\n\n\n使用 SCAN 命令扫描数据库\n\n\n\n\n\nTYPE 命令获取返回的 key 的类型\n\n\n\n\nString 类型：STRLEN 获取长度\n\n\n集合类型\n\n提前知道元素平均大小 * 元素个数\nRedis 4.0+ 版本的 MEMORY USAGE 命令查询一个键值对占用的内存空间\n\n\n\n\n\n\n\n\n"},"23｜MySQL-是怎么保证数据不丢的？":{"title":"23｜MySQL 是怎么保证数据不丢的？","links":[],"tags":["MySQL"],"content":"只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。\nbinlog 的写入机制 §\n\n\n写入逻辑：事务执行过程中，先把日志写到 binlog cache，事务提交时再把 binlog cache 写到 binlog 文件。\n\n一个事务的 binlog 是要确保一次性写入，不能被打断\n系统给 binlog cache 分配了一片内存，每个线程一个，\n\n参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。\n\n\n事务提交时，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图所示。\n\n\n\n\n\n图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。\n\n\n图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。\n\n\nwrite 和 fsync 的时机，是由参数 sync_binlog 控制的：\n\n\n\nsync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；\n\n\n\n\nsync_binlog=1 的时候，表示每次提交事务都会执行 fsync；\n\n\n\n\n\nsync_binlog=N(N&gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。\n\n\n\n如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。\n\n\n\n\n\n\n\n\n\nredo log 的写入机制 §\n\n\n都先写到 redo log buffer\n\n不用每次生成后都直接持久化到磁盘\n\n如果事务执行期间 MySQL 异常重启，这部分日志丢了，由于事务并没有提交，所以没损失\n\n\n事务没提交，这时日志也有可能被持久化到磁盘\n\n\n\nredo log 的存储状态\n\n\n\n\n\n为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数\n\n\n\n设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;\n\n\n\n\n设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；\n\n\n\n\n设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。\n\n\n\n\n\nInnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。\n\n没有提交的事务的 redo log 也会\n\n\n\n另外两个会让没有提交的事务的 redo log 写入到磁盘的场景\n\n\n\nredo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。\n\n\n注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。\n\n\n\n\n并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。\n\n\n假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。\n\n\n\n\n\n通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。\n\n\n组提交机制 §\n\n\n日志逻辑序列号（log sequence number，LSN）\n\n单调递增，用来对应 redo log 的一个个写入点\n每次写入长度为 length 的 redo log， LSN 的值就会加上 length。\nLSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log\n\n\n\n一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。\n\n\n\n\n\ntrx1 先到达，会被选为 leader\n\n\n开始写盘，因为组里有了三个事务，所以 LSN 变成了最大值 160\n\n\n等到 trx1 返回时，所有 LSN 小于等于 160 的 redo log 都已经被持久化到磁盘，所以 trx2 和 trx3 可以直接返回\n\n\n\n\n在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。\n\n\n为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。\n\n\n两阶段提交\n\n\n\n\n\n两阶段提交细化\n\n\n\n\n\n写 binlog 是分成两步的\n\n\n\n先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；\n\n\n\n\n调用 fsync 持久化。\n\n\n\n\n\nMySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后\n\n\n3 执行很快，所以 binlog 的组提交效果通常不如 redo log 的效果好\n\n\n\n\n提升 binlog 组提交的效果\n\n\n\nbinlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n\n\n\n\nbinlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n\n\n两个条件是 或 的关系\n\n\n\nWAL 机制是减少磁盘写，但每次提交事务都要写 redo log 和 binlog，磁盘读写没减少？ §\n\nredo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；\n组提交机制可以大幅度降低磁盘的 IOPS 消耗。\n\nMySQL 出现 IO 性能瓶颈的提升性能方法 §\n\n\n\n设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。\n\n\n这个方法基于“额外的故意等待”来实现，因此可能会增加语句的响应时间，但没有丢失数据的风险。\n\n\n\n\n将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。\n\n\n⚠️ 这样做的风险是，主机掉电时会丢 binlog 日志。\n\n\n\n\n将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。\n\n\n不建议设置为 0（只保存在内存中）\n0 跟 2 的性能差不多，但 2 的风险更小\n\n\n\n数据库的 crash-safe 的作用 §\n\n\n\n如果客户端收到事务成功的消息，事务就一定持久化了；\n\n\n双 1 配置时\n\n\n\n\n如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；\n\n\n\n\n如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。\n\n\n\n思考题 §\n\n\n你的生产库设置的是「双 1」吗？ 如果平时是的话，你有在什么场景下改成过“非双 1”吗？你的这个操作又是基于什么决定的？\n\n\n\n业务高峰期\n\n\n\n\n备库延迟\n\n\n\n\n用备份恢复主库的副本，应用 binlog 的过程\n\n\n\n\n批量导入数据的时候\n\n\n\n\n\n我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？\n\n\n一般情况下，把生产库改成“非双 1 ”配置，是设置\n\ninnodb_flush_logs_at_trx_commit=2\nsync_binlog=1000\n\n\n\n评论区 §\n\n\n看到的「binlog 的记录」是从 page cache 读，page cache 在操作系统文件系统上\n\nls 的结果也是\n\n\n\n为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？\n\nbinlog 存储是以 statement 或者 row 格式存储的，而 redo log 是以 page 页格式存储的。page 格式，天生就是共有的，而 row 格式，只跟当前事务相关\n在这里联系到 binlog 的格式，statement 记录的是更新的 SQL，但是要写上下文，因此不能中断，不然同步到从库后从库无法恢复一样的数据内容\n\n\n\n如果 sync_binlog = N｜binlog_group_commit_sync_no_delay_count = M｜binlog_group_commit_sync_delay = 很大值，这种情况 fsync 什么时候发生\n\nsync_delay 和 sync_no_delay_count 的逻辑先走，因此该等还是会等。等到满足了这两个条件之一，就进入 sync_binlog 阶段。这时候如果判断 sync_binlog=0，就直接跳过，还是不调 fsync。\n\n\n"},"23｜旁路缓存：Redis-是如何工作的？":{"title":"23｜旁路缓存：Redis 是如何工作的？","links":[],"tags":["Redis"],"content":"\n\n旁路缓存：读取缓存、读取数据库和更新缓存的操作都需要在应用程序中完成\n\n\nRedis 适合做缓存\n\n\n\n在分层系统中，数据暂存在快速子系统中有助于加速访问\n\n\n\n\n缓存容量有限，缓存写满时，数据需要被淘汰\n\n\n\n\n\n只读缓存\n\n写操作直接作用在数据库，并删掉已缓存的数据\n适用于写请求较少或者只需要提升读请求响应速度的情况\n数据可靠，优先保证数据库和缓存的一致性\n\n\n\n读写缓存\n\n\n对写请求进行加速\n\n\n对数据可靠性要求低，或业务上不会并发修改同一个值时\n\n\n同步直写\n\n\n异步写回\n\n需要在脏数据被淘汰时，自行把数据写回数据库，Redis 无法实现这一点\n所以，使用 Redis 缓存时，不采用这个模式\n\n\n\n\n"},"24｜MySQL-是怎么保证主备一致的？":{"title":"24｜MySQL 是怎么保证主备一致的？","links":[],"tags":["MySQL"],"content":"本章的内容是所有 MySQL 高可用方案的基础\n将备库设置为只读模式（readonly） §\n\n防止误操作\n防止切换逻辑有 bug，比如切换过程中出现双写造成主备不一致\n可以用 readonly 状态判断节点的角色\nreadonly 设置对超级权限用户（super）无效，用于同步更新的线程拥有超级权限\n\n一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。（主备同步内部流程） §\n\n\n\n\n\n主备关系由备库指定\n\n\n搭建完成后由主库决定“要发数据给备库”\n\n\n一个事务日志同步的完整过程（基于长连接） §\n\n\n\n在备库 B 通过 change master 命令设置主库 A 的 IP、端口、用户名、密码，以及从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量\n\n\n\n\n在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n\n\n\n\n主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n\n\n\n\n备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\n\n\n\n\nsql_thread 读取中转日志，解析出日志里的命令，并执行。\n\n\n后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程跟本章讲的原理没有直接关系\n\n\n\nbinlog 的三种格式对比（建议设置为 row） §\n\nstatement\n\n记录 SQL 原文\n\nunsafe 的，比如一个 delete 语句，在主库跟在备库的执行结果可能不一样\n\n有些语句执行依赖上下文，比如会有 SET TIMESTAMP=时间戳 用来设置接下来的 now() 函数的返回时间\n\n\n\n\n比如带了 limit，在主备上用到了不同的索引\n⚠️ 可能导致数据不一致\n\n\nraw\n\n记录变更前和变更后的数据或被删的数据，是安全的\n很占空间\n\n\nmixed = statement + row\n\nMySQL 自己判断执行的语句应该使用哪种格式的日志\n用得不多\n\n\n\n查看 binlog §\n\n首先通过 show variables like ‘log_%’ 查看 log_bin 参数是否为 ON\n\nmysql&gt; show binary logs; 获取binlog文件列表\nmysql&gt; show binlog events; 只查看第一个binlog文件的内容\nmysql&gt; show binlog events in ‘mysql-bin.000001’; # 查看指定 binlog 文件的内容\nmysql&gt; show master status；查看当前正在写入的 binlog 文件\n\n\n需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容\n\n比如事务的 binlog 是从 8900 这个位置开始，可以用 start-position 参数来指定从这个位置的日志开始解析\n\nmysqlbinlog -vv data/master.000001 --start-position=8900;\n\n\n\n\n\n越来越多的场景要求把格式设置为 row，最直接的好处是可以恢复数据 §\n\ndelete 语句\n\n记录被删的数据\n\n\ninsert 语句\n\n把语句转成 delete 执行即可\n\n\nupdate 语句\n\nbinlog 记录修改前和修改后的整行数据\n对调两行信息再到数据库里面执行即可\n\n\nMariaDB 的 Flashback 工具基于上面的原理回滚数据\n\n前提：\n\nbinlog_format=row\nbinlog_row_image=FULL\n\n\n\n\n标准做法\n\n\n\n用 mysqlbinlog 工具解析出来\n\n\n\n\n把解析结果整个发给 MySQL 执行\n\n\n类似于：将 master.000001 文件从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行。\n\nmysqlbinlog master.000001 —start-position=2738 —stop-position=2973 | mysql -h127.0.0.1 -P13000 -uuser -ppwd;\n\n\n\n\n\n循环复制问题 §\n\n\n实际生产上使用比较多的是双 M 结构（互为主备）\n\n相比于主从，在切换时不用修改主备关系\n\n\n\n业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n\n\n解决（在某些场景下还是有可能出现死循环，看下一章）\n\n规定两个库的 server id 必须不同\n一个备库接到 binlog 并重放时，生成与原 binlog 的 server id 相同的新的 binlog\n每个库在收到从自己的主库发过来的日志后，先判断 server id\n\n\n\n思考题 §\n\n\n什么场景下会出现循环复制？\n\n\n一种场景是，在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行。\n\n\n三个 M\n\n可以通过暂时修改 server id 解决\n但出现循环复制时应该考虑是不是数据本身已经失去可靠性\n\n\n\n评论区 §\n\n\nbinlog 准备写到 binlog file 时都会先判断写入后是否超过设置的 max_binlog_size 值如果超过，rotate 自动生成下一个 binlog file 记录这条 binlog 信息\n\n一个事务的 binlog 日志不会被拆到两个 binlog 文件，所以会等到日志写完才 rotate，所以可以看到超过配置大小上限的 binlog 文件\n\n\n\n如果一张表并没有主键，插入的一条数据和这张表原有的一条数据所有字段都是一样的，然后对插入的这条数据做恢复，会不会把原有的那条数据删除？\n\n会删除一条，有可能删除到之前的那条\n因为表没有主键的时候，binlog 里面就不会记录主键字段，即：binlog 不会记录 InnoDB 隐藏的主键 id 字段\n\n\n\n如果“redo 没有及时刷盘，binlog 刷盘了”之后瞬间数据库所在主机掉电，主机重启，MySQL 重启以后，这个事务会丢失；会引起日志和数据不一致，这也是要默认设置双 1 的原因之一\n\n\n主库 ssd，备库机械硬盘，此时可以试试备库非双 1\n\n\n联表一般在业务层面进行\n\n"},"24｜替换策略：缓存满了怎么办？":{"title":"24｜替换策略：缓存满了怎么办？","links":[],"tags":["Redis"],"content":"\n\n建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销\n\nCONFIG SET maxmemory 4gb\n\n\n\n数据淘汰策略\n\n\nnoeviction（不进行数据淘汰）\n\n一旦缓存被写满，再有写请求时，Redis 不再提供服务，直接返回错误\n\n\n\n进行数据淘汰的策略\n\n\n在设置了过期时间的数据中进行淘汰\n\n\nvolatile-lru\n\n\nvolatile-random\n\n\nvolatile-ttl\n\n\nvolatile-lfu\n\nRedis 4.0 后新增\n\n\n\n\n\n在所有数据中进行淘汰\n\n\nallkeys-lru\n\n\nallkeys-random\n\n\nallkeys-lfu\n\nRedis 4.0 后新增\n\n\n\n\n\n\n\nRedis 3.0 之前默认是 volatile-lru，之后（包括 3.0）是 noeviction\n\n\n\n\nLRU（Least Recently Used）算法\n\n\n最近最少使用\n\n\n基于链表实现\n\nMRU 端：链头\nLRU 端：链尾\n\n\n\n刚被访问的和刚写入的数据移到队头，其他数据向后挪一位\n\n\nRedis 中做了简化，减轻数据淘汰对缓存性能的影响\n\n\n\n\nRedis 默认会记录每个数据的最近一次访问的时间戳\n\n\n\nRedisObject.lru\n\n\n\n\n\n决定淘汰的数据时，第一次会随机选出 N 个数据作为候选集合，比较 lru 字段，淘汰 lru 字段值最小的数据\n\n\n\n设置 N：CONFIG SET maxmemory-samples 100\n\n\n\n\n需要再次淘汰数据时，挑选数据进入第一次创建的候选集合，能进入的数据的 lru 字段值必须小于候选集合中最小的 lru 值，数据个数达到 maxmemory-samples 时把最小的数据淘汰\n\n\n\n简化后，Redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时移动链表项，提升了缓存的性能\n\n\n\n\n\n\n有明显的数据冷热区分时，优先使用 allkeys-lru 策略，可以充分利用缓存算法优势，把最近最常访问的数据留在缓存中，提升应用的访问性能\n\n\n数据访问频率相差不大，没有明显的冷热数据区分时，建议使用 allkeys-random 策略\n\n\n业务中有置顶的需求，可以使用 volatile-lru，同时不给置顶数据设置过期时间\n\n"},"25｜MySQL-是怎么保证高可用的？":{"title":"25｜MySQL 是怎么保证高可用的？","links":[],"tags":["MySQL"],"content":"\n最终一致性：正常情况下，只要主库执行更新生成的所有 binlog 都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态\n从库和备库概念上差不多，把会在「HA」过程中被选成新主库的称为备库\nHA：高可用（MySQL HA Solution）\n\n主动切换的场景 §\n\n\n主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n\n\n之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n\n很快\n\n\n\n备库 B 执行完成这个事务，我们把这个时刻记为 T3\n\n\n主备延迟 §\n\n\nT3 减 T1 的时间\n\n\n在备库执行 show slave status 命令，返回结果的 seconds_behind_master 表示当前备库延迟了多少秒\n\n\n\n每个事务的 binlog 都有一个记录主库上写入的时间的时间字段\n\n\n\n\n备库取出当前正在执行的事务的时间字段的值，计算与当前「系统时间」的差值\n\n\n计算完之后手动修改备库时间，不会自动修正\n\n\n\n\n\n备库在连接到主库的时候会通过 SELECT UNIX_TIMASTAMP() 函数获得当前主库的系统时间\n\n如果主库时间跟自己时间不一样，会在计算时自动扣掉这个差值\n\n\n\n延迟原因 §\n\n\n备库比主库所在的机器性能差\n\n这种情况可以设置备库非双 1\n\n\n\n备库压力大\n\n比如一些不适合在主库跑的大查询放在了备库上，此时压力来到备库\n可以多接几个从库分担压力\n通过 binlog 输出到外部系统，比如 Hadoop 或 es，让外部系统提供统计类查询的能力\n工具可以了解下 canal\n\n\n\n大事务\n\n如果一个语句在主库执行了 10 分钟，那在备库上也要执行很久\n\n⚠️ 不要一次性修改、删除太多数据\n\n\n大表 DDL\n\n计划内的 DDL 建议用 gh-ost 方案\n\n\n\n\n\n备库的并行复制能力（在下一篇）\n\n\n主备切换策略 §\n可靠性优先 §\n\n判断备库 B 现在的 seconds_behind_master，持续重试，如果小于某个值才进入下一步\n把主库 A 改成只读状态\n判断备库 B 的 seconds_behind_master 的值是否为 0，持续重试\n把备库 B 改成可读写状态\n把业务请求切到备库 B\n\n一般由专门的 HA 系统完成此流程\n可用性优先 §\n\n把 4、5 调整到最开始执行\n可能会出现数据不一致\n适用场景之一\n\n一个专门负责操作日志的库，数据不一致可以通过 binlog 修补，短暂的不一致也不会引发业务问题同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行\n\n\n\n思考题 §\n\n\n什么原因导致的？\n\n\n\n\n\n一种是大事务（包括大表 DDL、一个事务操作很多行）；\n\n\n还有一种情况比较隐蔽，备库起了一个长事务，比如 begin; select * from t limit 1; 然后就不动了\n\n\n\n\n怎么确认？\n\n看一下备库当前执行的命令\n\n\n"},"25｜缓存异常（上）：如何解决缓存和数据库的数据不一致问题？":{"title":"25｜缓存异常（上）：如何解决缓存和数据库的数据不一致问题？","links":[],"tags":["Redis"],"content":"\n\n数据的一致性\n\n缓存中有数据，缓存的数据值需要和数据库中的值相同\n缓存中没有数据，数据库中的值必须是最新值\n\n\n\n「读写缓存」\n\n要保证一致性可以采用同步直写策略\n适用于读写相当的业务场景\n\n\n\n「只读缓存」\n\n\n数据不一致的问题原因、现象和应对方案\n\n\n\n\n\n分为 1. 先删除缓存再更新数据库；2. 先更新数据库再删除缓存\n\n\n\n\n适用于读操作比较多的业务场景\n\n\n\n\n优先使用先更新数据库再删除缓存的方法\n\n\n\n先删除缓存可能导致请求因缓存缺失而访问数据库，给数据库带来压力\n\n\n\n\n业务应用中读取数据库和写缓存的时间不好估算，所以延迟双删的等待时间不好设置\n\n\n注意：如果要保证数据一致，可以在更新数据库的时候在 Redis 缓存客户端暂存并发读请求，等数据库更新完、缓存值删除后再读取数据\n\n\n"},"26｜备库为什么会延迟好几个小时？":{"title":"26｜备库为什么会延迟好几个小时？","links":[],"tags":["MySQL"],"content":"\n为了解决备库一直追不上更新压力较大的主库的问题\n\n多线程复制机制：将单线程 sql_thread 拆成多个线程 §\n\n\n\n\n\ncoordinator 就是原来的 sql_thread，但不再更新数据，只负责读取中转日志和分发事务真正更新日志的变成 worker 线程，个数由参数 slave_parallel_workers 决定一般设置 8～16 之间最好（32 核物理机的情况）需要留资源给读查询\n\n\n\n\n\n分发时的基本要求\n\n\n\n不会造成更新覆盖。这就要求更新同一行的两个事务必须分发到同一个 worker 中\n\n\n\n\n同一个事务不能被拆开\n\n\n\n\n\nMySQL 5.5 版本的并行复制策略 §\n\n\n官方 5.5 版本不支持并行复制\n\n下面两个策略没有被合并\n\n\n\n按表分发策略\n\n\n如果两个事务更新不同的表，就可以并行， 如果有跨表的事务就需要把两张表放在一起考虑\n\n\n按表并行复制线程模型\n\n\n\n\n\n每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。\n\n\n假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。此时事务 T 的分配规则：1. 由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。2. 按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。3. 事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。4. 每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。5. 这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。6. coordinator 继续读下一个中转日志，继续分配事务。\n\n\n每个事务在分发的时候，跟所有 worker 的冲突关系包括三种情况：\n\n\n\n如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;\n\n\n\n\n如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；\n\n\n\n\n如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n\n\n\n\n\n\n\n按行分发策略\n\n如果两个事务没有更新相同的行，它们在备库上可以并发执行\n需要同时考虑主键和唯一键\n执行 update t1 set a=1 where id=2 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项\n\nkey=hash_func(db1+t1+“PRIMARY”+2), value=2，这里 value=2 是因为修改前后的行 id 值不变，出现了两次。\nkey=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。\nkey=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。\n\n\n消耗更多的计算资源\n\n\n\n两个方案有一些约束条件\n\n\n\n要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；\n\n\n\n\n表必须有主键；\n\n\n\n\n不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n\n\n\n\n\n按行策略遇到一个语句要删除 100 万行数据类似的情况时，hash 表要记录 100 万个项，耗内存解析 binlog 计算 hash 值，对于大事务，成本很高\n\n设置阈值，单个事务如果超过设置的行数阈值，就暂时退化为单线程模式\n\ncoordinator 暂时先 hold 住这个事务；\n等待所有 worker 都执行完成，变成空队列；\ncoordinator 直接执行这个事务；\n恢复并行模式。\n\n\n\n\n\nMySQL 5.6 版本的并行复制策略 §\n\n按库并行\nhash 表的 key = 数据库名\n不要求 binlog 的格式\n\nMariaDB 的并行复制策略 §\n\n\n利用了 redo log 组提交优化（group commit）的特性\n\n\n\n能够在同一组里提交的事务，一定不会修改同一行；\n\n\n\n\n主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n\n\n\n\n实现\n\n\n\n在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id + 1；\n\n\n\n\ncommit_id 直接写到 binlog 里面；\n\n\n\n\n传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；\n\n\n\n\n这一组全部执行完成后，coordinator 再去取下一批。\n\n\n\n\n\n之前的思路：分析 binlog，并拆分到 worker 上，MariaDB 的策略：模拟主库的并行模式\n\n\n但是没有实现“真正的模拟主库并发度”目标主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的\n\n\nMySQL 5.7 的并行复制策略 §\n\n\n由参数 slave-parallel-type 控制并行复制策略\n\n\n\n配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n\n\n\n\n配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。\n\n\n同时处于“执行状态”的所有事务不可以并行因为可能由由于锁冲突而处于锁等待状态的事务\n这里的思想是：1. 同时处于 prepare 状态的事务，在备库执行时是可以并行的；2. 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n备库如何知道事务的二阶段提交状态（依赖 redo log，备库接收到的是 binlog）\n\n主库在写 binlog 的时候会给这些 binlog 里面记 commit_id 和sequence_no，来说明事务之间在主库上并行 prepare 的状态；备库是通过解析 binlog 拿到 commit_id 和 sequence_no，来决定要怎么并发的。\n\n\n\n\n\n\n\nbinlog 的组提交相关参数\n\n\n\nbinlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync；\n\n\n\n\nbinlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n\n\n用于故意拉长 binlog 从 write 到 fsync 的时间，减少 binlog 的写盘次数\n同时可以用来制造更多的“同时处于 prepare 阶段的事务”，增加备库复制的并行度\n\n\n\nMySQL 5.7.22 的并行复制策略 §\n\n\nMySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n\n\n相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n\n\n\nCOMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\n\n\n\n\nWRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\n\n\n\n\n\nWRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n\n\n基本用不到\n\n\n\n\n\n2、3 的 hash 值 = 库名 + 表名 + 索引名 + 值，如果表上除了主键索引外，还有其他唯一索引，对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值\n\n\n跟 MySQL 5.5 版本的按行分发策略差不多，但有优势\n\n\n\nwriteset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；\n\n\n\n\n不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；\n\n\n\n\n由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。\n\n\n\n\n\n对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。\n\n\n⚠️ 5.7 版本新增的备库并行策略修改了 binlog 的内容，说明 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要考虑这个因素 §\n思考题 §\n\n假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。\n这时候，你为了更快地让备库追上主库，要开并行复制。在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？你选择的原因是什么？\n\nWRITESET\n\n\n如果设置另外两个参数，你认为会出现什么现象呢？\n\nCOMMIT_ORDER：由于主库是单线程压力模式，所以每个事务的 commit_id 不同\n由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。\n\n\n\n评论区 §\n\n\n存在主从的 binlog event 写入顺序不一致的情况\n\n\n对同一行的修改会因为行锁而不能同时进入 commit 状态，所以 commit_id 不会相同\n\n\n每个事务都有两个数字表示它在执行提交阶段的时间范围，构成区间 (c1, c2)。如果两个事务的区间有交集，就是可以并行的。这里 c1 是事务启动的时候，当前系统里最大的 commit_id；一个事务提交的时候，commit_id + 1.\n\n进入 prepare 的时候就给这个事务分配 commit_id，这个 commit_id 就是当前系统最大的一个 commit_id\n\n\n\n作者回复: 我也建议尽量少使用外键\n\n这个关系应该维护在开发系统的逻辑中，放在数据库里面，比较隐蔽，容易忘记\n外键约束可能会导致有些更新失败\n外键约束（尤其是级联更新）容易出现非预期的结果\n\n\n"},"26｜缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？":{"title":"26｜缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？","links":[],"tags":["Redis"],"content":"\n\n三大问题的原因和应对方案\n\n\n\n\n\n\n\n缓存雪崩\n\n\n\n大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n\n\n\n\n缓存击穿\n\n\n\n针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。\n缓存击穿的情况，经常发生在热点数据过期失效时。\n\n\n\n\n\n缓存穿透\n\n\n\n要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。\n此时缓存成了摆设。\n同时给缓存和数据库巨大压力。\n\n\n\n\n\n尽量使用预防式方案\n\n1-1. 给缓存数据的过期时间加上小的随机数\n1-5. Redis 缓存主从集群\n2-1. 不给热点数据设置过期时间，一直保留\n3-3. 请求入口签到对请求合法性进行检查\n\n\n\nRedis 的布隆过滤器\n\n使用 String 类型实现，是一个 bigkey\n建议使用时单独部署一个实例\n直接配置参数使用即可\n4.0 提供了布隆过滤器模块，4.0 以下需要引入第三方库\n在判别数据不存在时，不存在误判，且速度非常快\n\n\n\n思考题：可以采用服务熔断、服务降级、请求限流的方法来应对缓存穿透问题吗？\n\n没必要\n\n\n三个机制是为了解决 Redis 实例没有起到缓存层作用的情况，穿透实质是查询缓存和数据库中没有的数据\n\n\n\n\n在穿透的场景下，除非人工介入，否则无论过去多久都不太可能自然恢复\n\n\n\n\n问题没有解决的同时降低了用户体验\n\n\n\n\n"},"27｜主库出问题了，从库怎么办？":{"title":"27｜主库出问题了，从库怎么办？","links":[],"tags":["MySQL"],"content":"基于位点的主备切换 §\n\n\nchange master 命令：\nCHANGE MASTER TO \nMASTER_HOST=$host_name \nMASTER_PORT=$port \nMASTER_USER=$user_name \nMASTER_PASSWORD=$password \nMASTER_LOG_FILE=$master_log_name \nMASTER_LOG_POS=$master_log_pos\n\n\n最后两个参数就是位点参数：从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步\n\n\n其中一种取同步位点的方法\n\n\n\n等待新主库把中转日志全部同步完成；\n\n\n\n\n在新主库上执行 show master status 命令，得到当前最新的 File 和 Position；\n\n\n\n\n取原主库故障的时刻 T；\n\n\n\n\n用 mysqlbinlog 工具解析新主库的 File，得到 T 时刻的位点。mysqlbinlog File —stop-datetime=T —start-datetime=T\n\n\n\n\n\n⚠️ 得到的位置不准确：比如旧主库执行完成一个 insert 语句插入数据，并且将 binlog 传给了要成为新主库的实例和从库，传完后掉电。此时，从库执行 binlog 后有了新数据，新主库可能又再次把 binlog 传过来，会报主键重复错误。\n\n\n两种解决方法\n\n\n\n\n主动跳过一个事务：set global sql_slave_skip_counter=1;start slave;\n\n\n\n此方法需要在从库刚开始连接到新主库的时候持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。\n\n\n\n\n通过设置 slave_skip_error 参数，直接设置跳过指定的错误。在执行主备切换时，经常会遇到：\n\n\na. 1062 错误，插入数据时唯一键冲突；\nb. 1032 错误，删除数据时找不到行。\n\n\n\n\n\nGTID（Global Transaction Identifier，全局事务 ID） §\n\n\nMySQL 5.6 版本引入\n\n\n一个事务在提交的时候生成的，格式：GTID=server_uuid:gno\n\nserver_uuid：实例第一次启动时自动生成，全局唯一\ngno：整数，初始值 1，每次提交事务的时候分配给这个事务，并加 1\n\n\n\n官方文档的 GTID 格式定义容易造成误解：GTID=source_id:transaction_id\n\nsource_id：server_uuid\ntransaction_id：gno\n在 MySQL 里 transaction_id 就是指事务 id，事务 id 是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，不连续递增。\n而 gno 是在事务提交的时候才会分配，连续递增。\n\n\n\n启动 GTID 模式：启动 MySQL 实例时加上参数 gtid_mode=on 和 enforce_gtid_consistency=on\n\n\n每个事务跟一个 GTID 一一对应\n\n\nGTID 两种生成方式\n\n\n\n如果 gtid_next=automatic，代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。\n\n\na. 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT=‘server_uuid:gno’;\nb. 把这个 GTID 加入本实例的 GTID 集合。\n\n\n\n\n如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next=‘current_gtid’ 指定为 current_gtid，那么就有两种可能：\n\n\na. 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；\nb. 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。\n\n\n\n\n\n每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”。\n\n\n基于 GTID 的主备切换 §\n\n\nchange master 命令：\nCHANGE MASTER TO\nMASTER_HOST=$host_name\nMASTER_PORT=$port\nMASTER_USER=$user_name\nMASTER_PASSWORD=$password\nmaster_auto_position=1\n\nmaster_auto_position=1 表示这个主备关系使用的是 GTID 协议\n\n\n\n实例 B 执行 start slave 命令，取 binlog 逻辑：\n\n建立连接\n实例 B 把 set_b 发给主库\n主库算出两个 GTID 集合的差集（所有存在于 set_a 但不存在 set_b 的 GTID 集合），判断本地是否包含差集需要的所有 binlog 事务\n\na 不包含，直接返回错误\nb 确认全部包含，从 binlog 找出第一个不在 set_b 的事务，发给 B4. 从这个事务开始往后读文件，按顺序取 binlog 发给 B 执行\n\n\n之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行\n\n\n\n取位点的工作由主库内部自动完成\n\n\n思考题 §\n\n\n你在 GTID 模式下设置主从关系的时候，从库执行 start slave 命令后，主库发现需要的 binlog 已经被删除掉了，导致主备创建不成功。这种情况下，你觉得可以怎么处理呢？\n\n\n\n如果业务允许主从不一致的情况，那么可以在主库上先执行 show global variables like &#039;gtid_purged&#039;，得到主库已经删除的 GTID 集合，假设是 gtid_purged1；然后先在从库上执行 reset master，再执行 set global gtid_purged =&#039;gtid_purged1&#039;；最后执行 start slave，就会从主库现存的 binlog 开始同步。binlog 缺失的那一部分，数据在从库上就可能会有丢失，造成主从不一致。\n\n\n\n\n如果需要主从数据一致的话，最好还是通过重新搭建从库来做。\n\n\n\n\n如果有其他的从库保留有全量的 binlog 的话，可以把新的从库先接到这个保留了全量 binlog 的从库，追上日志以后，如果有需要，再接回主库。\n\n\n\n\n如果 binlog 有备份的情况，可以先在从库上应用缺失的 binlog，然后再执行 start slave。\n\n\n\n\n\n评论区 §\n\n\n一主多从，即使采用半同步，也只能保证 binlog 至少在两台机器上，没有一个机制能够选出拥有最完整 binlog 的从库作为新的主库。\n\n直接使用MHA工具，在配置文件里面选择 candidate_master，选择使用了半同步复制的备库就行了。MHA 工具介绍\n\n\n\n如果在从库上执行了单独的操作，导致主库上缺少 GTID，那么可以在主库上模拟一个与从库 B 上 GTID 一样的空事务，这样主从同步就不会报错了。\n\n\n在 Docker 中跑 MySQL 没有问题\n\n\n慎用 reset master；等同于删数据\n\n\nMySQL 是怎么快速定位 binlog 里面的某一个 GTID 位置的？binlog 文件头部的 Previous_gtids\n\n\nsql_slave_skip_counter 跳过的是一个 event，由于 MySQL 总不能执行一半的事务，所以既然跳过了一个 event，就会跳到这个事务的末尾\n\nset global sql_slave_skip_counter=1;start slave 可以跳过整个事务。\n\n\n"},"27｜缓存被污染了，该怎么办？":{"title":"27｜缓存被污染了，该怎么办？","links":[],"tags":["Redis"],"content":"\n\n缓存污染\n\n留存在缓存中的数据，实际不会被再次访问了，但是又占据了缓存空间。\n如果这样的数据体量很大，甚至占满了缓存，每次有新数据写入缓存时，还需要把这些数据逐步淘汰出缓存，就会增加缓存操作的时间开销。\n\n\n\n解决\n\n\nvolatile-ttl 策略：设置时需明确知道数据被再次访问的情况时\n\n\nLRU 缓存策略：只看数据的访问时间，可能在对大量数据进行一次全体读取后没能及时删除缓存数据\n\n\nLFU 缓存策略\n\n在 LRU 策略基础上，为每个数据增加一个计数器，用于统计数据的访问次数\n淘汰数据时，首先根据数据的访问次数进行筛选\n如果访问次数相同，则比较两个数据的访问时效性\n\n\n\nLRU 与 LFU 实现的异同\n\nLRU 使用 24bit 大小的 lru 字段\nLFU 使用前 16bit 作为 ldt 值，表示数据的访问时间戳，后 8bit 作为 counter 值，表示数据的访问次数（最大值 255）\n\n\n\nLFU 的计数规则\n\n\n增加机制\n\n\n\n每当数据被访问一次\n\n\n\n\n用计数器当前值 * 配置项 lfu_log_factor，再加 1，再取倒数，得到一个 p 值\n\n\n\n\n把 p 值和一个取值范围再（0，1）间的随机数 r 值比大小\n\n\n\n\np 值大于 r 值时，计数器加 1\n\n\n计数器默认值为 5（由代码中的 LFU_INIT_VAL 常量设置），避免数据刚写入就被淘汰\n一般将 lfu_log_factor 设置为 10 就可以对百、千、十万级别的访问次数做明显区分\n\n\n\n衰减机制\n\n\n\n假设设置 lfu_decay_time 取值为 1\n\n\n\n\n如果数据在 N 分钟没有被访问\n\n\n\n\n访问次数减 N\n\n\n如果业务应用中有短时高频访问的数据，建议把 lfu_decay_time 设置为 1\n\n\n\n\n\n使用 LFU 策略后，缓存还会被污染，因为存在参数设置不合理的问题\n\n如设置太大导致衰减过慢\n或者一个数据只在短时间内被高频访问，也有可能滞留在缓存中\n\n\n\n\n"},"28｜Pika：如何基于-SSD-实现大容量-Redis？":{"title":"28｜Pika：如何基于 SSD 实现大容量 Redis？","links":[],"tags":["Redis"],"content":"\n\n基于大内存实现大容量 Redis 实例的潜在问题\n\n\n\n内存快照 RDB 生成和恢复效率低\n\n\n\n\n主从节点全量同步时长增加、缓冲区易溢出\n\n\n\n\n\nPika 键值数据库\n\n\n设计目标\n\n一、单实例可以保存大容量数据，同时避免实例恢复和主从同步时的潜在问题\n二、和 Redis 数据类型保持兼容，可以平滑迁移到 Pika 上\n\n\n\n整体架构\n\n\n\n\n\n\n网络框架\n\n\n\n\n\nPika 线程模块\n\n\n\n\n多线程\n\n\n\n\n\n一个请求分发线程 DispatchThread\n\n\n一组工作线程 WorkerThread\n\n\n一个线程池 ThreadPool\n\n\n\n\n\n\nNemo 存储模块\n\n\n\n\n实现 Pika 和 Redis 的数据兼容\n\n\nList\n\n\n\n\n\nSet\n\n\n\n\n\nHash\n\n\n\n\n\nSorted Set\n\n\n\n\n\n\n\n不用修改业务应用中操作 Redis 的代码\n\n\n\n\n\n\nRocksDB\n\n\n\n\nRocksDB 写入数据的基本流程\n\n\n\n\n\n基于 SSD 保存数据\n\n\n是一个持久化键值数据库\n\n\n保存数据\n\n\n使用两小块内存空间 Memtable1 和 Memtable2 交替缓存写入的数据\n\n大小可设置\nmax_write_buffer_number 控制写限速\n\n\n\n其中一块写满后，RocksDB 把数据以文件的形式快速写入底层的 SSD\n\n\n\n\n读取数据\n\n先在 Member 中查询，查询不到再到数据文件中查询\n\n\n\n避免了内存快照的生成和恢复问题\n\n\n在把数据写入 Memtable 时，也会把命令操作写到 binlog 文件中。\n\n\n\n\n\n\nbinlog 机制\n\n\n\n实现增量命令同步\n节省了内存，避免缓冲区溢出\n\n\n\n其他优势\n\n\n\n实例重启快\n\n\n\n\n主从库执行全量同步风险低，不受内存缓冲区大小的限制\n\n\n\n\n\n不足\n\n\n\n\n性能比用内存低\n\n\n\n多线程模型一定程度上弥补从 SSD 存取数据造成的性能损失\n\n\n\n\n写 binlog 时影响性能\n\n\n\n\n\n降低性能影响的建议\n\n\n\n利用 Pika 的多线程模型，增加线程数量，提升 Pika 的并发请求处理能力\n\n\n\n\n为 Pika 配置高配的 SSD，提升 SSD 自身的访问性能\n\n\n\n\n\n工具\n\n使用 aof_to_pika 命令迁移 Redis 数据到 Pika 中\nGithub｜Pika\n\n\n\n\n"},"28｜读写分离有哪些坑？":{"title":"28｜读写分离有哪些坑？","links":[],"tags":["MySQL"],"content":"\n过期读：在从库上会读到系统的一个过期状态\n\n客户端连接数据库的方式 §\n直连 §\n\n查询性能稍微好点，整体架构简单，排查问题更方便\n主备切换、库迁移等操作时，客户端会感知到，并且需要调整数据库连接信息\n一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发\n\n带 proxy 的架构 §\n\n对客户端友好，连接维护、后端信息等工作都由 proxy 完成\n对后端维护团队的要求更高，需要高可用，整体架构比较复杂\n\n强制走主库 §\n\n对于必须要拿到最新结果的请求，强制将其发到主库上\n对于可以读到旧数据的请求，才将其发到从库上\n\n判断主备无延迟方案 §\n\n每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。\n\n\nseconds_behind_master 的单位是秒，可能精度不够\n\n\n对比位点\n\n\nMaster_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。如果Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成。\n\n\n对比 GTID 集合\n\n\n\nAuto_Position=1 ，表示这对主备关系使用了 GTID 协议。Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。如果这两个集合相同，也表示备库接收到的日志都已经同步完成。\n\n\n后两种准确度更高，但还不够\n\n\n可能还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n\n\n\n\n\n配合 semi-sync（半同步复制）\b 方案 §\n\n\nsemi-sync 的设计\n\n\n\n事务提交的时候，主库把 binlog 发给从库；\n\n\n\n\n从库收到 binlog 以后，发回给主库一个 ack，表示收到了；\n\n\n3。 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。\n\n\n\n如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。\n\n\n存在问题\n\n\n\n一主多从的时候，在某些从库执行查询请求会存在过期读的现象；\n\n\n因为主库只要等到一个从库的 ack，就开始给客户端返回确认\n\n\n\n\n在持续延迟的情况下，可能出现过度等待的问题。\n\n\n如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。\n\n\n\n\n\n等主库位点方案 §\n\n\n主备持续延迟一个事务\n\n\n\n\n\n\ntrx1 事务更新完成后，客户端马上执行 show master status 得到当前主库执行到的 File 和 Position；\n\n\n\n\n选定一个从库执行查询语句；\n\n\n\n\n\n在从库上执行 select master_pos_wait(File, Position, 1)；\n\n\n\na. 参数 file 和 pos 指的是主库上的文件名和位置；\nb. timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。\n这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。等于 0：代表这个 file 和 postion 已经执行过；大于 0：代表在时间内已经执行到这个 file 和 position，并且已经执行了 n 条事务。\n\n\n\n\n如果返回值是 &gt;=0 的正整数，则在这个从库执行查询语句；\n\n\n\n\n否则，到主库执行查询语句。\n\n\n\n等 GTID 方案 §\n\n\n\n= MySQL 5.7.6\n\n\nselect wait_for_executed_gtid_set(gtid_set, 1);\n\n\n\n等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；\n\n\n\n\n超时返回 1。\n\n\n\n\n\n\ntrx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；\n\n\n将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值。\n\n\n\n\n选定一个从库执行查询语句；\n\n\n\n\n在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；\n\n\n\n\n如果返回值是 0，则在这个从库执行查询语句；\n\n\n\n\n否则，到主库执行查询语句。\n\n\n\n思考题 §\n\n\n假设你的系统采用了我们文中介绍的等 GTID 的方案，现在你要对主库的一张大表做 DDL（加减索引、增加字段在最后一列），可能会出现什么情况呢？\n\n假设，这条语句在主库上要执行 10 分钟，提交后传到备库就要 10 分钟（典型的大事务）。那么，在主库 DDL 之后再提交的事务的 GTID，去备库查的时候，就会等 10 分钟才出现。\n这样，这个读写分离机制在这 10 分钟之内都会超时，然后走主库。\n\n\n\n为了避免这种情况，你会怎么做呢？\n\n在业务低峰期，确保主库能够支持所有业务查询。把读请求都切到主库，然后在主库上做 DDL。\n等备库延迟追上以后，再把读请求切回备库。\n\n\n"},"29｜如何判断一个数据库是不是出问题了？":{"title":"29｜如何判断一个数据库是不是出问题了？","links":[],"tags":["MySQL"],"content":"\n优先考虑 update 系统表，然后再配合增加检测 performance_schema 的信息。\n\nselect 1 判断 §\n\n⚠️ 只能说明这个库的进程还在，不能说明主库没问题\nmysqladmin ping 机制也属于同一类\n\n控制并发线程上限 §\n\n建议把 innodb_thread_concurrency 设置为 64~128 之间的值\n一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。\n⚠️ 达到上限时，select 1 能正常返回\n并发连接：达到几千个影响不大，占内存而已\n并发查询：CPU 杀手\n在线程进入锁等待以后，并发线程的计数会减一\n\n查表判断 §\n\n一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行：mysql&gt; select * from mysql.health_check; \n⚠️ 空间满了之后，此方法失效，因为系统还能正常读数据\n\n更新判断 §\n\n\n常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。这条更新语句类似于：mysql&gt; update mysql.health_check set t_modified=now();\n\n⚠️ 但是主备下会出现行冲突（导致主备同步停止）\n\n\n\n为了让主备之间的更新不产生冲突，可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。表 health_check（id，t_modified）检测命令：insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();\n\n\n此方案还会有判断慢的问题\n\n⚠️ 检测命令需要的资源少，可能系统已经负载严重，但是检测还是能在超时前正常返回\n\n\n\n内部统计 §\n\n\n上面的都是外部检测\n\n\nMySQL 5.6 版本以后提供的 performance_schema 库，就在 file_summary_by_event_name 表里统计了每次 IO 请求的时间。\n\n\n打开所有的 performance_schema 项，性能会下降 10% 左右。\n\n\n打开 redo log 的时间监控\n\nmysql&gt; update setup_instruments set ENABLED=‘YES’, Timed=‘YES’ where name like ‘%wait/io/file/innodb/innodb_log_file%‘;\n\n\n\n检测方法\n\n\n\n假设单次 IO 请求时间超过 200 毫秒属于异常\n\n\n\n\n检测：mysql&gt; select event_name,MAX_TIMER_WAIT FROM performance_schema.file_summary_by_event_name where event_name in (‘wait/io/file/innodb/innodb_log_file’,‘wait/io/file/sql/binlog’) and MAX_TIMER_WAIT&gt;200*1000000000;\n\n\n\n\n清空之前的统计信息：mysql&gt; truncate table performance_schema.file_summary_by_event_name;\n\n\n\n\n\n评论区 §\n\n\n怎么之前遇到空间满，数据库都登不上，所有的连接都连不上，更不用说执行 select 语句\n\n空间满本身是不会导致连不上的。\n但是因为空间满，事务无法提交，可能会导致接下来外部事务重试，新重试的业务还是堵在提交阶段，持续累积可能会把连接数用满\n\n\n\n外部检测：检测时间点的信息内部统计：取到的是一段时间内的信息\n\n\n表 drop 列是很麻烦的，尽量不做。业务代码直接无视这个列就好\n\n"},"29｜无锁的原子操作：Redis-如何应对并发访问？":{"title":"29｜无锁的原子操作：Redis 如何应对并发访问？","links":[],"tags":["Redis"],"content":"\n\n原子操作\n\n\n单命令操作\n\n多个操作在 Redis 中实现成一个操作（如改源码）\nINCR/DECR 命令\n\n\n\n以原子性方式执行 Lua 脚本\n\nredis-cli —eval {lua.script} {keys}, {args}\n要避免把不需要做并发控制的操作写入脚本\n\n\n\n\n\n并发访问中需要控制的操作\n\n读取 - 修改 - 写回操作（RMW）\n\n\n"},"3-2-1-的有趣想法":{"title":"3-2-1 的有趣想法","links":[],"tags":["想法","思考"],"content":"内容摘抄自：https://jamesclear.com/3-2-1\n想法 §\n\n\nIf you’re searching for more time this year, start with a clean slate and choose what to add to your days rather than starting with a full schedule and trying to figure out what to eliminate.\n\n如果你今年正在寻找更多的时间，那就从一块干净的石板开始，选择在你的日子里增加什么，而不是从一个完整的时间表开始，试图找出要取消的东西。\n\n\n\nI was reviewing some old notes to myself recently and I found this one:You just need to have the courage to eliminate everything that doesn’t directly feed what you really want.\n\n我最近回顾了一些给自己的旧笔记，我发现了这一条：你只需要有勇气消除那些不能直接满足你真正想要的东西的一切。\n\n\n\nWhen something fascinates you, pay attention to the details. The person who thinks, “That was cool” is a consumer. The person who thinks, “How did they make something that cool?” is on the path to being a creator.\n\n当一件事情让你着迷时，要注意细节。认为 “这很酷 “的人是一个消费者。而认为 “他们是如何做出这么酷的东西的？“的人则是在成为创造者的道路上。\n\n\n\nDon’t just taste the recipe, look for the ingredients.”\n\n不要只是品尝食谱，要寻找其中的成分”。\n\n\n\n“You never change things by fighting the existing reality. To change something, build a new model that makes the existing model obsolete.”\n\n你永远不会通过对抗现有的现实来改变事情。要改变一些东西，就要建立一个新的模式，使现有的模式变得过时。\n\n\n\n“It doesn’t make sense to continue wanting something if you’re not willing to do what it takes to get it.\n\n“如果你不愿意做任何事情来得到它，那么继续想要它是没有意义的。\n\n\n\n“Before you throw more time at the problem, throw more focused action at the problem. You don’t need more time, you need fewer distractions.”\n\n在你花更多的时间解决问题之前，先把更多的注意力集中在问题上。你不需要更多的时间，你需要更少的干扰。\n\n\n\n“With the creative process, the key is to create a lot and edit a lot. Make more than you need, then remove everything that isn’t exceptional.”\n\n在创作过程中，关键是要大量创作，大量编辑。创作超过你的需要，然后删除一切不出众的东西。\n\n\n\n“It’s rarely doing the work that is hard, it’s starting the work. Once you begin, it’s often less painful to continue working. This is why—in the beginning—it is often more important to build the habit of getting started than it is to worry about whether or not you are doing enough.”\n\n“很少工作是困难的，难的是开始工作。一旦你开始工作，继续工作往往就不那么痛苦了。这就是为什么在开始时，养成开始工作的习惯往往比担心你是否做得够多更重要。\n\n\n\nEnvision where you are headed in great detail. Don’t talk yourself out of it. Don’t encourage yourself to be realistic. You will have to wrestle with reality soon enough. Don’t be your own bottleneck at this stage.\n\n详细地设想你要去的地方。不要劝说自己放弃。不要鼓励自己要现实一点。你将不得不很快与现实搏斗。在这个阶段，不要成为你自己的瓶颈。\n\n\n\n“It’s easier to ask forgiveness than it is to get permission.”\n\n请求宽恕比获得许可更容易。\n\n\n\n“Everything is a lesson. Learn enough lessons and the failures become useful.”\n\n每件事都是一个教训。学到足够的教训，失败就会变得有用。\n\n\n\nGreek philosopher Epicurus on desire and contentment: “Do not spoil what you have by desiring what you have not; remember that what you now have was once among the things you only hoped for.”\n\n不要因为渴望你没有的东西而破坏你所拥有的东西；记住你现在所拥有的东西曾经是你只希望得到的东西之一。\n\n\n\n“A phrase I heard recently and found useful: I agree with the idea, but I disagree with the tone. Many ideas get dismissed because they are delivered in a cocky or hostile or dismissive tone—or because of who delivers them. Separate substance from style.”\n\n我最近听到的一句话，发现很有用：我同意这个想法，但我不同意这个语气。\n许多想法被驳回是因为它们是以傲慢、敌意或轻蔑的语气提出的—或者是因为谁提出的。\n把内容和风格分开。\n\n\n\nDonella Meadows: “Remember, always, that everything you know, and everything everyone knows, is only a model. Get your model out there where it can be viewed. Invite others to challenge your assumptions and add their own.”\n\n“永远记住，你所知道的一切，以及每个人所知道的一切，都只是一个模型。把你的模型展示出来，让大家都能看到。邀请他人对你的假设提出质疑，并补充他们自己的假设”。\n\n\n\nIs what I’m about to do today connected to what I’m going to value over the long-term?\n\n我今天要做的事与我要长期重视的事有关吗？\n\n\n\n“Whoever has the most fun, wins.”\n\n“谁玩得最开心，谁就是赢家。”\n\n\n\n“If you need 10 of something, make 30. Then pick the best.”\n\n“如果你需要 10 个东西，就做 30 个。然后挑选最好的。”\n\n\n\n“Many people won’t attempt something unless they can find an example of someone else who is already doing it. Rely on this type of thinking too much and you’ll never do anything interesting.\n\n“许多人不会尝试某事，除非他们能找到其他人已经在做的例子。过分依赖这种思维方式，你永远不会做任何有趣的事情。\n\n\n\n“People usually judge you based on where you are at currently, not what you could become eventually. Don’t let one comment stop you from trying. File it away or use it as fuel. Focus on getting better. Someone else’s analysis of your current position doesn’t tell you anything about your current potential.”\n\n“人们通常根据你目前所处的位置来评判你，而不是你最终会成为什么样的人。不要让一条评论阻止你尝试。把它归档或用它作为燃料。专注于变得更好。别人对你的分析当前的职位并不能告诉你任何有关你当前潜力的信息。”\n\n\n\n“One of the great balancing acts in life is to be cautious and daring at the same time.\n\n“生活中最伟大的平衡行为之一就是同时保持谨慎和大胆。\n\n\n\nDaring enough to bet on yourself, to do the things you would regret leaving undone, and to be willing to be uncomfortable in the short term so you can learn and grow in the long term.”\n\n敢于把赌注押在自己身上，去做那些不做就会后悔的事情，愿意在短期内感到不舒服，这样你才能长期学习和成长。”\n\n\n\n“Curiosity is the beginning of knowledge. Action is the beginning of change.”\n\n“好奇心是知识的开始。行动是改变的开始。”\n\n\n\n“If you feel safe in the area that you’re working in, you’re not working in the right area. Always go a little further into the water than you feel you’re capable of being in. Go a little bit out of your depth, and when you don’t feel that your feet are quite touching the bottom, you’re just about in the right place to do something exciting.”\n\n“如果你在你工作的区域感到安全，那么你就没有在正确的区域工作。总是比你认为自己能够进入的地方更深入水中。稍微离开一点当你感觉自己的脚没有完全接触到底部时，你就处于正确的位置，可以做一些令人兴奋的事情了。”\n\n\n\n“When you’re in the middle of the work, set your expectations high. It’s unlikely your performance will exceed the standard you set for yourself. High expectations encourage you to keep reaching and fulfill your potential.\n\n“当你在工作中时，设定很高的期望。因为你的表现不太可能超过你为自己设定的标准。高期望会鼓励你不断发挥和发挥你的潜力。\n\n\n\nOnce the work is done, release yourself from your expectations. The fastest way to ruin a good outcome is to tell yourself it’s not good enough. Your expectations dictate your happiness more than your results.\n\n工作完成后，将自己从期望中释放出来。毁掉好结果的最快方法就是告诉自己这还不够好。你的期望比你的结果更能决定你的幸福。\n\n\n\nExpectations can be helpful as a motivator and unhelpful as a measuring stick. Now that the work is done you can rest easy knowing you tried your best. You’ve already won.”\n\n期望作为激励因素可能很有帮助，但作为衡量标准则无济于事。现在工作已经完成，您可以高枕无忧了，因为您知道自己已经尽力了。你已经赢了。”\n\n\n\n“Do not be too timid and squeamish about your actions. All life is an experiment. The more experiments you make the better. What if they are a little coarse, and you may get your coat soiled or torn? What if you do fail, and get fairly rolled in the dirt once or twice. Up again, you shall never be so afraid of a tumble.”\n\n“不要对你的行为太胆怯和拘谨。所有的生活都是一个实验。你做的实验越多越好。如果它们有点粗糙，你的外套可能会被弄脏或撕裂怎么办？如果你失败了怎么办，在泥土里滚一两下。再站起来，你就再也不会那么害怕摔倒了。”\n\n\n\n“One filter I use for making decisions: How much can I influence the outcome after the initial choice is made?\n\n“我用来做决定的一个过滤器：在做出最初的选择后，我能在多大程度上影响结果？\n\n\n\nWhen I can do a lot to influence the outcome, I’m less worried about risk. Even if the choice appears risky on the surface, I can likely create a good outcome with effort.\n\n当我可以做很多事情来影响结果时，我就不太担心风险。即使这个选择表面上看起来有风险，但我很可能通过努力创造出好的结果。\n\n\n\nWhen I can’t do much to influence the outcome, I’m more risk averse. Even my best effort won’t move the needle. Your ability to influence the outcome after a decision is made is a crucial thing to consider.”\n\n当我无法做太多事情来影响结果时，我会更加厌恶风险。即使我尽最大努力也无法改变现状。做出决定后影响结果的能力是需要考虑的至关重要的事情。”\n\n\n\n“When you tolerate an error, you rob yourself of learning. When you ruminate on an error, you rob yourself of happiness. Notice it, improve it, and move on from it.”\n\n“当你容忍错误时，你就失去了学习的机会。当你反复思考错误时，你就剥夺了自己的快乐。注意它，改进它，然后继续前进。”\n\n\n\n“For each headache you face, ask yourself, “Is this mostly real or mostly imagined?”\n\n“对于你遇到的每一次头痛，问问自己，“这主要是真实的还是主要是想象的？”\n\n\n\nSolve the real problems, release the imaginary ones.”\n\n解决现实问题，释放想象问题。”\n\n\n\n“Don’t worry about being the most interesting person in the room, just try to be the most interested person in the room.\n\n“不要担心成为房间里最有趣的人，只要努力成为房间里最有趣的人。\n\n\n\n思考 §\n\n\nImagine all your responsibilities and obligations vanish overnight. What would you miss doing? What would you choose to add back to your life?\n\n想象一下，你所有的责任和义务一夜之间消失了。\n你会怀念做什么？你会选择在你的生活中增加什么？\n\n\n\nWhere do I want to be in 10 years? What can I do in the next 5 minutes to contribute to that outcome?\n\n10年后我想在哪里？在接下来的5分钟内，我可以做什么来促进这一结果？”\n\n\n\nIf you could spend 30 minutes today creating whatever you want, what would you create?\n\n如果你今天可以花 30 分钟创造你想要的东西，你会创造什么？\n\n\n\nHow would my daily schedule change if I did a little more of what I’m great at and a little less of what I’m not great at?\n\n如果我多做一点我擅长的事，少做一点我不擅长的事，我的日常安排会有什么变化？\n\n\n\nWhere am I spending energy trying to please someone who actually doesn’t care?\n\n我在哪里花精力去讨好一个实际上并不关心的人呢？\n\n\n\nThis thing that I am unhappy about… is it actually hard to change or is it simply hard to have the courage to change it?\n\n我不高兴的这件事……究竟是很难改变，还是只是很难有勇气去改变？\n\n\n\nIt’s easy to find ways to improve when you are genuinely curious about something. Rather than asking yourself, “How can I be better at this?” start by asking, “How can I be more curious about this?”\n\n当你真正对某件事感到好奇时，很容易找到改进的方法。不要问自己：“我怎样才能做得更好？”首先问：“我怎样才能对此更好奇？”\n\n\n\nHow can the work you’re doing today accumulate and layer on top of what you did yesterday? Find ways to compound your efforts.\n\n你今天所做的工作如何积累并叠加在你昨天所做的事情之上？寻找方法来增强你的努力。\n\n\n\nChallenge yourself to do something out of your normal routine. What is one thing you can do this week that is different than what you do on a normal week?\n\n挑战自己，做一些不寻常的事情。这周你可以做的与平常一周不同的一件事是什么？\n\n\n\nWhich of your current habits is least aligned with the type of person you hope to become?\n\n您目前的哪些习惯最不符合您希望成为的人类型？\n\n\n\nWho are you trying to become this year? Which actions will reinforce that identity?\n\n今年你想成为谁？哪些行动会强化这种身份？\n\n\n"},"30｜如何使用-Redis-实现分布式锁？":{"title":"30｜如何使用 Redis 实现分布式锁？","links":[],"tags":["Redis"],"content":"单机版 §\n\n用一个变量表示：0 没有线程获取到锁；1 有线程获取到锁\n\n分布式锁 §\n\n锁变量需要有一个共享存储系统来维护\n如果为了效率，可以使用单节点，缺点是允许锁偶尔失效，优点是简单效率高\n业务对结果要求非常严格，为了正确性，使用 Redlock，缺点是比较重，部署成本高\n\n基于单个节点 §\n\n\n加锁\n\n\n\n\nSET lock_key unique_value NX [EX seconds | PX milliseconds]\n\n\n\nkey 不存在时会被创建\nkey 存在，不做任何赋值操作\n例：SET lock_key unique_value NX PX 10000\n\n\n\n\n加锁成功后设置有效期\n\n\n\n\n将上述操作写进 Lua 脚本作为一个原子操作\n\n\n\n\n\n释放锁\n\n\n\n\n比较锁变量的 unique_value 是否相等，避免误释放\n\n\n\nunique_value：随机值，唯一，和其他客户端作区分\n\n\n\n\n\n使用 Lua 脚本保证原子性\n\n\n\n例：redis-cli —eval unlock.script lock_key, unique_value\n\n\n\n\n\n基于多个节点（Redlock） §\n\n\nRedis 的开发者 Antirez 提出了分布式锁算法 Redlock\n\n基本思路：让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，就认为加锁成功，否则加锁失败\n需要避免机器始终发生跳跃，需要运维来保证，否则可能会导致 Redlock 失效\n通常是 5 个 Redis（都是 Master） 节点\n能不用尽量不用\n\n\n\n\n客户端获取当前时间\n\n\n\n\n\n客户端按顺序依次向 N 个 Redis 实例执行加锁操作\n\n\n\n和在单实例上执行的加锁操作一样\n设置超时时间：远远小于锁的有效时间，如几十毫秒\n\n\n\n\n\n完成和所有 Redis 实例的加锁操作后，客户端计算整个加锁过程的总耗时，满足两个条件才算成功\n\n\n\n\na. 客户端从超过半数（大于等于 N/2+1）的 Redis 实例上成功获取到了锁\n\n\nb. 客户端获取锁的总耗时没有超过锁的有效时间\n\n\n未满足条件时，向所有实例发起释放锁的操作\n\n即使是加锁失败的实例\n\n\n\n\n\n4 重新计算这把锁的有效时间：最初有效时间 - 客户端获取锁的总耗时\n\n\n\n如果锁的有效时间已经不够完成共享数据的操作，可以主动释放锁，避免没完成数据操作，锁就过期的情况\n\n\n\n相关讨论 §\n\n\n这篇文章详细介绍了争论 Redlock 算法涉及的可靠性的细节，以及 Redis 分布式锁在各种异常情况是否安全的分析，收益会非常大：http://zhangtielei.com/posts/blog-redlock-reasoning.html\n\n\n基于 ZooKeeper 的分布式锁\n\n不是唯一的实现方式\n\n\n客户端尝试创建一个 znode 节点，比如 /lock。那么第一个客户端就创建成功了，相当于拿到了锁；而其它的客户端会创建失败（znode 已存在），获取锁失败\n\n\n\n\n持有锁的客户端访问共享资源完成后，将 znode 删掉，这样其它客户端接下来就能来获取锁了\n\n\n\n\nznode 应该被创建成 ephemeral 的。这是 znode 的一个特性，它保证如果创建 znode 的那个客户端崩溃了，那么相应的 znode 会被自动删除。这保证了锁一定会被释放\n\n\nZooKeeper 一个很有用的特性是 watch 机制。这个机制可以这样来使用，比如当客户端试图创建 /lock 的时候，发现它已经存在了，这时候创建失败，但客户端不一定就此对外宣告获取锁失败。客户端可以进入一种等待状态，等待当 /lock 节点被删除的时候，ZooKeeper 通过 watch 机制通知它，这样它就可以继续完成创建操作（获取锁）。这可以让分布式锁在客户端用起来就像一个本地的锁一样：加锁失败就阻塞住，直到获取到锁为止。这样的特性 Redlock 就无法实现\n\n\n\n和 Redlock 的不同\n\n\n优点\n\n\n\n在正常情况下，客户端可以持有锁任意长的时间，这可以确保它做完所有需要的资源访问操作之后再释放锁。这避免了基于 Redis 的锁对于有效时间（lock validity time）到底设置多长的两难问题。实际上，基于 ZooKeeper 的锁是依靠 Session（心跳）来维持锁的持有状态的，而 Redis 不支持 Session\n\n\n\n\n基于 ZooKeeper 的锁支持在获取锁失败之后等待锁重新释放的事件。这让客户端对锁的使用更加灵活\n\n\n\n\n\n缺点\n\n\n\n性能不如 Redis\n\n\n\n\n\n\n\n此实现并不是最优的，会引发“herd effect”（羊群效应），降低获取锁的性能\n\n\n一个更好的实现\n\nhttp://zookeeper.apache.org/doc/r3.4.9/recipes.html#sc_recipes_Locks\n\n\n"},"30｜答疑文章（二）：用动态的观点看加锁":{"title":"30｜答疑文章（二）：用动态的观点看加锁","links":[],"tags":["MySQL"],"content":"下面的讨论基于此表\nCREATE TABLE `t` (\n  `id` int(11) NOT NULL,\n  `c` int(11) DEFAULT NULL,\n  `d` int(11) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  KEY `c` (`c`)\n) ENGINE=InnoDB;\ninsert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n\n\nshow engine innodb status 命令输出的信息中，LATESTADETECTED DEADLOCK 记录了最后一次死锁信息\n\n\n由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；\n在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。\n\n\n\n所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。\n\n\n思考题 §\n\n空表的间隙的定义\n\n一个空表只有一个间隙\n比如执行：begin; select * from t where id&gt;1 for update;\n加锁范围：next_key lock (-∞, supremum]\n\n\n\n评论区 §\n\n删除数据，导致锁扩大的描述：“因此，我们就知道了，由于 delete 操作把 id=10 这一行删掉了，原来的两个间隙 (5,10)、(10,15）变成了一个 (5,15)。”我觉得这个提到的(5, 10) 和 (10, 15)两个间隙会让人有点误解，实际上在删除之前间隙锁只有一个(10, 15)，删除了数据之后，导致间隙锁左侧扩张成了5，间隙锁成为了(5, 15)。\n"},"31｜事务机制｜Redis-能实现-ACID-属性吗？":{"title":"31｜事务机制｜Redis 能实现 ACID 属性吗？","links":[],"tags":["Redis"],"content":"事务命令 §\n\nMULTI：开启一个事务\nEXEC：提交事务，从命令队列中去除提交的操作命令，进行实际执行\nDISCARD：放弃一个事务，清空命令队列\n\n只是清空，起不到回滚的作用\n\n\nWATCH：检测一个或多个键的值在事务执行期间是否发生变化，如果发生变化，那么当前事务放弃执行\n\n\n\n\n\nRedis 的事务机制 §\n\n可以保证一致性和隔离性，无法保证持久性（非必要）\n原子性\n\n\n命令语法有误时，得不到保证\n\n不存在的命令一开始就会被记录错误\n无法得到保证的原因：命令和操作的数据类型不匹配，但 Redis 实例没检查出错误并开始执行\n预防建议：严格按照 Redis 的命令规范进行程序开发，并且通过 code review 确保命令的正确性\n\n\n\n实例发生故障，且 Redis 使用了 RDB 机制\n\nRDB 不会在事务执行时执行，也就不会记录下事务执行了一部分的结果\n存在一种情况无法保证原子性：如果事务执行完成，还没执行 RDB 快照，此时发生故障，会丢失事务修改的数据\n\n\n\n其他情况，事务都可以原子性执行\n\n前提：执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败\n开启 AOF 日志\n\n只会有部分的事务操作被记录到 AOF 日志中\n使用 redis-check-aof 工具检查 AOF 日志文件\n工具会把未完成的事务操作从 AOF 日志中去除\n这时再使用 AOF 恢复实例，失败的事务操作不会再被执行\n\n\n\n\n\n\n\n事务使用建议 §\n\n配合 Pipeline 使用\n\n隔离性由服务端保证，此时不需要使用 WATCH\n\n\nWATCH 的使用场景\n\nWATCH key，读取 key，修改 key，写回\n\n\n"},"31｜误删数据后除了跑路，还能怎么办？":{"title":"31｜误删数据后除了跑路，还能怎么办？","links":[],"tags":["MySQL"],"content":"多种情况 §\n\n使用 delete 语句误删数据行；\n使用 drop table 或者 truncate table 语句误删数据表；\n使用 drop database 语句误删数据库；\n使用 rm 命令误删整个 MySQL 实例。\n\n误删行 §\n\n恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。\n预防：把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。\ndelete 全表很慢，应该优先考虑使用 truncate table 或者 drop table 命令\n\n误删库/表 §\n\n\n即使配置了 binlog_format=row，记录的还是 statement 格式，binlog 只有一个 truncate/drop 语句，不足以恢复数据\n\n\n恢复方法：使用全量备份 + 增量日志的方式\n\n\n\n加速数据恢复：使用 mysqlbinlog 命令时加上 -database 参数指定误删表所在的库\n\n\n\n\n应用日志时跳过误操作的语句的 binlog\n\n\n\n\n如果原实例没有使用 GTID 模式，只能在应用到包含错误语句的 binlog 文件时，先用 -stop-position 参数执行到误操作之前的日志，再用 -start-position 从误操作之后的日志继续执行\n\n\n\n\n如果实例使用了 GTID 模式，假设误操作命令的 GTID 时 gtid1，执行 set gtid_next=gtid1; begin; commit; 把这个 GTID 加到临时实例的 GTID 集合，之后顺序执行 binlog 的时候会自动跳过误操作的语句\n\n\n\n\n\n上述使用 mysqlbinlog 方法恢复数据不够快\n\n\n\nmysqlbinlog 不能指定只解析一个表的日志\n\n\n\n\n单线程\n\n\n\n\n\n加速方法之一：在用备份恢复出临时实例之后，把实例设置成线上备库的从库\n\n\n\n在 start slave 之前，先通过执行 change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表；\n\n\n\n\n这样做也可以用上并行复制技术，来加速整个数据恢复过程。\n\n\n如果备库上没有日志的话，从备份中下载恢复\n\n\n\n\n\n\n\n建议把上述恢复功能做成自动化工具，并且经常拿出来演练\n\n\n延迟复制备库 §\n\nMySQL 5.6 引入\n延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。\n备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。\n随时可以得到一个，只需要最多再追 n 秒，就可以恢复出数据的临时实例，也就缩短了整个数据恢复需要的时间。\n\n预防误删库/表的方法 §\n\n第一条建议是，账号分离。这样做的目的是，避免写错命令。\n第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。\n\n\n\n在删除表之前，必须先对表做改名操作，然后观察一段时间。\n\n\n\n\n改表名时，要求给表名加固定的后缀（比如 to_be_deleted），删除表的动作必须通过管理系统执行，并且只能删除固定后缀的表\n\n\n\n\n\n评论区 §\n\n当需要把脚本发给别人时\n\n不同的浏览器浏览文件可能会截断或乱码\n可以把脚本放到 git 上，然后把 git 地址和文件的 md5 发给要执行的人\n\n\n修改生产的数据，或者添加索引优化，都要先写好四个脚本\n\n备份脚本\n执行脚本\n验证脚本\n回滚脚本\n\n\n通过 chatrr +i 命令给所有重要的文件增加了 i 权限属性，这样哪怕 root 用户都无法直接删除文件。\nrename 表：DDL，且很快\n"},"32｜Redis-主从同步与故障切换，有哪些坑？":{"title":"32｜Redis 主从同步与故障切换，有哪些坑？","links":[],"tags":["Redis"],"content":"1. 主从数据不一致 §\n\n\n因为主从数据是异步复制\n\n\na）使用外部监控程序对比主从库复制进度，不让客户端从落后的从库中读取数据\n\n\n开发一个工具：\n\n基于 INFO replication 命令查看主库接收写命令的进度信息（master_repl_offset）和从库复制写命令的进度信息（slave_repl_offset）\n比较两者大小，大于我们预设的阈值则不让客户端和此从库连接\n\n\n\n\n\nb）保证主从间的网络链接状况良好\n\n\n\n\n2. 读到过期数据 §\n\n\nRedis 同时使用两种策略删除过期的数据\n\n\n惰性删除\n\n\n当一个数据过期时间到了之后，不会立即删除数据，等到再有请求读写这个数据时，检查发现过期再删除\n\n\n好处是对于用不到的数据，不浪费时间进行检查和删除\n\n\n会导致大量已过期数据留存在内存中\n\n⚠️ 而且，从库本身不会执行删除操作，只能同步主库的删除操作，所以主库可能已经自动删除的数据，在从库还有留存\n\n\n\n\n\n定期删除\n\nRedis 每隔一段时间（默认 100ms）随机选出一定数量的数据，删除其中过期的数据\n\n\n\n\n\nRedis 3.2 之前，数据过期但未删除时，会被读取，之后的版本会检查过期，返回空值\n\n\nEXPIRE 和 PEXPIRE：给数据设置的是从命令执行时开始计算的存活时间\n\n加上主从节点执行命令的时间不一致，导致数据的过期时间不一致\n\n\n\nEXPIREAT 和 PEXPIREAT：直接把数据的过期时间设置为具体的一个时间点\n\n⚠️ 业务中使用这个\n一定要保证主从节点的时钟一致\n\n\n\n3. 不合理配置项导致服务挂掉 §\n\n\n\n\nprotected-mode\n\n\n\n设置哨兵实例能否被其他服务器访问\n当设置为 yes，而其余哨兵实例部署在其它服务器，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终 Redis 服务不可用\n⚠️ 应该设置为 no，并设置白名单\n\n\n\n\n\ncluster-node-timeout 配置不合理\n\n\n\n设置了 Redis Cluster 中实例响应心跳消息的超时时间\n调大些，例如为 10 到 20 秒\n\n\n\n4. 主从库的 mexmemory 不同 §\n\n一定要相同\n\n5. 其他建议 §\n\n\nslave-serve-stale-data 配置项设置从库能否处理数据读写命令，no 时，从库只能服务 INFO、SLAVEOF 命令，可以避免在从库中读到不一致的数据\n\n\n不要让从库可以处理写请求\n\nslave-read-only 设置为 yes，从库不能处理写请求，但还能读\n\n\n"},"32｜为什么还有-kill-不掉的语句？":{"title":"32｜为什么还有 kill 不掉的语句？","links":[],"tags":["MySQL"],"content":"两个 kill 命令 §\n\n\n\nkill query + 线程 id\n\n\n终止这个线程中正在执行的语句\n\n\n\n\nkill connection + 线程 id\n\n\nconnection 可以不写\n断开这个线程的连接\n会先停止正在执行的语句\n\n\n\n收到 kill 以后，线程做什么？ §\n\n\n告诉执行线程：这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”\n\n跟 Linux 的 kill 命令类似，kill -N pid 并不是让进程直接停止，而是给进程发一个信号，然后进程处理这个信号，进入终止逻辑。只是对于 MySQL 的 kill 命令来说，不需要传信号量参数，就只有“停止”这个命令。\n\n\n\n实现上，当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：\n\n\n\n把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；\n\n\n如果 session B 处于锁等待，并不能知道状态变化，还是会继续等待。\n\n\n\n\n给 session B 的执行线程发一个信号。\n\n\n发信号的目的：让 session B 退出等待，处理 1 设置的状态\n\n\n\n\n\nkill 无效的两类情况 §\n\n\n\n\n线程没有执行到判断线程状态的逻辑\n\n\n\n相同的还有由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态\n语句执行到能判断到线程状态已经变成了 KILL_QUERY 或者 KILL_CONNECTION 的时候，再进入终止逻辑阶段。\n如果一个线程的状态是KILL_CONNECTION，就把Command列显示成Killed。\n\n\n\n\n\n终止逻辑耗时较长\n\n\n\n\n\n超大事务执行期间被 kill，触发回滚操作\n\n\n\n\n大查询回滚，查询过程生成了比较大的临时文件 + 此时文件系统压力大 =&gt; 删除临时文件可能需要等待 IO 资源\n\n\n\n\nDDL 命令执行到最后阶段，被 kill 需要删除中间过程的临时文件，同 2\n\n\n\n\n\n客户端执行 Ctrl+C §\n\n是 MySQL 客户端另外启动一个连接发送一个 kill query 命令\n\n另外两个关于客户端的误解 §\n\n\n如果库里面的表特别多，连接就会很慢。\n\n每个客户端在和服务端建立连接的时候，需要做的事情就是 TCP 握手、用户校验、获取权限。但这几个操作，跟库里面表的个数无关。（第一章）\n我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢。\n\n客户端在连接成功后：\n\n执行 show databases\n切到 db1 库，执行 show tables\n把这两个命令的结果用于构建一个本地的哈希表（最耗时）\n\n\n如果在连接命令中加上 -A，就可以关掉这个自动补全的功能，然后客户端就可以快速返回。\n–quick 也可以跳过\n\n\n\n\n\n–quick\n\n\n是让客户端变快\n\n\nMySQL 客户端发送请求后，接收服务端返回结果的方式有两种：\n\n\n一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 mysql_store_result 方法。\n\n\n另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 mysql_use_result 方法。\n\n\n\n\n默认第一种\n\n查询的返回结果不会很多的话，都推荐用这个\n\n\n\n加上 -quick 参数后使用第二种\n\n\n\n\n采用不缓存的方式，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢\n\n\n参数效果\n\n\n\n跳过表名自动补全功能\n\n\n\n\nmysql_store_result 需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存\n\n\n\n\n不会把执行命令记录到本地的命令历史文件\n\n\n\n\n\n\n\n线程处于 Killed 状态 §\n\n可以做的事情：通过影响系统环境，让 Killed 状态尽快结束\n并发度问题，临时调大 innodb_thread_concurrency 的值或停掉别的线程，让出位子给这个线程执行\n回滚逻辑由于 IO 资源限制，通过减少系统压力让它加速\n\n思考题 §\n\n\n如果你碰到一个被 killed 的事务一直处于回滚状态，你认为是应该直接把 MySQL 进程强行重启，还是应该让它自己执行完成呢？\n\n让它自己结束\n\n\n\n为什么呢？\n\n因为重启之后该做的回滚动作不能少\n可以先做主备切换，切到新主库提供服务\n\n\n\n减少系统压力，加速终止逻辑\n\n\n评论区 §\n\n\n并非所有的 DDL 操作都可以通过主从切换来实现\n\n改索引、 加最后一列、删最后一列\n其他的大多数不行，比如删除中间一列\n\n\n\nkill 的影响只有回滚，恢复到执行前的状态，没有其他\n\n\n遇到错误时：pstack  &gt; /tmp/pstack.1\n\n"},"33｜我查这么多数据，会不会把数据库内存打爆？":{"title":"33｜我查这么多数据，会不会把数据库内存打爆？","links":[],"tags":["MySQL"],"content":"全表扫描对 server 层的影响 §\n\n\n服务端并不需要保存一个完整的结果集\n\n\n取数据和发数据的流程（边读边发）：\n\n获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。\n重复获取行，直到 net_buffer 写满，调用网络接口发出去。（发给 socket send buffer）\n如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。\n如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送\n\n\n\n\nshow processlist 结果看到 State 一直处于“Sending to client”，表示服务器端的网络栈写满了（上一节讲到的 -quick 参数就可能导致这种情况）\n\n可以考虑将 net_buffer_length 参数设置为更大的值\n等待客户端接收结果\n\n\n\n“Sending data”状态\n\n\n一个查询语句的状态变化（这里略去了其他无关的状态）：\n\nMySQL 查询语句进入执行阶段后，首先把状态设置成“Sending data”；然后，发送执行结果的列相关的信息（meta data) 给客户端；再继续执行语句的流程；执行完成后，把状态设置成空字符串。\n\n\n\n不一定是指正在发送数据，而可能是处于执行器过程中的任意阶段\n\n\n\n\n全表扫描对 InnoDB 的影响 §\n\n\n内存的数据页是在 Buffer Pool (BP) 中管理，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，加速查询。\n\n由于有 WAL 机制，当事务提交的时候，磁盘上的数据页是旧的，此时如果有一个查询要读这个数据页，并不需要把 redo log 应用到数据页。因为这时候内存数据页的结果是最新的， 直接读内存页就可以了\n\n\n\nBuffer Pool 对查询的加速效果依赖于一个重要的指标：内存命中率\n\nshow engine innodb status 结果查看\n一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。\nBuffer pool hit rate 表示命中率\nInnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定，一般建议设置成可用物理内存的 60%~80%。\n\n\n\nInnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。\n\n用链表实现\n没有改进前：遇到全表扫描时内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢\n改进的 LRU 算法\n\n\n\n\n\n靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。\n\n\n\n状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。\n\n\n\n\n之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。\n\n\n\n\n处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：\na. 若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部； \nb. 如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。\n\n\n\n\n\n\n\n评论区 §\n\n大查询常见的做法：分批取，然后每一批拿到最大的一个 id（主键值），下一批查询的时候用 where id &gt; N 这种写法\n一个大查询不会打爆，但是很多并发查询还是可能打爆\nMyISAM 跟 InnoDB 一样不会爆内存\n"},"33｜脑裂：一次奇怪的数据丢失":{"title":"33｜脑裂：一次奇怪的数据丢失","links":["19｜波动的响应延迟：如何应对变慢的-Redis？（下）"],"tags":["Redis"],"content":"脑裂 §\n\n\n指在主从集群中，同时有两个主节点，都能接收写请求\n\n\n影响：客户端不知道该往哪个主节点写入数据，结果不同客户端往不同的主节点写数据，严重的会导致数据丢失\n\n\n\n\n\n\n\n\n数据丢失排查过程 §\n\n\n\n\n确认是不是数据同步出现问题\n\n\n\n主库的数据未同步到从库且发生了故障，从库升级为主库，未同步的数据丢失\n可以通过计算 master_repl_offset 和 slave_repl_offset 的差值做判断\n\n\n\n\n\n排查客户端的操作日志，发现脑裂现象\n\n\n\n在主从切换后的一段时间内，有客户端仍然在和原主库通信，并没有和升级的新主库进行交互\n\n\n\n原主库假故障导致的脑裂 §\n\n采用哨兵机制，如果超过预设数量的哨兵实例和主库的心跳都超时，才会把主库判断为客观下限，然后哨兵开始执行主从切换，切换完成后客户端会和新主库通信\n和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如 CPU 资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常\n主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap，短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了\n\n复习下 19｜波动的响应延迟：如何应对变慢的 Redis？（下） 中总结的导致实例阻塞的原因\n\n\n\n脑裂应对方案 §\n\n\nmin-slaves-to-write：设置主库能进行数据同步的最少从库数量\n\n\nmin-slaves-max-lag：设置主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）\n\n\n搭配两个配置项，假设为 N 和 T，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求\n\n只是减少数据的丢失\n\n\n\n建议：假设从库有 K 个，将 min-slaves-to-write 设置为 K/2+1（如果 K = 1，就设为 1），将 min-slaves-max-lag 设置为十几秒（如 10～20s），在这个配置下，如果有一半以上的从库和主库进行的 ACK 消息延迟超过十几秒，我们就禁止主库接收客户端写请求\n\n"},"34｜到底可不可以使用-join-？":{"title":"34｜到底可不可以使用 join ？","links":[],"tags":["MySQL"],"content":"Index Nested-Loop Join（NLJ） §\n\n使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；\n如果使用 join 语句的话，需要让小表做驱动表\n\n前提是“可以使用被驱动表的索引”\n\n\n\nSimple Nested-Loop Join §\n\nMySQL 没有\n\nBlock Nested-Loop Join（BNL） §\n\n\n\n\n\n\n被驱动表没有索引\n\n\n\n\n\n驱动表中取出所有满足条件的数据，读入线程内存 join_buffer 中\n\n\n\n如果 join_buffer 满了，进入下一步，比较完放入结果集后，清空 join_buffer，回到这一步\njoin_buffer_size 设置 join_buffer 的大小\n\n\n\n\n\n扫描被驱动表，把每一行拿出来跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回\n\n\n\n跟 Simple xx join 一样的扫描行数\n不同的是一个是每一行都在驱动表全表扫描作比较，一个在内存比较\n\n\n\n不用分段时，选哪个表做驱动表都一样\n\n\n\n两个表都做一次全表扫描 M + N\n\n\n\n\n内存中的判断次数 M * N\n\n\n\n\n\n分段时，选择小表做驱动表\n\n驱动表 N 行，被驱动表 M 行\nN 越大，分段次数越多，M 被扫的次数越多\n调大 join_buffer_size 可以加快没用到被驱动表索引的 join 语句\n\n\n\n能不能用 join 语句？ §\n\n如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；\n判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样，有就不用\n\n选择大表还是小表做驱动表 §\n\n总是应该用“小表”\n小表：两个表按照各自的条件过滤，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。\n"},"35｜Codis-VS-Redis-Cluster：我该选择哪一个集群方案？":{"title":"35｜Codis VS Redis Cluster：我该选择哪一个集群方案？","links":[],"tags":["Redis"],"content":"Codis 集群 §\n\n\nCodis 集群的架构和关键组件图\n\n\n\n\n\ncodis server\n\n进行了二次开发的 Redis 实例，其中增加了额外的数据结构，支持数据迁移操作，主要负责处理具体的数据读写请求\n\n\n\ncodis proxy\n\n接收客户端请求，并把请求转发给 codis server\n\n\n\nZookeeper 集群\n\n\n保存集群元数据，例如数据位置信息和 codis proxy 信息\n\n\n也可以换用 etcd 或本地文件系统保存元数据信息\n\netcd 是一个分布式键值对存储\n\n\n\n\n\ncodis dashboard 和 codis fe\n\n共同组成集群管理工具\ncodis dashboard 负责执行集群管理工作，包括增删 codis server、codis proxy 和进行数据迁移\ncodis fe 负责提供 dashboard 的 Web 操作界面，便于进行集群管理\n\n\n\nCodis 处理请求 §\n\n\n\n先使用 codis dashboard 设置 codis server 和 codis proxy 的访问地址\n\n\n\n\n客户端直接和 proxy 建立连接，不用修改客户端，和访问单实例 Redis 没区别\n\n\n\n\nproxy 接收到请求，查询请求数据和 codis server 的映射关系，转给相应的 server 处理，最后通过 proxy 把数据返回给客户端\n\n\n处理流程图\n\n\n\n\n\nCodis 关键技术原理 §\n集群里的数据分布 §\n\n\n\n\n\n\n\n集群一共有 1024 个 Slot，编号依次是 0 到 1023\n\n\n\n可以手动，也可以通过 codis dashboard 进行自动分配\n\n\n\n\n\n客户端要读写数据时，使用 CRC32 算法计算数据 key 的哈希值，把哈希值对 1024 取模得到对应 Slot 的编号\n\n\n\nCRC32(key) % 1024 = n\n\n\n\n\n即可知道数据保存在哪个 server 上\n\n\n\n数据路由表 §\n\n指 Slot 和 codis server 的映射关系\n在 codis dashboard 分配好路由表后会把路由表发送给 codis proxy，同时也会保存在 Zookeeper 中，codis proxy 会把路由表缓存在本地\n路由表的分配和使用过程\n\n\n\n\n\n集群扩容和数据迁移 §\n\n\n增加 codis server\n\n\n\n启动新的 codis server，将它加入集群\n\n\n\n\n\n把部分数据迁移到新的 server\n\n\n\n\nCodis 集群按照 Slot 的粒度进行数据迁移\n\n\n\n\n\n\n在源 server 上，Codis 从要迁移的 Slot 中随机选择一个数据，发送给目的 server\n\n\n\n\n目的 server 确认收到数据后，会给源 server 返回确认消息。这时，源 server 会在本地将刚才迁移的数据删除\n\n\n\n\n第一步和第二步就是单个数据的迁移过程。Codis 会不断重复这个迁移过程，直到要迁移的 Slot 中的数据全部迁移完成\n\n\n\n支持两种迁移模式\n\n\n同步迁移\n\n阻塞，此时源 server 无法处理新的请求操作\n\n\n\n异步迁移\n\n\n非阻塞，迁移的数据会被设置为只读，不会出现数据不一致的问题\n\n\n对于 bigkey，采用拆分指令的方式进行迁移：对 bigkey 的每个元素，用一条指令进行迁移\n\n会给目的 server 上被迁移中的 bigkey 设置临时过期时间，如果迁移过程发生故障，不会影响迁移的原子性，完成迁移后删除设置的临时过期时间\n\n\n\n可以通过异步迁移命令 SLOTSMGRTTAGSLOT-ASYNC 的参数 numkeys 设置每次迁移的 key 数量\n\n\n\n\n\n\n\n\n增加 codis proxy\n\n\n\n\n\n\n启动新的 proxy\n\n\n\n\n通过 codis dashboard 把 proxy 加入集群即可\n\n\n\n\n\nCodis 集群可靠性 §\n\n\ncodis server\n\n给每个 server 配置从库，并使用哨兵机制进行监控\n此时每个 server 成为一个 server group，都是一主多从\nserver group 的 Codis 集群架构图\n\n\n\n\n\n\n\ncodis proxy\n\n和 Zookeeper 搭配使用\n有超过半数的 Zookeeper 实例可以正常工作，Zookeeper 集群就可以提供服务\nproxy 故障只需重启，然后通过 codis dashboard 从 Zookeeper 集群获取路由表即可恢复服务\n\n\n\n切片集群方案选择建议 §\n\nCodis 和 Redis Cluster 的区别\n\n\n\n\n\n\n从稳定性和成熟度，选 Codis\n\n\n\n\n从业务应用客户端兼容性，选 Codis\n\n\n\n\n从数据迁移性能纬度看，选 Codis\n\n\n\n\n\n从使用 Redis 新命令和新特性，选 Redis Cluster\n\n\n\nCodis server 是基于开源的 Redis 3.2.8 开发的，已经不再维护\n\n\n\n\n"},"35｜join-语句怎么优化？":{"title":"35｜join 语句怎么优化？","links":[],"tags":["MySQL"],"content":"Multi-Range Read 优化（MRR） §\n\n\n目的：尽量使用顺序读盘\n\n\n设计思路：因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n\n\n优化后的执行流程\n\n\n\n\n\n\n根据索引 a 定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;\n\n\nread_rnd_buffer：MySQL 的随机读缓冲区。当按任意顺序读取行时（例如按照排序顺序）将分配一个随机读取缓冲区，进行排序查询时，MySQL 会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度。\n\n\n\n\n将 read_rnd_buffer 中的 id 进行递增排序；\n\n\n\n\n排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。\n\n\n\nread_rnd_buffer 的大小由 read_rnd_buffer_size 参数控制。\n\n\n如果步骤 1 中 read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。\n\n\n\n\n想要稳定地使用 MRR 优化的话，需要设置set optimizer_switch=“mrr_cost_based=off”。\n\n官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。\n\n\n\n提升性能的核心：在索引 a 上做一个范围查询，拿到足够多的主键 id，通过排序后，再去主键索引查数据，才能体现出“顺序性”的优势。\n\n\n用了 order by 就不要用 MRR 了\n\n\nBatched Key Access（BKA） §\n\n\nMySQL 已经内置支持的，建议默认使用\n\n\nMySQL 5.6\n\n\n对 NLJ 算法的优化\n\nNLJ 用不到 join_buffer，BKA 可以\n每多一个 join，就多一个 join_buffer\n\n\n\n启用方法，在执行 SQL 语句之前，先设置：set optimizer_switch=‘mrr=on,mrr_cost_based=off,batched_key_access=on’;\n\n前两个参数的作用是要启用 MRR。BKA 算法的优化要依赖于 MRR。\n\n\n\nMySQL · 特性分析 · 优化器 MRR &amp; BKA\n\n\n并不是“先计算两个表 join 的结果，再跟第三个表 join”，而是直接嵌套查询。\n\n\n\n\n\nBNL 算法的性能问题 §\n\n\nBNL 算法对系统的影响\n- 可能会多次扫描被驱动表，占用磁盘 IO 资源；\n- 判断 join 条件需要执行 M * N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；\n- 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。\n\n\n如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部。\n\n\n业务正常访问的数据页，没有机会进入 young 区域。\n\n\n影响 Buffer Pool 的正常运作\n\n\n减小影响的方法：增大 join_buffer_size 的值，减少对被驱动表的扫描次数\n\n\n执行语句之前，通过理论分析和查看 explain 结果的方式，确认是否要使用 BNL 算法，如果确认优化器会使用，就需要做优化\n\n\nBNL 转 BKA §\n\n\n思路：用上被驱动表的索引，触发 BKA 算法\n\n\n\n一些情况下，直接在被驱动表上建索引\n\n\n\n\n不能建索引时，使用临时表\n\n\n把被驱动表中满足条件的数据放到临时表中\n\n\n为了让 join 使用 BKA 算法，给临时表的字段加上索引\n\n\n让驱动表和临时表做 join 操作\n  create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;\n  insert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;select * from t1 join temp_t on (t1.b=temp_t.b);\n\n\n这里用内存临时表的效果更好\ncreate temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;\ninsert into temp_t select * from t2 where b&gt;=1 and b&lt;=2000;select * from t1 join temp_t on (t1.b=temp_t.b);\n\n\n\n\n\n\n\n\nhash join §\n\n\nMysql 8.0.18 已经支持 Hash-join\n\n\n8.0.20 版本以上官方已经移除 BNL 的支持，全部替换成 hash -join\n\n\njoin_buffer 维护的无序数组替换成哈希表\n\nN * M =&gt; 1 * M\n\n\n\n自己在业务端实现\n\nselect * from t1; 取得表 t1 的全部数据，在业务端存入一个 hash 结构\nselect * from t2 where b&gt;=1 and b&lt;=2000; 获取表 t2 中满足条件的 2000 行数据。\n把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。\n\n\n\n执行效率：hash join &gt; 临时表\n\n\n评论区 §\n\nwhere in (?)，？的多个值不需要排序\n固态硬盘的顺序写还是比随机写快\n"},"36｜Redis-支撑秒杀场景的关键技术和实践都有哪些？":{"title":"36｜Redis 支撑秒杀场景的关键技术和实践都有哪些？","links":[],"tags":["Redis"],"content":"特征 §\n\n\n\n瞬时并发访问量非常高\n\n\n\n\n读多写少\n\n\n\n秒杀场景的所有环节 §\n\n\n活动前\n\n不需要 Redis\n尽量把商品详情页页面元素静态化，然后使用前端 CDN 或浏览器缓存把元素缓存起来\n\n\n\n活动开始\n\n\nRedis 参与的两个环节\n\n\n\n\n\n使用 Redis 保存库存量，不交给数据库做库存扣减\n\n如果把库存扣减在数据库执行，会带来两个问题\n\n\n额外的开销。Redis 中保存了库存量，而库存量的最新值又是数据库在维护，所以数据库更新后，还需要和 Redis 进行同步，这个过程增加了额外的操作逻辑，也带来了额外的开销。\n\n\n\n\n数据库处理较慢，不能及时更新库存余量，导致大量库存查验请求读取到 Redis 中的旧库存值，此时会出现下单数量大于实际的库存量，导致超售\n\n\n\n\n\n最后在数据库处理订单\n\n订单处理涉及支付、商品出库、物流等多个关联操作，要保证处理的事务性，需要在数据库中完成\n订单处理时的请求压力已经不大\n\n\n\n\n\n活动结束后\n\n不需要 Redis\n\n\n\n库存数据保存方式 §\n\n\n使用切片集群，用不同实例保存不同商品的库存\n\n\n每个商品用一个 Hash 类型的键值对保存\n\nkey: itemID\nvalue: {total: N, ordered: M}\n\n\n\n先用 CRC 算法计算不同商品 key 对应的 Slot，然后，在分配 Slot 和实例对应关系时，才能把不同秒杀商品对应的 Slot 分配到不同实例上保存\n\n\n基于原子操作支撑秒杀场景 §\n\n使用 Lua 脚本执行库存查验和库存扣减操作，保证原子性\n\n基于分布式锁来支撑秒杀场景 §\n\n先让客户端向 Redis 申请分布式锁，只有拿到锁的客户端才能执行库存查验和库存扣减\n这样可以在争夺分布式锁时过滤掉大量的秒杀请求\n库存查验和扣减也不用使用原子操作了，因为多个并发客户端只有一个客户端能够拿到锁，已经保证了客户端并发访问的互斥性\n\n建议 §\n\n\n使用切片集群中的不同实例，分别保存分布式锁和商品库存信息\n\n减轻保存库存信息的实例的压力\n\n\n\n把秒杀商品的库存信息用单独的实例保存，不要和日常业务系统的数据保存在同一个实例上，避免干扰业务系统的正常运行\n\n\n其他环节 §\n\n\n\n前端静态页面的设计\n\n\n\n\n\n请求拦截和流控\n\n\n\n使用黑名单禁止恶意 IP 进行访问；限流；等等\n\n\n\n\n\n库存信息过期时间处理\n\n\n\nRedis 中的库存信息 = 数据库的缓存，不给 Reids 的库存信息设置过期时间\n\n\n\n\n\n数据库订单异常处理\n\n\n\n增加订单重试功能\n\n\n"},"36｜为什么临时表可以重名？":{"title":"36｜为什么临时表可以重名？","links":[],"tags":["MySQL"],"content":"\n本章的内存表都是用户手动创建的\n\n临时表和内存表不同 §\n\n内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine=memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。\n而临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。临时表也可以使用 Memory 引擎。\n\n临时表的特性 §\n\n建表语法是 create temporary table …。\n一个临时表只能被创建它的 session 访问，对其他线程不可见。\na. 在 session 结束的时候会自动删除临时表\nb. 不同 session 的临时表可以重名\n临时表可以与普通表同名。\nsession A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。\nshow tables 命令不显示临时表。\n\n临时表的应用 §\n\n\n经常被用在复杂查询的优化过程中\n\n\n典型：分库分表系统的跨库查询\n\n\n第一种思路：在 proxy 层的进程代码中实现排序\n\n开发工作量比较大\n对 proxy 端压力大：内存、CPU\n\n\n\n第二种思路：把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。\n\n在汇总库创建临时表\n然后分库拿到需要的数据，插入到临时表中\n\n\n\n\n\n临时表可以重名 §\n\n\n物理上的文件\n\n\n#sql{进程 id}_{线程 id}_ 序列号.frm 文件保存表结构定义\n\n通过 select @@tmpdir 命令可以查看临时文件目录\n\n\n\n5.6 以及之前的版本：#sql{进程 id}_{线程 id}_ 序列号.ibd 存放数据文件\n\n\n5.7 开始：MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。不需要再创建 ibd 文件了。\n\n\n内存里面\n\n\n每个表对应一个 table_def_key\n\n普通表：库名 + 表名\n临时表：库名 + 表名 + server_id + thread_id\n\n\n\n在实现上，每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作。\n\n\n\n\n临时表和主备复制 §\n\n\n只在 binlog_format=statment/mixed 的时候，binlog 中才会记录临时表的操作。\n\nrow 格式会记录操作的数据\n\n删除临时表的语句会被改写，因为备库找不到临时表会报错\n/* generated by server */ 说明是被服务端改写过的语句\n\n\n\n\n\nMySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key：\n\n\n思考题 §\n\n可以用 alter table 修改临时表的表名，不能使用 rename 语法的原因？\n\n在实现上，执行 rename table 语句的时候，要求按照“库名/表名.frm”的规则去磁盘找文件，但是临时表在磁盘上的 frm 文件放在 tmpdir 目录，并且文件名的规则是 #sql{进程 id}_{线程 id}_ 序列号.frm，因此会报“找不到文件名”的错误。\n\n\n\n评论区 §\n\n\n“临时表会自动回收”这个功能，主要用于“应用程序异常断开、MySQL异常重启”后，不需要主动去删除表。平时正常使用的时候，建议用完手动删除。\n\n如果 A 客户端在执行过程中创建了临时表，用完了连接就放回池子里面，没有做别的清理工作，然后新的客户端 B 复用这个连接，就可能会看到 A 的临时表。具体要看连接池怎么实现的。\n\n\n\n一般一个事务创建临时表以后，读写分离就会默认接下来的请求都路由到主库去了\n\n\n用户没有显示指定主键的话，InnoDB 引擎会自己创建一个隐藏的主键，但是这个主键对 server 层是透明的，优化器用不上。\n\n"},"37｜什么时候会使用内部临时表？":{"title":"37｜什么时候会使用内部临时表？","links":[],"tags":["MySQL"],"content":"union 执行流程 §\n\n(select 1000 as f) union (select id from t1 order by id desc limit 2);\nunion，它的语义是，取这两个子查询结果的并集，并去重\n创建临时表，执行第一个查询，拿到 1000，放入临时表，执行第二个查询，拿到 1000 和 999，1000 由于违反唯一性约束插入失败，接着放入 999 后返回，最后从临时表中按行取出数据，返回结果，并删除临时表\n改成 union all 则没有去重的语义，执行时不需要临时表\n\ngroup by 执行流程 §\n\n\nselect id%10 as m, count(*) as c from t1 group by m;\n\n\n创建临时表（m(pk)，c），扫表 t1 的索引 a，取出 id 并计算出 x，放入临时表/计数，完成后根据 m 做排序，得到结果集返回给客户端\n\n\norder by null 可以跳过对结果集的排序\n\n\n内存临时表的大小是有限制的，参数 tmp_table_size 就是控制这个内存大小的，默认是 16M。\n\n如果超出，就会转成磁盘临时表\n\n\n\n磁盘临时表默认使用 InnoDB 引擎\n\n\ngroup by 优化方法 §\n索引 §\n\n\n数据有序，就不需要临时表排序\n\n如果可以确保输入的数据是有序的，那么计算 group by 的时候，就只需要从左到右，顺序扫描，依次累加。\n\n\n\n在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新\n\nalter table t1 add column z int generated always as(id % 100), add index(z);\n\n\n\nMySQL 5.6 及之前的版本，可以创建普通列和索引\n\n例子：select id%10 as m, count(*) as c from t1 group by m;\n可以改写成：select z, count(*) as c from t1 group by z;\n\nz 字段的值 = id%10\n\n\n\n\n\n直接排序 §\n\n在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。\nMySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。\n\n数组存放了每一个 id%10，最后排序，计数\n\n\n\n总结指导原则 §\n\n如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；\n尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；\n如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；\n如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。\n\n评论区 §\n\n\n如果只需要去重，不需要执行聚合函数，distinct 和 group by 那种效率高一些呢？\n\n如果没有 limit，是一样的；有 limit 的话，distinct 快些。\n\n\n\nsort_buffer、join_buffer、内存临时表和磁盘临时表 都是 server 层的，引擎间共用\n\n\n需要创建临时表的时候，与当前访问数据的引擎无关，都是默认创建内存临时表，内存不够了转磁盘临时表（默认是 innodb 表）\n\n\n内存表的主键不是保证有序的\n\n"},"37｜数据分布优化：如何应对数据倾斜？":{"title":"37｜数据分布优化：如何应对数据倾斜？","links":[],"tags":["Redis"],"content":"数据量倾斜 §\n\n\n在某些情况下，实例上的数据分布不均衡，某个实例上的数据特别多\n\n\nbigkey\n\n\n集合类型的 bigkey 如果是集合类型，可以拆分成很多个小的集合类型数据，分散保存在不同的实例上\n\n比如通过 ID 范围拆分\n\n\n\n避免 bigkey\n\n\n\n\nSlot 分配不均衡\n\n\n手动迁移 Redis Cluster 的 Slot\n\n\ncluster slots 命令查看 Slot 分配情况\n\n\n可用命令\n\nCLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例\nCLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key。\nMIGRATE：把一个 key 从源实例实际迁移到目标实例\n\n\n\n\n\n手动迁移 Codis 的 Slot\n\ncodis-admin —dashboard=ADDR -slot-action —create —sid=300 —gid=6\n\n\n\n\n\nHash Tag\n\n\n指加在键值对 key 中的一对花括号 {}\n\n\n如果有 Hash Tag，客户端在计算 key 的 CRC16 值时，只对 Hash Tag 花括号中的 key 内容进行计算\n\n\n相同 Hash Tag 的数据会被映射到相同的 Slot 上\n\n\n使用场景：用在 Redis Cluster 和 Codis 中，支持事务操作和范围查询\n\n因为 Redis Cluster 和 Codis 本身不支持跨实例的事务操作\n\n\n\n建议：不使用 Hash Tag，在客户端执行事务操作和范围查询\n\n\n\n\n数据访问倾斜 §\n\n\n虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁\n\n\n根本原因：实例存在热点数据\n\n\n应对方法\n\n\n只读的热点数据\n\n具体做法：将热点数据复制多分，每个副本 key 增加一个随机前缀，映射到不同的实例的 Slot 中\n\n\n\n有读有写的热点数据\n\n\n给实例本身增加资源\n\n比如配置更高的机器\n\n\n\n\n\n\n\n集群的实例资源配置建议 §\n\n在构建切片集群时，尽量使用大小配置相同的实例（例如实例内存配置保持相同），可以避免因实例资源不均衡而在不同实例上分配不同数量的 Slot\n"},"38｜通信开销：限制-Redis-Cluster-规模的关键因素":{"title":"38｜通信开销：限制 Redis Cluster 规模的关键因素","links":[],"tags":["Redis"],"content":"\n\nRedis Cluster 实例间以 Gossip 协议进行通信的机制\n\n\nGossip 协议的工作原理\n\n两个实例间进行 PING、PONG 消息传递的情况\n每个实例默认每秒从集群中随机挑选一些实例，把 PING 消息发送给挑选出来的实例，用来检测这些实例是否在线，并交换彼此的状态信息\nPING 消息中封装了发送消息的实例自身的状态信息、部分其它实例的状态信息，以及 Slot 映射表\n一个实例在接收到 PING 消息后，会给发送 PING 消息的实例，发送一个 PONG 消息。PONG 消息包含的内容和 PING 消息一样\n\n\n\nGossip 消息大小\n\n\nPING 和 PONG 消息的消息体都大约 12KB\n\n\nPING 消息中带有一个长度为 16384 bit 的 Bitmap\n\n每一位对应一个 Slot，如果某一位为 1，表示这个 Slot 属于当前实例\n\n\n\n\n\n实例间通信频率\n\n\n\nGossip 协议的工作原理第二点\n\n\n\n\n实例每 100ms 扫描本地的实例列表，如果发现有实例最近一次接收 PONG 消息的时间已经大于配置项 cluster-node-timeout 的一半，就会立刻给该实例发送 PING 消息，更新这个实例上的集群状态信息\n\n\n\n每秒会发送的 PING 消息数量 = 1 + 10 * 实例数\n\n实例数 = 最近一次接收 PONG 消息的时间超出 cluster-node-timeout/2\n\n\n\n\n\n降低实例间的通信开销\n\n\n不能减小实例传输的消息大小\n\n\n只能修改 cluster-node-timeout 配置项\n\n\n默认 15 秒，调大到 20 或 25 秒\n\n\n验证调整后的值是否能减少心跳消息占用的集群网络带宽\n\n调整前后使用 tcpdump 命令抓取实例发送心跳信息网络包的情况\n例如，执行：tcpdump host 192.168.10.3 port 16379 -i 网卡名 -w /tmp/r1.cap\n通过分析网络包的数量和大小，就可以判断调整 cluster-node-timeout 值前后，心跳消息占用的带宽情况\n\n\n\n\n\n\n\n\n\n建议把 Redis Cluster 的规模控制在 400~500 个实例\n\n假设单个实例每秒能支撑 8 万请求操作（8 万 QPS），每个主实例配置 1 个从实例，400~ 500 个实例可支持 1600 万~2000 万 QPS（200/250 个主实例 * 8 万 QPS = 1600/2000 万 QPS），这个吞吐量性能可以满足不少业务应用的需求\n\n\n\n建议针对不同的业务线、业务模块，单独部署不同的分片集群，方便运维和管理，出问题也只会影响某一个业务模块\n\n"},"38｜都说-InnoDB-好，那还要不要使用-Memory-引擎？":{"title":"38｜都说 InnoDB 好，那还要不要使用 Memory 引擎？","links":[],"tags":["MySQL"],"content":"内存表的数据组织结构 §\n\n\nInnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。\n\n\nMemory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。\n\n\n\nInnoDB 表的数据总是有序存放，而内存表的数据就是按照写入顺序存放；\n\n\n\n\n当数据文件有空洞，InnoDB 表在插入新数据时，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；\n\n\n\n\n数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；\n\n\n\n\nInnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。\n\n\n\n\nInnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。\n\n\n\n内存表也支持 B-Tree 索引 §\n\nalter table t1 add index a_btree_index using btree (id);\n\n不建议在生产环境使用普通内存表 §\n\n\n\n锁粒度问题\n\n\n不支持行锁，只支持表锁\n\n\n\n\n数据持久化问题\n\n\nM - S 架构下，比如备库重启，内存表被清空，此时内存表被清空，导致主备同步停止\n双 M 架构下，在备库重启的时候，备库 binlog 里的 delete 语句就会传到主库，然后把主库内存表的内容删除。\n\n\n\n建议把普通内存表都用 InnoDB 代替 §\n\n例外：内存临时表\n\n\n临时表不会被其他线程访问，没有并发性的问题；\n临时表重启后也是需要删除的，清空数据这个问题不存在；\n备库的临时表也不会影响主库的用户线程。\n\n思考题 §\n\n假设你刚刚接手的一个数据库上，真的发现了一个内存表。备库重启之后肯定是会导致备库的内存表数据被清空，进而导致主备同步停止。这时，最好的做法是将它修改成 InnoDB 引擎表。\n假设当时的业务场景暂时不允许你修改引擎，你可以加上什么自动化逻辑，来避免主备同步停止呢？\n\n先避免备库重启的时候数据丢失：set sql_log_bin=off; alter table tbl_name engine=innodb; 由于主库重启后，会往 binlog 写 delete from tbl_name，传到备库，备库的同名的表数据也会被清空，所以不会出现主备同步停止的问题\n如果主库变成新备库，重复上面的操作\n所以，如果我们不能直接修改主库上的表引擎，可以配置一个自动巡检的工具，在备库上发现内存表就把引擎改了。\n\n\n"},"39｜Redis-6.0-的新特性：多线程、客户端缓存与安全":{"title":"39｜Redis 6.0 的新特性：多线程、客户端缓存与安全","links":[],"tags":["Redis"],"content":"多 IO 线程 §\n\n\n作用：使用多个 IO 线程并行读取网络请求、进行协议解析、回写 Socket\n\n\n主线程和 IO 线程协作完成请求处理\n\n\n阶段一：服务端和客户端建立 Socket 连接，并分配处理线程\n\n\n阶段二：IO 线程读取并解析请求\n\n\n阶段三：主线程执行请求操作\n\n\n\n\n\n阶段四：IO 线程回写 Socket 和主线程清空全局队列\n\n\n\n\n\n\n\n启用多线程命令：io-threads-do-reads yes\n\n\n设置线程个数命令：io-threads 6\n\n一般要小于实例所在机器的 CPU 核个数\n例如，对于一个 8 核的机器来说，Redis 官方建议配置 6 个 IO 线程\n\n\n\n如果在实际应用中，发现 Redis 实例的 CPU 开销不大，吞吐量却没有提升，可以考虑使用 Redis 6.0 的多线程机制，加速网络处理，进而提升实例的吞吐量\n\n\n\n\n注意事项：多 IO 线程只负责处理网络请求，不执行命令操作\n\n\n适用场景：提升 Redis 吞吐量\n\n\n客户端缓存 §\n\n\n作用\n\n\n普通模式：检测客户端读取的 key 的修改情况\n\n服务端对于记录的 key 只会报告一次 invalidate 消息，如果 key 再被修改，服务端就不会再次给客户端发送 invalidate 消息\n\n\n\n广播模式：将 key 的失效消息发送给所有客户端\n\n\n客户端需执行命令注册要跟踪的 key\n\nCLIENT TRACKING ON BCAST PREFIX user\n\n\n\n\n\n重定向模式：支持使用 RESP 2 协议的客户端\n\n\nRedis 6.0 之前的客户端可以使用此模式\n\n\n客户端 B 只支持 RESP 2 协议\n\n客户端 B 执行，客户端 B 的 ID 号是 303\nSUBSCRIBE redis:invalidate\n\n\n\n客户端 A 支持 RESP 3 协议，兼容方案\n\n执行 CLIENT TRACKING ON BCAST REDIRECT 303 将获取到的失效消息转发给 B\n\n\n\n\n\n\n\n注意事项：普通模式和广播模式需要启用 RESP 3 协议接收失效消息\n\n\n适用场景：加速业务应用访问\n\n\n访问权限控制 §\n\n\n作用：区分不同用户，支持以用户和 key 为粒度设置某个或某类命令的调用权限\n\n一些可用的操作汇总图\n\n\n\n\n\n\n\n适用场景：支持多用户以不同权限访问 Redis\n\n\nRESP 3 协议 §\n\n作用：使用不同开头字符表示多种数据类型，简化客户端开发复杂度\n适用场景：高效支持不同数据类型使用，支持客户端缓存\n\n新特性汇总图 §\n\n\n"},"39｜自增主键为什么不是连续的？":{"title":"39｜自增主键为什么不是连续的？","links":[],"tags":["MySQL"],"content":"自增值保存在哪儿？ §\n\n表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。\nMyISAM 引擎的自增值保存在数据文件中。\nInnoDB\n\n在 MySQL 5.7 及之前的版本，自增值保存在内存里。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。\n在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。\n\n\n\n自增值修改机制 §\n\n如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；\n如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。\n\n如果大于当前自增值，则会将插入的值的下一个大于的值作为自增值（基于步长）\n\n\n\n自增锁的优化 §\n\n\nMySQL 5.0 版本，自增锁的范围是语句级别，等语句执行完才释放，影响并发度\n\n\nMySQL 5.1.22 引入一个新策略，新增参数 innodb_autoinc_lock_mode，默认值 1\n\n\n\n这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略\n\n\n\n\n这个参数的值被设置为 1 时：a. 普通 insert 语句，自增锁在申请之后就马上释放；b. 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；\n\n\n⚠️ 关于 b，如果像参数设置 2 一样，将会导致主备不一致（binlog_format=statement），因为事务的 binlog 是记录到一起的，在备库是连续，但在主库时却不一定是连续拿到自增值\n这里说的批量插入数据，包含的语句类型是 insert … select、replace … select 和 load data 语句。\nb 的设定是因为“不知道要预先申请多少个 id”\n\n\n\n\n这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。\n\n\n推荐，需配合 binlog_format=row\n\n\n\n\n\n在 8.0.3 版本后，innodb_autoinc_lock_mode 默认值已是 2\n\n\n对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略 §\n\n语句执行过程中，第一次申请自增 id，会分配 1 个；\n1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；\n依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。\n\n最后一次申请的如果没用完就浪费掉了\n\n\n\n评论区 §\n\n在 binlog 为 statement 的情况下。语句 A 先获取 id=1，然后 B 获取 id=2，接着 B 提交，写 binlog，再 A 写 binlog。这个时候如果 binlog 重放，是不是会发生 B 的 id 为 1，而 A的 id 为 2 的不一致的情况？\n\n不会因为 binlog 在记录这种带自增值的语句之前，会在前面多一句，用于指定“接下来这个语句要需要的 自增 ID 值是多少”，而这个值，是在主库上这一行插入成功后对应的自增值，所以是一致的\n\n\n"},"40｜Redis-的下一步：基于-NVM-内存的实践":{"title":"40｜Redis 的下一步：基于 NVM 内存的实践","links":[],"tags":["Redis"],"content":"\n\n特性\n\n\n能持久化保存数据\n\n\n读写速度比 DRAM 内存稍慢\n\nDRAM：Dynamic random-access memory 动态随机存取存储器（半导体记存储器）\n\n\n\n容量大\n\n\n\n\nOptane AEP 内存条（简称 AEP 内存，Intel 2019 年 4 月份推出）\n\n\nMemory 模式\n\n只用容量大和性能高的特性，没有启用数据持久化功能\n仍需配 DRAM 内存，但它是作为 AEP 内存的缓存，对应用软件不可见\n软件系统能使用到的内存空间，就是 AEP 内存条的空间容量\n\n\n\nApp Direct 模式\n\n\n启用持久化数据的功能\n\n\n此模式的 AEP 内存叫做持久化内存（Persistent Memory，PM）\n\n\n使用方法\n\n\n\n部署 PM\n\n\n\n\n格式化\n\n\n\n\n挂载到服务器的一个目录下\n\n\n\n\n在目录下创建文件，通过内存映射（mmap）的方式把文件映射到 Redis 的进程空间\n\n\n\n\n\n\n\n\n\n仍需要主从集群\n\n分担读压力\n\n\n\n没有了 RDB，主从复制的实现，二选一\n\n\n首先，增加从节点时，把全库数据拷贝到从节点上\n\n\n一、用写前日志，日志拷贝到从节点进行回放\n\n会带来双写问题\n\n\n\n二、主节点在 NVM 上做快照，但不写文件，从节点直接从主节点的 NVM 上通过远程内存拷贝来实现复制，需要基于 RDMA（远程内存访问） 来做\n\n\n\n\n应用程序如何基于持久化内存恢复自身的状态？\n\n把应用程序本身的运行时状态，如堆栈等也保存到持久化内存上，需要对操作系统的内核做修改\n目前还没有成熟的方案（2021.09.29）\n\n\n"},"40｜insert-语句的锁为什么这么多？":{"title":"40｜insert 语句的锁为什么这么多？","links":[],"tags":["MySQL"],"content":"insert … select §\n\n\n并发 insert 场景\n\n\n\n\n\n实际的执行效果是，如果 session B 先执行，由于这个语句对表 t 主键索引加了 (-∞,1]这个 next-key lock，会在语句执行完成后，才允许 session A 的 insert 语句执行。\n\n\n但如果没有锁的话，就可能出现 session B 的 insert 语句先执行，但是后写入 binlog 的情况。于是，在 binlog_format=statement 的情况下，binlog 里面就记录了这样的语句序列：insert into t values(-1,-1,-1);insert into t2(c,d) select c,d from t;这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。\n\n\n\n\n是很常见的在两个表之间拷贝数据的方法\n\n\n在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁。\n\n\ninsert 循环写入 §\n\n如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。\n怕边遍历原表边插入数据会查到刚插入的新数据，所以会先把查询结果放到临时表，再取出来进行插入操作\n这里需要给子查询加入 limit，不然就会全表扫描，导致给所有记录和空隙加锁\n\nv8.x 优化了\n\n\n\ninsert 唯一键冲突 §\n\n\n\n\n\ninsert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。\n\n\n一个经典的死锁场景\n\n\n\n\n\nA 先加锁，B、C 发现唯一键冲突（c 是唯一索引，所以读是当前读），都加上读锁（间隙锁不互斥所以加成功，读、写锁会互斥，所以都在等待行锁释放），A 回滚，B、C 继续执行，都要加上写锁，互相等待对方的行锁，于是出现了死锁\n\n\n\n\ninsert into … on duplicate key update §\n\n\n这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。\n\n会给索引 c 上 (5,10] 加一个排他的 next-key lock（写锁）。\n\n\n\n如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。\n\n\n执行这条语句的 affected rows 返回的是 2，很容易造成误解。\n\n真正更新的只有一行，只是在代码实现上，insert 和 update 都认为自己成功了，update 计数加了 1， insert 计数也加了 1。\n\n\n\n评论区 §\n\n关于 insert 造成死锁的情况，insert、delete 和 update 都可能造成死锁问题，核心还是插入唯一值冲突导致的。线上的处理办法可以是\n\n去掉唯一值检测\n减少重复值的插入\n降低并发线程数量\n\n\n关于数据拷贝大表，建议采用 pt-archiver，这个工具能自动控制频率和速度，建议在低峰期进行数据操作\n一般 select …lock in share mode 就是共享锁；select … for update 和 IUD 语句，就是排他锁。\n"},"41｜怎么最快地复制一张表？":{"title":"41｜怎么最快地复制一张表？","links":[],"tags":["MySQL"],"content":"逻辑导数据 §\n\n\n在两张表中拷贝数据，最简单地使用 insert … select 语句即可实现\n\n\n将数据写到外部文本文件，然后再写回目标表\n\n\n\nmysqldump 方法\n\n\n\n\n导出 CSV 文件\n\n\nload data 命令（导入 CSV 文件）有两种用法：\n\n\n\n不加“local”，是读取服务端的文件，这个文件必须在 secure_file_priv 指定的目录或子目录下；\n\n\n\n\n加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程。\n\n\n\n\n\n\n\n\n\n都可以跨引擎使用\n\n\n物理拷贝（最快） §\n\n\nMySQL 5.6\n\n执行 create table r like t，创建一个相同表结构的空表；\n执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；\n执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；\n在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；\n执行 unlock tables，这时候 t.cfg 文件会被删除；\n执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。\n\n\n\n只能全表拷贝\n\n\n需要到服务器上拷贝数据，无法登录数据库主机时无法使用\n\n\nInnoDB 专属\n\n\n思考题 §\n\n\n我们前面介绍 binlog_format=statement 的时候，binlog 记录的 load data 命令是带 local 的。既然这条命令是发送到备库去执行的，那么备库执行的时候也是本地执行，为什么需要这个 local 呢？\n\n为了确保备库应用 binlog 正常。因为备库可能配置了 secure_file_priv=null，所以不用 local 的话，可能会导入失败，造成主备同步延迟。\n使用 mysqlbinlog 工具解析 binlog 文件，并应用到目标库的情况。使用下面命令 ：mysqlbinlog $binlog_file | mysql -h$host -P$port -u$user -p$pwd 把日志直接解析出来发给目标库执行。增加 local，就能让这个方法支持非本地的 $host。\n\n\n"},"41｜第-35～40-讲课后思考题答案及常见问题答疑":{"title":"41｜第 35～40 讲课后思考题答案及常见问题答疑","links":[],"tags":["Redis"],"content":"\n\nMemcached 是内存键值数据库\n\n\nRocksDB 是硬盘键值数据库（持久化）\n\n\nRedis 和 Memcached 的比较\n\n\n\n\n\nRedis 和 RocksDB 的比较\n\n\n\n\n\n可扩展性\n\nMemcached &gt; Codis &gt; Redis Cluster\n\n\n\n一致性哈希的集群扩容\n\n\n\n假设新加入的节点在一致性哈希圆环上是 A\n\n\n\n\n沿逆时针方向的前一个集群节点是 B\n\n\n\n\n只需要迁移 B 和 A 之间的数据\n\n\n数据迁移量比普通哈希后取模的方法的量少\n\n\n\n5 分钟理解一致性哈希算法（掘金）\n\n"},"42｜grant-之后要跟着-flush-privileges-吗？":{"title":"42｜grant 之后要跟着 flush privileges 吗？","links":[],"tags":["MySQL"],"content":"\n不用\n直接手动修改权限表时用\n在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 ua@ip1 和 ua@ip2 代表的是两个不同的用户。\n\n全局权限 §\n\n保存在 mysql.user 表\n给用户 ua 赋一个最高权限，语句：grant all privileges on . to ‘ua’@’%’ with grant option;\n\n同时更新磁盘和内存\n\n\n磁盘上，将 mysql.user 表里，用户’ua’@’%‘这一行的所有表示权限的字段的值都修改为‘Y’；\n\n\n\n\n内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”。\n\n\n在这个 grant 命令执行完成后，如果有新的客户端使用用户名 ua 登录成功，MySQL 会为新连接维护一个线程对象，然后从 acl_users 数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。\nrevoke 命令也一样\n\n\n\ndb 权限 §\n\n保存在 mysql.db 表\n让用户 ua 拥有库 db1 的所有权限：grant all privileges on db1.* to ‘ua’@’%’ with grant option;\n\n\n\n磁盘上，往 mysql.db 表中插入了一行记录，所有权限位字段设置为“Y”；\n\n\n\n\n内存里，增加一个对象到数组 acl_dbs 中，这个对象的权限位为“全 1”。\n\n\n每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 acl_dbs 数组\nacl_dbls 是一个全局数组\n如果已经 use database_name，则在切换出该库之前，session 就一直有该库权限\n\n\n\n表权限和列权限 §\n\n表权限定义存放在表 mysql.tables_priv 中\n列权限定义存放在表 mysql.columns_priv 中\n这两类权限，组合起来存放在内存的 hash 结构 column_priv_hash 中。\ncolumn_priv_hash 也是一个全局对象\n\n其他 §\n\n如果内存的权限数据和磁盘数据表相同的话，不需要执行 flush privileges。\n如果我们都是用 grant/revoke 语句来执行的话，内存和数据表本来就是保持同步更新的。\n\nflush privileges 语句可以用来重建内存数据，达到一致状态。\n\n\nflush privileges 使用场景\n\n直接手动修改系统权限表时\n\n\ngrant 命令加了 identified by ‘密码’\n\n\n\n如果用户 ‘ua’@’%’ 不存在，就创建这个用户，密码是 pa\n\n\n\n\n如果用户 ua 已经存在，就将密码修改成 pa\n\n\n⚠️ 不建议的写法，容易不慎把密码给改了\n\n\n"},"43｜要不要使用分区表？":{"title":"43｜要不要使用分区表？","links":[],"tags":["MySQL"],"content":"\n分区表：对于引擎层，n 个表对于 server 层，1 个表\n用法跟普通表在 sql 语句上是相同的。\n\n分区策略 §\n\n\nMyISAM 分区表\n\n\nInnoDB 分区表\n\n\n通用分区策略：每次访问都由 server 层控制\n\nMyISAM 分区表使用的分区策略\n性能较差\n⚠️ 5.7.17 开始标记为即将弃用，8.0 开始不允许使用\n打开分区表时，如果分区过多，超过 open_files_limit 参数设置的值时会报错，默认 1024\n\n\n\n本地分区策略：引擎内部自己管理打开分区的行为\n\nInnoDB 和 NDB 引擎支持\n没有通用分区策略会报错的问题：innodb_open_files 参数控制打开多少个文件后自动关闭一些之前打开的文件\n\n\n\nserver 层行为 §\n\nMySQL 在第一次打开分区表的时候，需要访问所有的分区；\n在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；\n在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。\n\n应用场景 §\n\n对业务透明，代码更简洁\n清理历史数据方便\n\n删掉分区：alter table t drop partition … 会直接删除分区文件，效果跟 drop 普通表类似\n与使用 delete 语句删除数据相比，速度快，对系统影响小\n\n\n\n注意事项 §\n\n分区不是越细越好。\n分区不要提前预留太多，在使用之前预先创建即可。\n比如，如果是按月分区，每年年底时再把下一年度的 12 个新分区创建上即可。对于没有数据的历史分区，要及时的 drop 掉。\n\n其他分区方法 §\n\n官方手册\n\n思考题 §\n\n文章中举例只用到了日期字段，没有自增主键，如果要定义这个表的主键，怎么定义？为什么？\n\nMySQL 要求主键包含所有的分区字段\n\n这里必须创建联合主键\n\n\n从利用率上看，应该创建 (ftime, id)\n\nInnoDB 要求至少有一个索引，以自增字段作为第一个字段，所以还要创建一个 id 的单独索引\n\n\n上面的方案反过来也可以 (id, ftime) (ftime)\n\n\n"},"44｜答疑文章（三）：说一说这些好问题":{"title":"44｜答疑文章（三）：说一说这些好问题","links":[],"tags":["MySQL"],"content":"join 的写法 §\n\n\n在 MySQL 里，NULL 跟任何值执行等值判断和不等值判断的结果，都是 NULL。这里包括， select NULL = NULL 的结果，也是返回 NULL。\n\nwhere a.f2=b.f2 就表示，查询结果里面不会包含 b.f2 是 NULL 的行\n\n\n\n使用 left join 时，左边的表不一定是驱动表。\n\n\n如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面\n\n\ndistinct 和 group by 的性能 §\n\n如果只需要去重，不需要执行聚合函数，distinct 和 group by 哪种效率高一些呢？\n\n没有索引时一样\nselect a,count(*) from t group by a order by null;\n\n这条语句的逻辑是：按照字段 a 分组，计算每组的 a 出现的次数。在这个结果里，由于做的是聚合计算，相同的 a 只出现一次。37 章有关于 group by 的相关内容\n\n\n\n\n"},"45｜自增-id-用完怎么办？":{"title":"45｜自增 id 用完怎么办？","links":[],"tags":["MySQL"],"content":"\n表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。\n\nrow_id §\n\nInnoDB 表没有指定主键时，会创建一个不可见的，长度为 6 个字节的 row_id。\nrow_id 是一个长度 8 字节的无符号长整形\n但是 InnoDB 只留了 6 个字节的长度给 row_id 用\n\nrow_id 写入表中的值范围，是从 0 到 248-1；\n达到上限后从 0 开始，写入时会覆盖原有的行\n\n\n\nXid §\n\n\nredo log 和 binlog 相配合时的一个共同字段\n\n\nMySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。\n\n\nglobal_query_id 是一个纯内存变量，重启之后就清零了\n\n\n\n重启后会清零\n\n\n不同事务的 Xid 可能相同\n\n\n\n\n重启后会重新生成新的 binlog 文件\n\n\n同一个 binlog 文件里，Xid 唯一\n达到上限（超大）后从 0 开始，还是可能不唯一，但是只存在于理论上\n\n\n\n\n\n长度是 8 个字节，上限超大\n\n\nInnodb trx_id §\n\n\n第 8 篇讲事务可见性用到的事务 id（transaction id）\n\n\nXid 由 server 层维护，InnoDB 内部使用 Xid 是为了在 InnoDB 事务和 server 之间做关联\n\n\nInnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，并将 max_trx_id 加 1。\n\n对于正在执行的事务，可以从 information_schema.innodb_trx 表中看到事务的 trx_id。\n对于只读事务，InnoDB 不分配 trx_id，在表中查看到的很大的 trx_id 只是显示用的\n\n把当前事务的 trx 变量的指针地址转成整数，再加上 2^48\n\n\n\n因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx 还是在 innodb_locks 表里，同一个只读事务查出来的 trx_id 就会是一样的。\n\n\n\n\n如果有并行的多个只读事务，每个事务的 trx 变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的 trx_id 就是不同的。\n\n\n加上是为了避免跟真正的 trx_id 一样\n\n\n不分配的好处\n\n可以减小事务视图里面活跃事务数组的大小\n可以减少 trx_id 的申请次数（减少并发事务申请 trx_id 的锁冲突）\n\n\n\n\nselect 语句后面加上 for update 则不是只读事务\n\n\nupdate 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1， 因此在一个事务中至少加 2；\n\n\n\n\nInnoDB 的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id 值并不是按照加 1 递增的。\n\n\n\n\n\nInnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。\n\n\n重启 MySQL时 max_trx_id 不会清零\n\n理论上，MySQL 实例运行得足够久，trx_id 达到上限后从 0 开始，就会持续出现脏读\n\n\n\nthread_id §\n\n4 个字节，达到 2^32 - 1 后重置为 0，然后继续增加\n不会在 show processlist 看到两个相同的 thread_id\n\nMySQL 设计了一个唯一数组：循环尝试插入自增 1 的线程 id 直到成功\n\n\n\n小结 §\n\n表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。\nrow_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。\nXid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。\nInnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。\nthread_id 是我们使用中最常见的，而且也是处理得最好的自增 id 逻辑。\n"},"About-Atlas":{"title":"About Atlas","links":[],"tags":[],"content":"MOC (map of maps)"},"Capslock":{"title":"Capslock","links":[],"tags":["软件","工具","Mac"],"content":"功能 §\n\n加强 Caps 键功能\n\n安装 §\n\nGithub\n到系统设置 - 键盘 - 键盘快捷键 - Modifier Keys 里选择键盘\n\n设置单击 Caps 切换输入法 §\n\n打开配置文件 ~/.config/karabiner/karabiner.json\n搜 &quot;key_code&quot;: &quot;spacebar&quot;\n将 to_if_alone 值改成 caps_lock\n"},"Crontab-执行提示没有权限":{"title":"Crontab 执行提示没有权限","links":[],"tags":["Linux","自动化"],"content":"\nMac 的解决方案：How to Fix Cron “Operation not permitted” error in macOS - ITPro Helper\n检查有没有用户对应的 home 目录\n"},"Docker-不常见问题":{"title":"不常见问题","links":[],"tags":["docker"],"content":"修改宿主机 hosts §\n\n\n编辑 /etc/hosts\n\n\n执行 sudo killall -HUP mDNSResponder 刷新缓存\n\n\n可能需要重启 service docker restart\n\n如果刷新缓存报错则执行 /etc/init.d/network restart 使修改生效\n重启 service docker restart\n不重启则外网访问 Docker 部署的 Nginx 等服务失败，宿主机 $ curl http://localhost 可以成功\n\n\n\ncrontab §\n\n指定用户执行：crontab -u www-data -e\n到容器里执行 /usr/sbin/crond -b 启动服务\n可以把配置文件，比如 www-data 命名的文件映射到容器的 /etc/crontabs/ 下\n"},"Docker":{"title":"Docker","links":["Docker-不常见问题"],"tags":["docker"],"content":"\nDocker 不常见问题\n"},"Egg.js-手动热更新":{"title":"Egg.js 手动热更新","links":[],"tags":["部署","热更新","Eggjs","Nodejs"],"content":"package.json\n{\n  &quot;scripts&quot;: {\n    &quot;start&quot;: &quot;egg-scripts start --daemon --title=egg-server&quot;,\n    &quot;stop&quot;: &quot;egg-scripts stop --daemon --title=egg-server&quot;,\n    &quot;start-tmp&quot;: &quot;egg-scripts start --daemon --title=egg-tmp-server --port=7002&quot;,\n    &quot;stop-tmp&quot;: &quot;egg-scripts stop --daemon --title=egg-tmp-server --port=7002&quot;\n  }\n}\n\n正常启动时 npm run build &amp;&amp; npm run start，在 Nginx 里反代到 7001 端口\n需要热更新时，npm run start-tmp，在 Nginx 里反代到 7002 端口（service nginx reload）\n重启 7001 端口上的服务，在 Nginx 里反代回 7001 端口\nnpm run start-tmp 关闭 7002 端口的服务\n"},"GitHub-加速访问":{"title":"GitHub 加速访问","links":[],"tags":["GitHub"],"content":"\nGitHub Hosts | hosts\n"},"Laravel-Pint-使用":{"title":"Laravel Pint 使用","links":[],"tags":["PHP"],"content":"\n参考：https://laraveldaily.com/post/laravel-pint-pre-commit-hooks-github-actions\nPhpStorm 已内置支持，可在设置里搜索到并主动打开\nVscode 安装插件：https://marketplace.visualstudio.com/items?itemName=open-southeners.laravel-pint\n最新版需要 PHP8.1+，最低需要 PHP8\n"},"Laravel-开发注意事项":{"title":"PHP 开发注意事项","links":[],"tags":["PHP","开发","规范"],"content":"MySQL §\n\n时区：Asia/Shanghai\nbinlog 格式：row\n隔离级别：读提交\n\nselect @@transaction_isolation;\nset @global transaction isolation level read committed;\n\n\n\n目录说明 §\n\nRequests 表单验证\nControllers 控制器，无业务或写简单的业务逻辑\nServices 行业务逻辑处理\nModels 定义模型，提供数据库操作\nTraits 需要复用的代码\n\n任务调度 §\n\nhttps://learnku.com/docs/laravel/10.x/scheduling/14875#running-the-scheduler\n\n添加到部署 PHP 的服务器的 crontab 中\n* * * * * cd /path-to-your-project &amp;&amp; php artisan schedule:run &gt;&gt; /dev/null 2&gt;&amp;1\n数据库规范 §\n\n隔离级别：读提交\n表名均使用小写加下划线且复数形式（除非单词没有复数）\n表字段名均使用小写加下划线\n普通索引使用 idx_ 开头\n唯一索引使用 uk_ 开头\n索引名里的表名使用大驼峰形式\n索引名里的字段名使用小驼峰形式\n索引名太长可用缩写\n作为索引的字符串类型字段的长度不能大于 191\n日期字段均使用 datetime 类型（避免时区问题）\n索引字段均不允许为 null（暂时只有 datetime 类型可能为 null，2023-06-16）\n添加新字段时必须有默认值或 nullable\n需要区分字母大小写的字段使用 binary 类型，如 $table-&gt;string(&#039;fixed_id&#039;, 191)-&gt;collation(&#039;utf8mb4_bin&#039;)\n表、列和 Model 对应的字段必须有注释，参考 User 和 Student Model\n\n开发规范 §\n\n只在配置文件里使用 env() 函数\n只使用 === 和 !==，不使用 == 和 !=\n使用 Carbon 日期类型\n使用小驼峰形式的变量名、方法名\n对于接口可选参数都需要添加 nullable，如：&#039;name&#039; =&gt; &#039;nullable|string&#039;\n\nEloquent ORM §\n\n\n文档\n\n\n集合\n\n\n查看生成的 SQL：DB::enableQueryLog(); DB::getQueryLog();\n\n\n在循环里 $role-&gt;users 这种查询会触发 N+1 问题，使用 with 方法预加载\n\nRole::with(&#039;users&#039;)-&gt;get();\n或在 Model 里设置 protected $with = [&#039;users&#039;];\n\n小心循环引用，如：User::with(&#039;roles&#039;)-&gt;get(); 会导致死循环\n\n\n\n\n\n批量插入数据\n\nUser::insert() 支持批量插入，但是仅支持传入数组，不支持传入 Collection\n需要先调用 toArray() 方法再入 insert()\n如果遇到日期字段，需要 toArray() 后再调用 Carbon::parse(&#039;field&#039;)-&gt;toIso8601String() 方法\n\n\n\n基于 Model 使用 join 时，最后要在 get() 里指定字段，否则数据可能错误，关联模型的字段不会受指定字段影响\n\n如 User::join(Student)-&gt;get()，id 会被覆盖变成 student.id，改为 User::join(Student)-&gt;get([‘users.*’]) 即可\n\nuser-&gt;student 能正常拿到、从接口返回学生信息\n\n\n\n\n\n关联模型查询\n## 查找出拥有指定 id 的角色的学生\nStudent::whereHas(&#039;users.roles&#039;, function ($query) use ($roleId) {\n    $query-&gt;where(&#039;id&#039;, $roleId);\n})-&gt;get();\n\n\n基于关联模型排序\n// examArrangement-&gt;examCourse-&gt;class-&gt;name\n-&gt;join(&#039;course_grade_exam_batch_courses&#039;, &#039;course_grade_exam_batch_courses.id&#039;, &#039;=&#039;, &#039;course_grade_exam_arrangements.exam_course_id&#039;)\n-&gt;join(&#039;school_roll_classes&#039;, &#039;school_roll_classes.id&#039;, &#039;=&#039;, &#039;course_grade_exam_batch_courses.class_id&#039;)\n-&gt;orderBy(&#039;school_roll_classes.name&#039;, &#039;asc&#039;)\n\n\n本地文件存储 §\n\n文件存储在 storage/app/public 目录下，保存的路径时不需要加 public/ 前缀\n保存客户端上传的文件\n\nuse app\\FileTrait;\n$file = $this-&gt;fileSave($request-&gt;file, &#039;enrollment/guide&#039;);\n\n\n生成访问链接时使用 \\Illuminate\\Support\\Facades\\Storage::url() 方法\n生成文件访问链接\n\nStorage::url() 方法\n\n文件保存位置 storage/app/public/\n\n\n或 url(config(&#039;app.url&#039;).&#039;/static/forms/缓考申请表.pdf&#039;\n\n文件在 public/\n\n\n\n\nRequest\n\n文件字段使用 Illuminate\\Http\\UploadedFile 类型，如 @property \\Illuminate\\Http\\UploadedFile $file\n验证规则使用 file 或 image，其他类型可以考虑使用 mimes，如：&#039;file&#039; =&gt; &#039;required|file|mimes:doc,docx&#039;\n\n对于 Office 文件，可以考虑多加一个 bin 到 mimes，如：&#039;file&#039; =&gt; &#039;required|file|mimes:doc,docx,bin&#039;，但必须用原文件名保存文件\n\n\n\n\nTODO：可能需要 Nginx + Lua 脚本来实现文件访问权限控制\n\n生成 Model 关系图 §\n\n安装 graphviz\ncomposer install\n修改 config/erd-generator.php\nphp artisan generate:erd [filename].png\n\n获取反代 IP §\n\nNginx\n\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header Host $http_host;\n\n设置中间件里的可信任列表\n\n# app/Http/Middleware/TrustProxies.php\nprotected $proxies = &#039;*&#039;;\n// config/app.php，这样设置未生效，待查\n&#039;trusted_proxies&#039; =&gt; [\n    &#039;*&#039;,\n],\n\n获取\n\n$request-&gt;ip();\n修改 storage_path() 默认路径 §\n# .env\n \n# 自定义 storage_path() 路径\nLARAVEL_STORAGE_PATH=/custom_path\nlaravel-ide-helper §\nGitHub - barryvdh/laravel-ide-helperl\n在线查看日志 §\n\nGitHub - rap2hpoutre/laravel-log-viewer\nGitHub - ARCANEDEV/LogViewer 日志一多会内存溢出。20240111\n"},"Linux-安装-oh-my-zsh":{"title":"Linux 安装 oh-my-zsh","links":["GitHub-加速访问"],"tags":["Linux","zsh"],"content":"安装 Zsh §\n\n\nhttps://github.com/ohmyzsh/ohmyzsh/wiki/Installing-ZSH\nsudo apt install zsh\n \n# 查看所有可用 shell\nchsh -l\n \n# 将终端默认 shell 切换到 zsh，后面要输入实际看到的 zsh 路径\nchsh -s /bin/zsh\n \n# 新开一个终端确认是否切换成功\necho $SHELL\n\n\n安装 Oh-my-zsh §\n\nhttps://ohmyz.sh/#install\n若安装时遇到网络问题则 GitHub 加速访问\n\n插件 §\n\ngit clone 到 .oh-my-zsh/custom/plugins\n\nhttps://github.com/zsh-users/zsh-syntax-highlighting.git\nhttps://github.com/zsh-users/zsh-autosuggestions.git\n\n\nautojump\n\nUbuntu：sudo apt install autojump\nCentos：yum install autojump-zsh\n\n\n修改 ~/.zshrc 文件的内容\n\nplugins=(git autojump zsh-autosuggestions zsh-syntax-highlighting)\n\n\n"},"Mac-应用已损坏":{"title":"Mac 应用已损坏","links":[],"tags":["Mac"],"content":"\n安装后打开提示已损坏时执行命令：sudo xattr -d com.apple.quarantine &quot;/Applications/{appName}.app&quot;\n"},"MySQL-实战-45-讲":{"title":"MySQL 实战 45 讲","links":["01｜基础架构：一条-SQL-查询语句是如何执行的？","02｜日志系统：一条-SQL-更新语句是如何执行的？","03｜事务隔离：为什么你改了为还看不见？","04｜深入浅出索引（上）","05｜深入浅出索引（下）","06｜全局锁和表锁：给表加个字段怎么有这么多阻碍？","07｜行锁功过：怎么减少锁对性能的影响？","08｜事务到底是隔离的还是不隔离的？","09｜普通索引和唯一索引，应该怎么选择？","10｜MySQL-为什么有时候会选错索引？","11｜怎么给字符串字段加索引？","12｜为什么我的-MySQL-会“抖”一下？","13｜为什么表数据删掉一半，表文件大小不变？","14｜count(*)-这么慢，我该怎么办？","15｜答疑文章（一）：日志和索引相关问题","16｜“order-by”是怎么工作的？","17｜如何正确地显示随机消息？","18｜为什么这些-SQL-语句逻辑相同，性能却差异巨大？","19｜为什么我只查一行的语句，也执行这么慢？","20｜幻读是什么，幻读有什么问题？","21｜为什么我只改一行的语句，锁这么多？","22｜MySQL有哪些“饮鸩止渴”提高性能的方法？","23｜MySQL-是怎么保证数据不丢的？","24｜MySQL-是怎么保证主备一致的？","25｜MySQL-是怎么保证高可用的？","26｜备库为什么会延迟好几个小时？","27｜主库出问题了，从库怎么办？","28｜读写分离有哪些坑？","29｜如何判断一个数据库是不是出问题了？","30｜答疑文章（二）：用动态的观点看加锁","31｜误删数据后除了跑路，还能怎么办？","32｜为什么还有-kill-不掉的语句？","33｜我查这么多数据，会不会把数据库内存打爆？","34｜到底可不可以使用-join-？","35｜join-语句怎么优化？","36｜为什么临时表可以重名？","37｜什么时候会使用内部临时表？","38｜都说-InnoDB-好，那还要不要使用-Memory-引擎？","39｜自增主键为什么不是连续的？","40｜insert-语句的锁为什么这么多？","41｜怎么最快地复制一张表？","42｜grant-之后要跟着-flush-privileges-吗？","43｜要不要使用分区表？","44｜答疑文章（三）：说一说这些好问题","45｜自增-id-用完怎么办？"],"tags":["MySQL","极客时间"],"content":"\n内容整理自极客时间《MySQL 实战 45 讲》\n\n章节分类 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n分类名章节基础知识01索引04、05、09、10、11、15、16、18事务03、08、20锁06、07、13、19、20、21、30、40日志与主备02、12、23、24、25、26、27、28、29、31临时表17、34、35、36、37、43实用性14、32、33、38、41、44、45\n基础篇 §\n\n01｜基础架构：一条 SQL 查询语句是如何执行的？\n02｜日志系统：一条 SQL 更新语句是如何执行的？\n03｜事务隔离：为什么你改了为还看不见？\n04｜深入浅出索引（上）\n05｜深入浅出索引（下）\n06｜全局锁和表锁：给表加个字段怎么有这么多阻碍？\n07｜行锁功过：怎么减少锁对性能的影响？\n08｜事务到底是隔离的还是不隔离的？\n\n实践篇 §\n\n09｜普通索引和唯一索引，应该怎么选择？\n10｜MySQL 为什么有时候会选错索引？\n11｜怎么给字符串字段加索引？\n12｜为什么我的 MySQL 会“抖”一下？\n13｜为什么表数据删掉一半，表文件大小不变？\n14｜count(*) 这么慢，我该怎么办？\n15｜答疑文章（一）：日志和索引相关问题\n16｜“order by”是怎么工作的？\n17｜如何正确地显示随机消息？\n18｜为什么这些 SQL 语句逻辑相同，性能却差异巨大？\n19｜为什么我只查一行的语句，也执行这么慢？\n20｜幻读是什么，幻读有什么问题？\n21｜为什么我只改一行的语句，锁这么多？\n22｜MySQL有哪些“饮鸩止渴”提高性能的方法？\n23｜MySQL 是怎么保证数据不丢的？\n24｜MySQL 是怎么保证主备一致的？\n25｜MySQL 是怎么保证高可用的？\n26｜备库为什么会延迟好几个小时？\n27｜主库出问题了，从库怎么办？\n28｜读写分离有哪些坑？\n29｜如何判断一个数据库是不是出问题了？\n30｜答疑文章（二）：用动态的观点看加锁\n31｜误删数据后除了跑路，还能怎么办？\n32｜为什么还有 kill 不掉的语句？\n33｜我查这么多数据，会不会把数据库内存打爆？\n34｜到底可不可以使用 join ？\n35｜join 语句怎么优化？\n36｜为什么临时表可以重名？\n37｜什么时候会使用内部临时表？\n38｜都说 InnoDB 好，那还要不要使用 Memory 引擎？\n39｜自增主键为什么不是连续的？\n40｜insert 语句的锁为什么这么多？\n41｜怎么最快地复制一张表？\n42｜grant 之后要跟着 flush privileges 吗？\n43｜要不要使用分区表？\n44｜答疑文章（三）：说一说这些好问题\n45｜自增 id 用完怎么办？\n"},"Obsidian-插件":{"title":"Obsidian 插件","links":[],"tags":["Obsidian"],"content":"推荐 §\n\nEnhancing Mindmap 文档转成思维导图，只需修改文档头，没有额外学习成本\nUpdate time on edit 自动更新文档的创建、更新时间\n\n改用仓库根目录下的 modify_updated.sh 脚本 + crontab\n\n\n\n待折腾 §\n\n玩转 Obsidian 08：利用 Dataview 打造自动化 HomePage | by 闲者时间 | Medium\n"},"Obsidian":{"title":"Obsidian","links":[],"tags":["软件"],"content":"\n官网\nObsidian 是一个功能强大且可扩展的知识库，它在您的本地纯文本文件文件夹之上运行。\n您现在浏览的数字花园的文本编辑器\n"},"Oh-My-Zsh":{"title":"Oh My Zsh","links":["Linux-安装-oh-my-zsh"],"tags":["工具","软件"],"content":"Linux 用户请看：Linux 安装 oh-my-zsh\n安装 §\n\n切换到系统自带的 Zsh：chsh -s /bin/zsh\nOh My Zsh\n\n系统终端的配色方案 §\n\n\nPowerlevel10k\n\n\n下载\ncd ~/Downloads\ngit clone git://github.com/altercation/solarized.git\n\n\n打开终端，按「⌘ + ,」打开终端偏好设置，点击「描述文件 &gt; ⚙︎⌄ &gt; 导入」，选择「osx-terminal…ors-solarized/xterm 256 color」\n\n\n插件 §\nbrew install autojump\nbrew install zsh-syntax-highlighting\nbrew install zsh-autosuggestions\n \n# 添加以下内容到 .zshrc 文件末尾（上面三条命令运行结束会有提示）\n \n# zsh plugins\nsource /opt/homebrew/share/zsh-autosuggestions/zsh-autosuggestions.zsh\nsource /opt/homebrew/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\n[ -f /opt/homebrew/etc/profile.d/autojump.sh ] &amp;&amp; . /opt/homebrew/etc/profile.d/autojump.sh\nHIST_STAMPS=&quot;mm/dd/yyyy&quot;"},"PHP-开发设置":{"title":"PHP 开发设置","links":[],"tags":["PHP","WIP"],"content":"Laravel Pint §\n\n如何在PHPSTORM 配置Laravel Pint 代码格式化包\nLaravel Pint\n\nVSCode §"},"PHP-测试":{"title":"PHP 测试","links":[],"tags":["PHP","测试"],"content":"\n10 testing best practices for Laravel in 2023\n"},"PHP-错误码设计":{"title":"PHP 错误码设计","links":[],"tags":["PHP","WIP"],"content":"目标 §\n错误码包含：数字、英文、含义，还可以有 HTTP Status\n这些最好放到一起，不然添加时容易漏\n方案 §\n静态变量：数组\n多个名字类似的静态变量\n静态工厂方法\n枚举和注解\n讨论 §\n结论 §\n参考 §\n\nUsing attributes to add value\nPHP 异常与错误处理\n"},"PHP-FPM-配置":{"title":"PHP-FPM 配置","links":[],"tags":["PHP","php-fpm"],"content":"以下内容适用于 IO 密集型应用\n一个 PHP-FPM 进程大约占 30M 内存\n\n进程数量\n\n计算公式：进程数 = 内存大小（M） * 0.6 / 30\n举例：8G * 1024 * 0.6 / 30 = 163.84\n\n\nmax_requests\n\n每个进程重启前可以处理的请求数\n由 pm.max_children 的值和每秒的实际请求数量决定\n\n\n\n参考文章\n\nFastCGI 进程管理器（FPM）\nPHP-FPM tuning: Using ‘pm static’ for Max Performance（译文）\nPHP-FPM 配置\nPHP-FPM 进程数设置多少合适\n"},"PHP":{"title":"PHP","links":["PHP-开发设置","PHP-FPM-配置","PHP-错误码设计","Laravel-Pint-使用","Laravel-开发注意事项"],"tags":["PHP"],"content":"\nPHP 开发设置\nPHP-FPM 配置\nPHP 错误码设计\nLaravel Pint 使用\nLaravel 开发注意事项\n"},"README":{"title":"README","links":[],"tags":[],"content":"🫧 11ze §"},"Rate-Limit":{"title":"Rate Limit","links":[],"tags":["开发","设计","编程"],"content":"功能 §\n限制接口请求数\n缓存数据格式 §\nkey: {\n  current_count: number; // 也可以不要该字段，每次请求都算一次队列长度\n  started_at: date;\n  request_time_queue: date[];\n  time_range: number; // 时间窗口大小\n  count_limit: number;\n}\n实现流程 §\n\n请求进来\n拼接出 key\n查找 key 对应的缓存\n取出队头，跟当前时间比较\na. 若超出时间窗口，则移除，继续取下一个\n查看当前累积请求数量\n跟 limit 比较，若大于等于，拒绝请求\n若小于\na. 将当前时间加入队列\nb. 当前请求数量 + 1\n"},"Redis-学习路径":{"title":"Redis 学习路径","links":[],"tags":["Redis"],"content":"\n\n掌握数据结构和缓存的基本使用方法\n\n\n学会基础数据类型的用法\n\nString\nList\nHash\nSet\nSorted Set\n\n\n\n掌握扩展数据类型的用法\n\nHyperLogLog\nBitmap\nGEO\n\n\n\n积累 Redis 用作缓存的方法以及典型问题的解决方案\n\n数据库和 Redis 缓存的数据一致性问题\n缓存穿透问题\n缓存雪崩问题\n\n\n\n\n\n掌握支撑 Redis 实现高性能、高可靠的技术点\n\n持久化机制\n主从复制机制\n哨兵机制\n故障自动恢复\n切片集群\n\n\n\n精通 Redis 底层实现原理\n\n\n数据结构的实现原理\n\n\n高性能、高可靠相关的一系列原理\n\n持久化\n哨兵集群：分布式系统的选举问题和共识问题\n切片集群：分布式系统的很多问题，例如 CAP 原理、分布式事务、架构设计\n\n\n\n\n"},"Redis-客户端如何与服务端交换命令和数据？":{"title":"Redis 客户端如何与服务端交换命令和数据？","links":[],"tags":["Redis"],"content":"客户端和服务端交互内容 §\n\n命令\n键\n单个值\n集合值\nOK 回复\n整数回复\n错误信息\n\nRESP 2 协议 §\n\n\n两个基本规范\n\n\n\n实现 5 种编码格式类型，在每种编码类型的开头使用一个专门的字符区分\n\n\n\n\n按照单个命令或单个数据的粒度进行编码，在每个编码结果后面增加一个换行符 \\r\\n 表示编码结束\n\n\n\n\n\n\n\n简单字符串类型 RESP Simple Strings\n\n\n\n+OK\\r\\n\n\n\n\n\n\n长字符串类型 RESP Bulk String\n\n\n\n\n$9 testvalue\\r\\n\n\n\nRedis SDS 结构\n\nlen = 14; alloc; buf (“Redis\\0Cluster\\0”)\n\\0 解析成正常的 0 字符\n\n\n\n最大 512MB\n\n\n\n\n\n\n\n\n\n整数类型 RESP Integer\n\n\n\n:3\\r\\n\n\n\n\n\n\n错误类型 RESP Errors\n\n\n\n-ERR unknown command PUT, with args beginning with: testkey, testvalue\n\n\n\n\n\n数组编码类型 RESP Arrays\n\n\n\n*2\\r\\n3\\nGET˚​\\n˚​7\\r\\ntestkey\\r\\n\n2：数组元素个数，命令 GET 和键 testkey\n\n\n\n不足\n\n\n\n只能区分字符串和整数，其他类型需要客户端进行额外的转换操作\n\n\n\n\n使用数组类别编码表示所有的集合类型，客户端需要根据发送的命令操作把返回结果转换成相应的集合类型数据结构\n\n\n\n\n\nRESP 2 协议的 5 种编码类型和相应的开头字符\n\n\n\n\n\nRESP 3 协议（6.0） §\n\n\n增加对多种数据类型的支持，包括空值、浮点数、布尔值、有序的字典集合等\n\n也是通过不同的开头字符进行区分\n客户端不用再通过额外的字符串比对来实现数据转换操作\n\n\n\n小工具 §\n\n\ntelnet 实例IP 实例端口\n\n然后在 telnet 中给实例发送命令，就能看到 RESP 协议编码后的返回结果\n也可以在 telnet 中向 Redis 实例发送用 RESP 协议编写的命令操作\n\n\n"},"Redis-有哪些好用的运维工具？":{"title":"Redis 有哪些好用的运维工具？","links":["11｜“万金油”的-String，为什么不好用了？"],"tags":["Redis"],"content":"\n\n最基本的监控命令：INFO 命令\n\n\nINFO 命令的返回信息\n\n\n\n\n\n重点关注 stat、commandstat、cpu、memory 参数的返回结果\n\n\n通过 persistence 参数的返回结果查看 RDB 或者 AOF 的执行情况\n\n\n通过 replication 参数的返回结果查看主从集群的实时状态\n\n\n\n\n面向 Prometheus 的 Redis-exporter 监控\n\n开源的系统监控报警框架\n结合 Grafana 进行可视化展示\n支持 Redis 2.0 ～ 6.0\n有插件，也可以运行 Lua 脚本\n主流工具（2021.10.1）\n\n\n\n轻量级的监控工具\n\nRedis-stat\nRedis Live\n\n\n\n数据迁移工具 Redis-shake\n\n\n阿里云 Redis 和 MongoDB 团队开发的数据同步工具\n\n\n进行数据迁移的过程\n\n\n\n\n\n运行原理\n\n\n先启动 Redis-shake 进程，进程模拟了一个 Redis 实例，然后进程和数据迁出的源实例进行数据的全量同步\n\n\n和 Redis 主从实例的全量同步类似\n\n\n源实例相当于主库，Redis-shake 相当于从库\n\n\n\nRDB 文件 -&gt; Redis-shake -&gt; 目的实例\n\n\n\n\n增量命令 -&gt; Redis-shake -&gt; 目的实例\n\n\n\n\n\n优势\n\n支持单个实例、集群、proxy、云下的 Redis 实例的数据迁移\n\n\n\n\n\n迁移后通常需要对比源实例和目的实例的数据是否一致，如果不一致，需要找出来，从目的实例剔除或再次迁移不一致的数据\n\n\n阿里云团队开发的 Redis-full-check\n\n多轮比对\n三种对比模式\n\n\n\n\n\n\n\n集群管理工具 CacheCloud\n\n实现了主从集群、哨兵集群、Redis Cluster 的自动部署和管理\n提供 5 个运维操作和丰富的监控信息\n\n\n\n评论区：热 key 查找工具 redis-faina\n\n\n其他章节提到的\n\n\nRedis 容量预估工具\n\n11｜“万金油”的 String，为什么不好用了？\n\n\n\n\n"},"Redis-核心技术与实战":{"title":"Redis 核心技术与实战","links":["00｜开篇词","01｜基础架构：一个键值数据库包含什么？","02｜数据结构：快速的-Redis-有哪些慢操作？","03｜高性能-IO-模型：为什么单线程-Redis-那么快？","04｜AOF-日志：宕机了，Redis-如何避免数据丢失？","05｜内存快照：宕机后，Redis-如何实现快速恢复？","06｜数据同步：主从库如何实现数据一致？","07｜哨兵机制：主库挂了，如何不间断服务？","08｜哨兵集群：哨兵挂了，主从库还能切换吗？","09｜切片集群：数据增多了，是该加内存还是加实例？","11｜“万金油”的-String，为什么不好用了？","12｜有一亿个-keys-要统计，应该用哪种集合？","13｜GEO-是什么？还可以定义新的数据类型吗？","14｜如何在-Redis-中保存时间序列数据？","15｜消息队列的考验：Redis-有哪些解决方案？","16｜异步机制：如何避免单线程模型的阻塞？","17｜为什么-CPU-结构也会影响-Redis-的性能？","18｜波动的响应延迟：如何应对变慢的-Redis？（上）","19｜波动的响应延迟：如何应对变慢的-Redis？（下）","20｜删除数据后，为什么内存占用率还是很高？","21｜缓冲区：一个可能引发“惨案”的地方","22｜第-11～21-讲课后思考题答案及常见问题答疑","23｜旁路缓存：Redis-是如何工作的？","24｜替换策略：缓存满了怎么办？","25｜缓存异常（上）：如何解决缓存和数据库的数据不一致问题？","26｜缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？","27｜缓存被污染了，该怎么办？","28｜Pika：如何基于-SSD-实现大容量-Redis？","29｜无锁的原子操作：Redis-如何应对并发访问？","30｜如何使用-Redis-实现分布式锁？","31｜事务机制｜Redis-能实现-ACID-属性吗？","32｜Redis-主从同步与故障切换，有哪些坑？","33｜脑裂：一次奇怪的数据丢失","35｜Codis-VS-Redis-Cluster：我该选择哪一个集群方案？","36｜Redis-支撑秒杀场景的关键技术和实践都有哪些？","37｜数据分布优化：如何应对数据倾斜？","38｜通信开销：限制-Redis-Cluster-规模的关键因素","39｜Redis-6.0-的新特性：多线程、客户端缓存与安全","40｜Redis-的下一步：基于-NVM-内存的实践","41｜第-35～40-讲课后思考题答案及常见问题答疑","经典的-Redis-学习资料","Redis-学习路径","Redis-客户端如何与服务端交换命令和数据？","Redis-有哪些好用的运维工具？","Redis-的使用规范小建议","从微博的-Redis-实践中，我们可以学到哪些经验？"],"tags":["Redis","极客时间"],"content":"\n内容整理自极客时间《Redis 核心技术与实战》\n\n基础篇 §\n\n00｜开篇词\n01｜基础架构：一个键值数据库包含什么？\n02｜数据结构：快速的 Redis 有哪些慢操作？\n03｜高性能 IO 模型：为什么单线程 Redis 那么快？\n04｜AOF 日志：宕机了，Redis 如何避免数据丢失？\n05｜内存快照：宕机后，Redis 如何实现快速恢复？\n06｜数据同步：主从库如何实现数据一致？\n07｜哨兵机制：主库挂了，如何不间断服务？\n08｜哨兵集群：哨兵挂了，主从库还能切换吗？\n09｜切片集群：数据增多了，是该加内存还是加实例？\n\n实践篇 §\n\n11｜“万金油”的 String，为什么不好用了？\n12｜有一亿个 keys 要统计，应该用哪种集合？\n13｜GEO 是什么？还可以定义新的数据类型吗？\n14｜如何在 Redis 中保存时间序列数据？\n15｜消息队列的考验：Redis 有哪些解决方案？\n16｜异步机制：如何避免单线程模型的阻塞？\n17｜为什么 CPU 结构也会影响 Redis 的性能？\n18｜波动的响应延迟：如何应对变慢的 Redis？（上）\n19｜波动的响应延迟：如何应对变慢的 Redis？（下）\n20｜删除数据后，为什么内存占用率还是很高？\n21｜缓冲区：一个可能引发“惨案”的地方\n22｜第 11～21 讲课后思考题答案及常见问题答疑\n23｜旁路缓存：Redis 是如何工作的？\n24｜替换策略：缓存满了怎么办？\n25｜缓存异常（上）：如何解决缓存和数据库的数据不一致问题？\n26｜缓存异常（下）：如何解决缓存雪崩、击穿、穿透难题？\n27｜缓存被污染了，该怎么办？\n28｜Pika：如何基于 SSD 实现大容量 Redis？\n29｜无锁的原子操作：Redis 如何应对并发访问？\n30｜如何使用 Redis 实现分布式锁？\n31｜事务机制｜Redis 能实现 ACID 属性吗？\n32｜Redis 主从同步与故障切换，有哪些坑？\n33｜脑裂：一次奇怪的数据丢失\n35｜Codis VS Redis Cluster：我该选择哪一个集群方案？\n36｜Redis 支撑秒杀场景的关键技术和实践都有哪些？\n37｜数据分布优化：如何应对数据倾斜？\n38｜通信开销：限制 Redis Cluster 规模的关键因素\n\n未来篇 §\n\n39｜Redis 6.0 的新特性：多线程、客户端缓存与安全\n40｜Redis 的下一步：基于 NVM 内存的实践\n41｜第 35～40 讲课后思考题答案及常见问题答疑\n\n加餐篇 §\n\n经典的 Redis 学习资料\nRedis 学习路径\nRedis 客户端如何与服务端交换命令和数据？\nRedis 有哪些好用的运维工具？\nRedis 的使用规范小建议\n从微博的 Redis 实践中，我们可以学到哪些经验？\n"},"Redis-的使用规范小建议":{"title":"Redis 的使用规范小建议","links":[],"tags":["Redis"],"content":"键值对使用规范 §\n\n\n\n\n通过命名区分不同业务数据\n\n\n\n\nSELECT 命令进行数据库切换相当于增加一个额外的操作\n\n\n业务名缩写作为 key 的前缀\n\n对于业务名或业务数据名，可以使用相应的英文单词的首字母表示，（比如 user 用 u 表示，message 用 m），或者是用缩写表示（例如 unique visitor 使用 uv）。\n\n\n\n\n\n\n\n避免使用 bigkey\n\n\n\n尽量把集合类型的元素个数控制在 1 万以下\n控制 String 类型数据的大小不超过 10KB\n\n\n\n\n使用高效序列化方法和压缩方法减小 value 的大小\n\n\n\n\n\n使用整数对象共享池\n\n\n\n\n如果一个键值对中有 0 到 9999 范围的整数，Redis 会服用共享池中的整数对象\n\n\n不能用的情况\n\n\n\nRedis 设置了 maxmemory 并且启用 LRU 策略，因为 LRU 策略需要统计每个键值对的使用时间\n\n\n\n\n集合类型数据采用 ziplist 编码，而集合元素是整数，判断整数对象的共享情况效率低\n\n\n\n\n\n\n\n数据保存规范 §\n\n\n\n使用 Redis 保存热数据\n\n\n\n\n不同的业务数据分实例存储\n\n\n\n\n在数据保存时要设置过期时间\n\n\n\n\n\n控制 Redis 实例的容量\n\n\n\n\n单实例不要太大，建议设置在 2～6GB\n\nRDB 快照、主从集群数据同步都能很快完成\n\n\n\n\n\n命令使用规范 §\n\n\n\n\n线上禁用部分命令\n\n\n\n\nKEYS、FLUSHALL、FLUSHDB\n\n严重阻塞主线程\n\n\n\n具体的做法：管理员用 rename-command 命令在配置文件中重命名这些命令\n\n\n替代：SCAN、ASYNC 选项（分别对应上面的 KEYS，FLUSHALL、FLUSHDB）\n\n\n\n\n\n\n慎用 MONITOR 命令\n\n\n\n会把监控到的内容持续写入到输出缓冲区，可能很快溢出，对性能造成影响甚至引起服务崩溃\n\n\n\n\n\n慎用全量操作命令\n\n\n\n\nHGETALL、SMEMBERS 等\n\n全量扫描\n\n\n\n建议\n\n\n\n使用 SSCAN、HSCAN 命令分批返回集合中的数据\n\n\n\n\n大集合拆分成小集合\n\n\n\n\n如果集合类型保存的是业务数据的多个属性，而每次查询时，也需要返回这些属性，那么可以使用 String 类型，将这些属性序列化后保存，每次直接返回 String 数据，不用再对集合类型做全量扫描\n\n\n\n\n\n\n\n规范汇总 §\n\n强制类别的规范：如果不按照规范内容来执行，就会给 Redis 的应用带来极大的负面影响，例如性能受损。\n推荐类别的规范：能有效提升性能、节省内存空间，或者是增加开发和运维的便捷性，可以直接应用到实践中。\n建议类别的规范：这类规范内容和实际业务应用相关，结合自己的业务场景参考使用。\n\n\n面向业务开发人员 §\n\nkey 的长度尽量短，节省内存空间\n避免 bigkey，防止阻塞主线程\n4.0+ 版本建议开启 lazy-free\n把 Redis 当作缓存使用，设置过期时间\n不使用复杂度过高的命令，例如SORT、SINTER、SINTERSTORE、ZUNIONSTORE、ZINTERSTORE\n查询数据尽量不一次性查询全量，写入大量数据建议分多批写入\n批量操作建议 MGET/MSET 替代 GET/SET，HMGET/HMSET 替代 HGET/HSET\n禁止使用 KEYS/FLUSHALL/FLUSHDB 命令\n避免集中过期 key\n根据业务场景选择合适的淘汰策略\n使用连接池操作 Redis，并设置合理的参数，避免短连接\n只使用 db0，减少 SELECT 命令的消耗\n读请求量很大时，建议读写分离，写请求量很大，建议使用切片集群\n\n面向 DBA 运维人员 §\n\n按业务线部署实例，避免多个业务线混合部署，出问题影响其他业务\n保证机器有足够的 CPU、内存、带宽、磁盘资源\n建议部署主从集群，并分布在不同机器上，slave 设置为 readonly\n主从节点所部署的机器各自独立，尽量避免交叉部署，对从节点做维护时，不会影响到主节点\n推荐部署哨兵集群实现故障自动切换，哨兵节点分布在不同机器上\n提前做好容量规划，防止主从全量同步时，实例使用内存突增导致内存不足\n做好机器 CPU、内存、带宽、磁盘监控，资源不足时及时报警，任意资源不足都会影响 Redis 性能\n实例设置最大连接数，防止过多客户端连接导致实例负载过高，影响性能\n单个实例内存建议控制在 10G 以下，大实例在主从全量同步、备份时有阻塞风险\n设置合理的 slowlog 阈值，并对其进行监控，slowlog 过多需及时报警\n设置合理的 repl-backlog，降低主从全量同步的概率\n设置合理的 slave client-output-buffer-limit，避免主从复制中断情况发生\n推荐在从节点上备份，不影响主节点性能\n不开启 AOF 或开启 AOF 配置为每秒刷盘，避免磁盘 IO 拖慢 Redis 性能\n调整 maxmemory 时，注意主从节点的调整顺序，顺序错误会导致主从数据不一致\n对实例部署监控，采集 INFO 信息时采用长连接，避免频繁的短连接\n做好实例运行时监控，重点关注 expired_keys、evicted_keys、latest_fork_usec，这些短时突增可能会有阻塞风险\n扫描线上实例时，记得设置休眠时间，避免过高 OPS 产生性能抖动\n\n延伸阅读 §\n\n《Redis最佳实践：7个维度+43条使用规范，带你彻底玩转Redis》\n《阿里云｜云数据库 Redis 开发运维规范》\n"},"Think-in-English":{"title":"Think in English","links":[],"tags":["英语"],"content":"How to THINK in English | No More Translating in Your Head! - YouTube\nIntroduction §\nIf you’re translating in your head, then you know that that’s a frustrating way to speak English. But the good news is there are concrete things you can do and practice to stop translating in your head and start thinking in English. In this video we’re going to give you tips and strategies to start thinking in English, stop translating in your head, and increase fluency speaking English. And what a better way to start 2020 than with this goal.\nSetting the Goal §\nFirst, I want you to name one reason why you want to start thinking in English. I want to learn to think in English so I can easily participate in conversation. Whatever your reason is, I know it’s a good one. And I think in 2020, you can make that happen.\nTip 1: Start Simple §\nThe first tip is to start simple and name objects around you in English.\nI remember when I was learning German and I was doing this, I had to learn the article as well, der, die, das. We don’t have that in English, but it doesn’t hurt to really focus on the pronunciation as you’re thinking of simple objects. In fact, that’s why I started my YouTube channel and even my Academy – when I was learning German, French, and Italian as an opera student, I couldn’t find any resources that focused enough on pronunciation. And I knew that to be effective, I needed the right pronunciation right from the beginning. So I created my YouTube channel and my Academy to put pronunciation forward.\nSo take a moment as you’re naming objects to think about pronunciation. Closet. Box. Million subscriber button. Cool. Globe. Window. And if you’re not sure about the pronunciation, listen to some native speakers. You can use an online dictionary. Also, Youglish is a great resource for this. Computer, compute.They’re all saying with a flap. Compu— rarararara. A flap instead of TT, a T sound. Computer. Computer. Middle syllable stress. If you can add this step, of focusing on the pronunciation and listening to native speakers, awesome. If not, if you only have 15 seconds, and you’re naming as many as you can, that’s okay too. So that’s step one and it’s simple.\nTake a moment, look around you, and name all of the objects that you can in English. If you can do that very easily, then you can move on. But if that’s a challenge for you, spend some time on object naming. Every time you’re in a new room, a new environment, take a few seconds to do it. Note words you don’t know, look them up, learn them. The context will help you remember them.\nTip 2: Think in Simple Sentences §\nThe next step is to think in simple sentences.\nStop right now and think of the beginning of a sentence: I’m---. I’m hungry, I’m tired, I’m working. Do it in English. I’ll wait a few seconds. You’re starting with ‘I’m…’\nNow look around you. What can you say about anything in your environment? This chair is comfy. The drawer is open. My desk is messy. That one’s easy because it’s almost always true. If there’s something you can’t describe, look up the words you need in a dictionary, memorize it. Memorize that phrase. Learning in context like this will help.\nTip 3: Use English-Only Dictionary §\nSpeaking of dictionaries, see if you can do this. Get an English-only dictionary rather than a translating dictionary between English and your native language.\nIf you come across a word in English that you don’t know, use the English-only dictionary, a Learner’s dictionary. Can you see what we’re doing here? We’re building your mind to work in English mode rather than translation mode. There is a thing called a Learner’s dictionary, and it describes every word in English, in simple words and terms. Try it. Merriam-Webster has one, Oxford, Cambridge. If you have to learn and understand a word by reading in English, by studying what it means in English, then you’ll know it as an English word. Not as a translation of your language. So you’ve named single words, and you’ve made simple sentences.\nTip 4: Have Small Conversations with Yourself in English §\nWith yourself? Yes, you don’t feel pressure to speak quickly, to come up with the next thing. You can keep the pace slow, relaxed. I absolutely did this when learning Spanish. In fact, I remember a car trip I did by myself from Sarasota to Gainesville where the whole time I spoke to myself in Spanish. If this is hard for you, stop and give up. No! It will get better and easier with practice. Do it every day. Set aside 2 minutes every day to have a simple conversation with yourself. Give yourself 30 days. Do this every day for 30 days. Don’t take a day off. If you have five minutes one day, do it for five minutes. A whole conversation, as simple as it needs to be, in English. In 30 days, you’ll see. Wow. I did improve. This is worth my time. And rededicate 30 more days.\nOnce you’re able to do this, I think you’re able to do step 5, which is really exciting.\nTip 5: Change Everyday Life Things to English §\nChange at least one of your everyday life things to English.\nEveryday life things? What’s that? Switch your calendar to English. Use the English months and days of the week and write what you’re going to be doing in English.\nOr do you do to-do lists? Try it in English. A grocery list. Or change your Facebook settings so that your language is in English. Everything you see, you’ve got a friend request, and so on, will be in English. Maybe try internet searches in English. Or read an English newspaper, or listen to news in English. Do you write a journal? Try writing it in English. Yes! I love this. Take one everyday thing and do it in English. Switch your brain. Every morning when you wake up, before you get out of bed, take two minutes to think about your day in English.\nTip 6: Learn How to Do One Thing in English §\nHere’s another idea of an everyday thing you can do in English: take one thing like getting dressed, making breakfast, getting from your car to your desk, cleaning up. As you’re doing it, in your head, narrate in English. Laundry day. That’s light, that should go there. Let’s see. Does this need to be sprayed for stains? Yeah. Better spray it. All right, let’s load up the washing machine. That’s too light, that should go there. Okay, shove it all in. Let’s get some soap. Where is that? Here it is. Put it in there, close the door, press ‘start’, there we go!\nAnd here’s another one I love: learn how to do one thing in English. It can be really small, like, how to poach an egg. Research it and learn about it in English only, watch only English videos and read only English instructions.\nOr maybe it’s something bigger, a bigger project like how to knit or how to draw. Take an online course in English only on that topic. Pick something you’re dying to know how to do anyway. This will make it a super-enjoyable lesson.\nTip 7: Keep Track of Your Progress §\nThe next step is something you’re actually going to want to be doing all along, with all the steps, and that’s… keep track so you’re doing it every day.\nOnce you choose that you want to think English and stop translating in your head, write down every day what you do.\nAnd of course, do this in English. It could look like this: Today I named everything around me that I could think of in English two different times. I watched a 3-minute news story in English. Just having a place to write it down can motivate you to do it.\nTip 8: Recap Your Day in English §\nAnd the last thing is something you can do every night after you lay down for bed, but before you fall asleep. Recap your day in English. You’re taking advantage of this opportunity that you’ll have every day, no matter where you are or what your day was like: no one I know falls asleep the moment their head hits the pillow. What a lovely day that was. I got to meet my mom for lunch, go for a walk in the afternoon, and I even had time to watch a movie after I put the kids down to bed. And who knows, by putting your mind in English mode just before bed, maybe you’re even setting yourself up to dream in English, continuing your practice. The brain does amazing things with what it’s learned that day while you sleep."},"Tips":{"title":"Tips","links":[],"tags":["idea","思考"],"content":"\n想到什么点子就赶紧记下来，否则只是上个厕所洗个手也能忘。\n做一件事的时候，想象一下，最坏的情况能坏到哪里。\n找出自己擅长和不擅长做的事。\n什么工作是我非做不可的。\n善用搜索。\n把一天已经过的部分当成一个个快照、当前状态，我要基于当前状态做下一个决定。重复此流程。\n"},"Vault":{"title":"Vault","links":[],"tags":["Obsidian"],"content":"\n保管库是本地文件系统上的一个文件夹，Obsidian 将您的笔记存储在其中。您可以将所有笔记保存在一个保险库中，或为每个不同的项目创建多个保险库。\n\nCreate a vault - Obsidian Help"},"iCloud-不同步指定文件":{"title":"iCloud 不同步指定文件","links":[],"tags":["iCloud"],"content":"说明 §\niCloud 不同步带有 .nosync 后缀的文件和文件夹\n使用场景 §\n在 iCloud 中忽略 .git 且 Git 命令可以正常使用 §\ncd repo\nmv .git .git.nosync\nln -s .git.nosync .git"},"iCloud-同步卡住":{"title":"iCloud 同步卡住","links":[],"tags":["Mac","iCloud"],"content":"解决方案 §\n\n\n~/.zshrc\n# ~/.zshrc\nalias killicloud=&#039;killall bird &amp;&amp; killall cloudd&#039;\n\n\n终端执行命令 kill iCloud 进程\nkillicloud\n\n\n点击访达侧边栏的 iCloud ，观察同步进度，若还是卡住，继续 kill iCloud 进程直到正常\n\n\n\n\n\n\n每 10 分钟执行一次确保 iCloud 正常同步\n$ crontab -e\n*/10 * * * * killall bird &amp;&amp; killall cloudd # kill iCloud 进程\n\n\n参考 §\n\n一日一技 | Mac 上 iCloud 云盘同步卡住了？可以试试这样做\n"},"index":{"title":"11ze's Garden","links":["tags","英语","Docker","搭建数字花园","MySQL-实战-45-讲","Redis-核心技术与实战"],"tags":[],"content":"\nTags\n英语\nDocker\n搭建数字花园\nMySQL 实战 45 讲\nRedis 核心技术与实战\n"},"从微博的-Redis-实践中，我们可以学到哪些经验？":{"title":"从微博的 Redis 实践中，我们可以学到哪些经验？","links":[],"tags":["Redis"],"content":"微博对 Redis 的技术需求 §\n\n\n\n能够提供高性能、高并发的读写访问，保证读写延迟低\n\n\n\n\n能够支持大容量存储\n\n\n\n\n可以灵活扩展，对于不同业务能进行快速扩容\n\n\n\n对 Redis 的基本改进 §\n\n避免阻塞和节省内存\n持久化需求：使用全量 RDB + 增量 AOF 复制\n在 AOF 日志写入刷盘时，用额外的 BIO 线程负责实际的刷盘工作，避免 AOF 日志慢速刷盘阻塞主线程\n增加 aofnumber 配置项设置 AOF 文件的数量\n使用独立的复制线程进行主从库同步，避免对主线程的阻塞影响\n\n定制化设计了 LongSet 数据类型 §\n数据区分冷热度 §\n\n用异步线程将冷数据从 Redis 迁移到 RocksDB，保存到硬盘中\n\n\n\n\n\n服务化改造 §\n\n\n使用 Redis 集群服务不同的业务场景需求，每一个业务拥有独立的资源\n\n\n所有的 Redis 实例形成资源池，轻松扩容\n\n\n采用类似 Codis 的方案，通过集群代理层连接客户端和服务端\n\n客户端连接监听和端口自动增删\nRedis 协议解析：确定需要路由的请求，如果是非法和不支持的请求，直接返回错误\n请求路由：根据数据和后端实例间的映射规则，将请求路由到对应的后端实例进行处理，并将结果返回给客户端\n指标采集监控：采集集群运行的状态，并发送到专门的可视化组件，由这些组件进行监控处理\n配置中心：管理整个集群的元数据\n\n\n\n微博 Redis 服务化集群架构图\n\n\n\n\n\n原文 §\n\n万亿级日访问量下，Redis 在微博的 9 年优化历程\n"},"发布方案":{"title":"发布方案","links":[],"tags":["搭建"],"content":"选用方案 §\n\nquartz\n\n怎么做 §\n\n将笔记仓库作为发布仓库的 content/ 即可\n"},"发布笔记-404":{"title":"笔记 404","links":["2023-05-12","ISO8601"],"tags":["搭建"],"content":"\n记录此问题的时间：2023-05-12 01:26 东八区\n\n现象 §\n\n文档在 2023-05-12 0 点创建，发布失败，改成 2023-05-11，发布成功\n笔记出现在搜索结果，点击自动跳转到 404 页面\n\n猜测 §\n\nGitHub Action 服务器时间比文档头标记的创建时间早，文档属于未来，所以未发布成功\n2023-05-12 08:00 尝试发布成功\n\n解决方法 §\n\n使用 ISO8601 格式的日期\n"},"同步方案":{"title":"同步方案","links":["Obsidian","Vault","iCloud-同步卡住"],"tags":["搭建","iCloud","同步"],"content":"多种方案 §\n\nObsidian Sync：官方，要钱\nRemotely Sync：第三方插件，但自动同步最短间隔 1 分钟（可以手动同步），免费\niCloud：实时同步，免费\n\n我使用的同步方案（iCloud） §\n优点 §\n免费实时同步文档、插件、设置\n怎么做 §\n我的设备：iPhone + MacBook\n\n\niPhone 安装 Obsidian\n\n\n进入 Obsidian 创建一个打开 iCloud 同步功能的 Vault\n\n\n\n\n\n此时 iCloud 中会生成 Vault 目录\n\n\n\n\n\nMacBook 安装 Obsidian\n\n\n用 Obsidian 打开 2 创建的目录\n\n\n遇到的问题 §\n\niCloud 同步卡住\n"},"学习方法":{"title":"学习方法","links":[],"tags":["效率","学习"],"content":"费曼学习法 §\n\n\n\nhttps://mp.weixin.qq.com/s/mUAQX_2b0Ut3APWB-pyYSQ\n\n\n\n\n在纸上写下要学习的知识点\n\n\n\n\n写下自己对于这个知识点所知的一切, 然后假装讲给一个孩子听\n\n\n\n\n反复理解: 复习卡住的地方, 直到能用大白话讲清楚为止\n\n\n\n\n在第二步的基础上进行补充和简化, 循环\n\n\n\n\n\n高效学习: 深度, 归纳和坚持时间 §\n\n\n\nhttps://time.geekbang.org/column/article/14360\n\n\n\n系统地学习（学习模板）\n\n\n\n这个技术出现的背景、初衷和要达到什么样的目标或是要解决什么样的问题\n\n\n\n\n这个技术的优势和劣势分别是什么，或者说，这个技术的 trade-off 是什么\n\n\n\n\n这个技术适用的场景\n\n\n\n\n技术的组成部分和关键点\n\n\n\n\n技术的底层原理和关键实现\n\n\n\n\n已有的实现和它之间的对比\n\n\n\n\n\n系统学习完了？举一反三\n\n\n\n联想, 抽象, 自省\n\n\n\n\n\n总结和归纳\n\n\n\n学习的开始阶段，可以不急于总结归纳，不急于下判断，做结论，而应该保留部分知识的不确定性，保持对知识的开放状态\n\n\n\n\n把看到和学习到的信息，归整好，排列好，关联好，总之把信息碎片给结构化掉，然后在结构化的信息中，找到规律，找到相通之处，找到共同之处，进行简化、归纳和总结，最终形成一种套路，一种模式，一种通用方法\n\n\n\n\n\n分享\n\n\n\n每周写一个 ARTS：Algorithm 是一道算法题，Review 是读一篇英文文章，Technique/Tips 是分享一个小技术，Share 是分享一个观点\n\n\n\n\n坚持一年\n\n\n\n\n晒出来, 可以是单一篇文章: 每周学习报告, 可以是多篇文章: 博客\n\n\n\n\n\n十步学习法 §\n\n\n\n《软技能：代码之外的生存指南》\n\n\n\n\n如何开始——要想开始使用自己所学的，我需要掌握哪些基本知识？\n\n\n\n\n学科范围——我现在学的东西有多宏大？我应该怎么做？\n\n\n\n\n基础知识——不止在开始阶段，要想使用一项特定的技术，我需要了解基本的用户案例和最常见的问题，也需要知道自己学的哪 20% 就能满足 80% 的日常应用\n\n\n\n\n执行\n\n说明\n\n1 - 6 走一遍（所有步骤都是为了 3）\n7 - 10 重复\n先完整过一遍再尝试优化成自己的学习方法\n\n\n步骤\n\n\n\n了解全局：网上搜索关键字\n\n\n\n\n确定范围：缩小到一个特定的范围，一次只学一样东西。如「学习 C#」改为「学习 C# 的基础知识，掌握如何创建一个简单的控制台程序」\n\n\n\n\n定义目标：不好的成功标准「完学习了关于 C# 语言的基础知识」，好的「我可以利用 C# 语言的主要功能写出一个小的应用程序」\n\n\n\n\n寻找资源\n\n\n\n\n创建学习计划：从第四步找到的资源看看别人都是按什么顺序教的\n\n\n\n\n筛选资源\n\n\n\n\n开始学习，浅尝辄止：快速学习基础知识，立刻开始实际操作（像玩游戏）\n\n\n\n\n动手操作，边玩边学：如果我正在学一门新技术或者新的编程语言，我可以先创建一个小项目来测试这一步的效果，记录下尚未找到答案的问题\n\n\n\n\n全面掌握，学以致用：只需要阅读或观看与当前所学相关的部分，找到 8 的问题答案\n\n\n\n\n乐为人师，融会贯通：比如对话、写博客，在整理过程中发现问题\n\n\n\n\n\n\n"},"常见错误":{"title":"常见错误","links":[],"tags":["Git","GitHub"],"content":"Connection Closed by x.x.x.x Port 22 §\n添加以下代码到 ~/.ssh/config\nHost github.com\n  HostName ssh.github.com\n  User $username\n  Port 443"},"开发环境":{"title":"开发环境","links":["Capslock","Obsidian","Oh-My-Zsh","GitHub-加速访问"],"tags":["开发","设置","Mac"],"content":"设备 §\n\nM1 MacBook Pro 14\n先更新系统\n\nHomebrew §\n\n安装\n\nbrew tap homebrew/cask-drivers\nbrew tap homebrew/cask-fonts\nbrew tap homebrew/cask-versions\nbrew tap buo/cask-upgrade\nbrew tap mongodb/brew\n \nbrew install git git-lfs git-flow\ngit config --global core.autocrlf false # 不自动转换 CRLF\ngit config --global core.quotepath off # 显示原始文件名\ngit config --global core.ignorecase false # 区分大小写\ngit config --global init.defaultBranch main\ngit config --global remote.origin.prune true # 自动移除不存在的远端分支\ngit config --global user.name username # 注意不要照抄\ngit config --global user.email email # 注意不要照抄\n \nbrew install font-jetbrains-mono\nbrew install tldr # 像 man 命令一样在终端查看命令的说明和使用例子\n \n# 访达插件\nbrew install --cask openinterminal # 在 Finder 打开终端，https://github.com/Ji4n1ng/OpenInTerminal\nbrew install --cask qlmarkdown # Markdown\nbrew install --cask qlstephen # 查看没有文件扩展名的纯文本文件```\nbrew install --cask --no-quarantine syntax-highlight # 代码高亮\n \n# 以下应用，安装后关闭自动检查更新\nbrew install --cask another-redis-desktop-manager\nbrew install --cask devtoys # 开发小工具集合\nbrew install --cask font-hack-nerd-font\nbrew install --cask iina # 本地音视频播放器\nbrew install --cask jetbrains-toolbox\nbrew install --cask maczip\nbrew install --cask mini-program-studio # 支付宝小程序开发者工具\nbrew install --cask macs-fan-control # 控制风扇\nbrew install --cask mongodb-compass\nbrew install --cask switchhosts\nbrew install --cask wechatwebdevtools # 微信小程序开发者工具\n \nbrew install battery # https://github.com/actuallymentor/battery\nbrew install btop\nbrew install percona-toolkit # MySQL 运维工具\nbrew install stats # 菜单栏系统状态\n \nbrew install go\n  # 添加以下内容到 .zshrc 末尾\n  export PATH=&quot;/Users/wangze/go/bin:$PATH&quot;\n  export GO111MODULE=on\n  export GOPROXY=https://goproxy.cn\n \n# Rust--\n# 安装\ncurl --proto &#039;=https&#039; --tlsv1.2 https://sh.rustup.rs -sSf | sh\nrustc -V &amp;&amp; cargo -V\n \n# vi ~/.cargo/config.toml\n[source.crates-io]\nreplace-with = &#039;ustc&#039;\n \n[source.ustc]\nregistry = &quot;git://mirrors.ustc.edu.cn/crates.io-index&quot;\n \n# --Rust\n \n# 添加到 ~/.zshrc（需要先配置 Zsh）\nalias upb=&#039;brew cleanup --prune=all -q &amp;&amp; brew upgrade &amp;&amp; brew cu -ay &amp;&amp; brew uninstall node@14 node@16 node@18 node@19 --ignore-dependencies -f &amp;&amp; brew cleanup --prune=all -q &amp;&amp; npm update --location=global &amp;&amp; omz update&#039;\n \n# 执行 crontab -e，输入下面的内容，确保 iCloud 同步正常\n*/10 * * * * killall bird &amp;&amp; killall cloudd\nAppStore §\n\nBob 全局翻译\niShot Pro 截图\nPasteNow 同步剪切板\nQuantumult X\nWPS Office\n滴答清单\n\n软件 §\n\n\nApipost API 调试\n\n\nBartender 5 隐藏菜单栏图标\n\n\nCapslock 增强 Caps 键功能\n\n\nChrome\n\n访问一次 google.com/ncr，避免 Google 重定向\n修改扩展允许预加载网页：uBlock Origin，Decentraleyes\n\n\n\nGrammarly 英语语法纠错\n\n\niTerm2 终端\n\n\nMac Mouse Fix 增强鼠标功能\n\n\nNavicat Premium 管理数据库\n\n\nObsidian 双链笔记\n\n\nOh My Zsh 增强终端功能\n\n\nOrbStack Docker\n\n\n修改设置\n{\n  &quot;builder&quot;: {\n    &quot;gc&quot;: {\n      &quot;defaultKeepStorage&quot;: &quot;10GB&quot;,\n      &quot;enabled&quot;: true\n    }\n  },\n  &quot;experimental&quot;: false,\n  &quot;log-driver&quot;: &quot;json-file&quot;,\n  &quot;log-opts&quot;: {\n    &quot;max-file&quot;: &quot;1&quot;,\n    &quot;max-size&quot;: &quot;10m&quot;\n  },\n  &quot;registry-mirrors&quot;: [\n    &quot;https://mirrors.ustc.edu.cn&quot;\n  ]\n}\n\n\n\n\nParallels Desktop 虚拟机\n\n\nPicGo 图床\n\n\nPostman API 调试\n\n\nRaycast 启动器\n\n\nRectangle 管理窗口布局\n\n\nSourcetree Git 客户端\n\n\nTencent Lemon 系统清理工具\n\n\nVisual Studio Code\n\n\nwhistle 抓包工具\n\n\nWireshark 抓包工具（更多人推荐）\n\n\nXmind 思维导图\n\n\n微信\n\n\n微信输入法\n\n\n网易云音乐\n\n\n系统设置 §\n\n\n打开\n\n「三指拖移」\n触控板手势 - 更多手势 -「App Exposé」四指向下清扫\n「使窗口按应用程序成组」\n「使用大写锁定键切换“ABC”输入法」\n「自动切换到文稿的输入法」\n在滚动条中点按「跳到点按的位置」\n键盘快捷键\n\n调度中心\n\n向左移动一个空间 Ctrl + Q\n向右移动一个空间 Ctrl + W\n\n\n调度中心：Ctrl + E\n应用程序窗口：Ctrl + D\n\n\n\n\n\n关闭\n\n调度中心\n\n「根据最近的使用情况自动重新排列空间」\n\n\niCloud 同步「桌面与文稿文件夹」\n「在程序坞中显示最近使用的应用程序」\n「显示“聚焦”搜索」：有 Raycast\n「显示“访达”搜索窗口」：有 Raycast\n\n\n\nDNS §\n\n腾讯云\n\n主：119.29.29.29\n备：182.254.116.116\n\n\nGoogle Public DNS\n\n主：8.8.8.8\n备：8.8.4.4\n\n\n\nhosts §\n\nGitHub 加速访问\n"},"抢红包系统":{"title":"抢红包系统","links":[],"tags":["抢红包"],"content":"\n不能超抢\n剩余的到期需要返还\n通常使用的解决高并发问题方案\n\n方案一：使用内存操作替代实时的 DB 事务操作 §\n可能丢数据\n方案二：使用乐观锁替代悲观锁 §\n同时抢的只能有一个能成功，可能手慢的反而能抢到\n微信红包系统的高并发解决方案\n方案三：将关于同一个红包的所有请求聚合到同一个 §\n双维度库表设计：db_xx.t_y_dd xx/y 红包 ID 的 hash 值后三位，dd 的取值范围 01～31，一个月最多 31 天\n通过分流 + 队列 + 流控解决高并发场景下库存锁竞争的情况；\n通过事务操作串行化保证资金安全，避免出现红包超发、漏发、重复发的情况；\n通过红包 ID + 循环天双维度分库表规则提升系统性能。"},"换新设备":{"title":"换新设备","links":["Vault","同步方案"],"tags":["搭建"],"content":"推荐做法 §\n\nclone 文档仓库到本地\n将 .git 文件夹移到 iCloud 的 Obsidian 目录下的花园 Vault 根目录\n\n强烈不推荐做法 §\n\n删掉 iCloud 里的 Vault\n再走一遍 同步方案\n"},"搭建数字花园":{"title":"搭建数字花园","links":["同步方案","发布方案","配置自定义域名","添加评论区","配置图床","本库自动提交到-GitHub","iCloud-不同步指定文件","换新设备","发布笔记-404","特殊字符"],"tags":["搭建"],"content":"主要步骤 §\n\n同步方案\n发布方案\n配置自定义域名\n添加评论区\n配置图床\n本库自动提交到 GitHub\n不同步 .git 文件夹\n换新设备\n\n问题合集 §\n\n发布笔记 404\n特殊字符\n"},"支付技术方案":{"title":"支付技术方案","links":[],"tags":["支付","WIP"],"content":""},"收藏文章":{"title":"收藏文章","links":[],"tags":["推荐阅读"],"content":"技术 §\n\n[Linter上手完全指南 - GitHub](GitHub - haixiangyan/linter-tutorial: 👮‍♀️ 《Linter 上手完全指南》)\n一文搞懂 Redis 架构演化之路 - 腾讯技术工程\n一文搞懂什么是 SaaS、BaaS、PaaS 和 IaaS - 知乎\n\n规范 §\n\n编程中的命名设计那点事 | 酷 壳 - CoolShell\n\n经济 §\n\n经济机器是怎样运行的 (时长30分钟) Ray Dalio - YouTube\n\n沟通 §\n\nX-Y Problem | 酷 壳 - CoolShell\n你会问问题吗？ | 酷 壳 - CoolShell\n"},"本库自动提交到-GitHub":{"title":"本库自动提交到 GitHub","links":["Crontab-执行提示没有权限"],"tags":["搭建"],"content":"\n在文档仓库根目录添加文件：auto_push.sh\n配置 crontab 每天自动执行文档仓库的 auto_push.sh\n\nCrontab 执行提示没有权限\n\n\n由于文档仓库已配置 GitHub Action，自动提交后会触发发布仓库的 Github Action 自动部署网站\n\ncontent submodule -&gt; v4 of quartz repository -&gt; master of quartz repository\n\n\n"},"油猴脚本":{"title":"油猴脚本","links":[],"tags":["油猴","篡改猴","Tampermonkey","Chrome","插件"],"content":"安装说明 §\n\nGreasy Fork - safe and useful user scripts\n\n我发布的脚本 §\n\nhttps://github.com/11ze/user-scripts\n\n推荐脚本 §\n\nEndless Google: Google 搜索结果列表可以无限下拉\nredirect 外链跳转: 从 QQ 邮箱、知乎等网站点击外链时自动跳转，免去点击步骤\n"},"添加评论区":{"title":"添加评论区","links":[],"tags":["搭建","评论区"],"content":"\n\n适用于 Quartz v4\n\n\n到 giscus 生成自己的评论区代码并复制\n\n\n创建组件 quartz/components/pages/Giscus.tsx\nimport { QuartzComponentConstructor } from &quot;../types&quot;\n\nfunction Content() {\n  return &lt;script src=&quot;https://giscus.app/client.js&quot;\n    data-repo=&quot;11ze/knowledge-garden&quot;\n    data-repo-id=&quot;R_kgDOJhaxtw&quot;\n    data-category=&quot;General&quot;\n    data-category-id=&quot;DIC_kwDOJhaxt84CWa3R&quot;\n    data-mapping=&quot;title&quot;\n    data-strict=&quot;0&quot;\n    data-reactions-enabled=&quot;1&quot;\n    data-emit-metadata=&quot;0&quot;\n    data-input-position=&quot;bottom&quot;\n    data-theme=&quot;preferred_color_scheme&quot;\n    data-lang=&quot;zh-CN&quot;\n    crossorigin=&quot;anonymous&quot;\n    async&gt;\n  &lt;/script&gt;\n}\n\nexport default (() =&gt; Content) satisfies QuartzComponentConstructor\n\n\n\n在 quartz/components/pages/index.ts 中导出\n\n\nquartz.layout.ts\nexport const defaultContentPageLayout: PageLayout = {\n  right: [\n    Component.Giscus(),\n  ],\n\n"},"特殊字符":{"title":"特殊字符","links":[],"tags":["搭建","Hugo","Quartz"],"content":"\n&amp;#64 表示邮箱的 at 符号，否则发布后显示 email protected\n\n上面的编码在代码块里无效，但直接用 at 符号会被当成邮箱\n\n\n"},"疑难杂症":{"title":"疑难杂症","links":[],"tags":["疑难杂症"],"content":"Linux Crontab §\n\n看日志：/var/log/cron\n问题：Jan  9 15:05:01 i-9010749a crond[14778]: (www) PAM ERROR (鉴定令牌不再有效；需要新的鉴定令牌)\n解决：执行 chage -M 99999 www # 99999 单位是天\n"},"秒杀系统":{"title":"秒杀系统","links":[],"tags":["秒杀"],"content":"主要问题：并发读、并发写\n关键点 §\n\n高性能\n一致性\n高可用\n\n原则 §\n\n请求数据要尽量少\n\n减少序列化和反序列化\n字符转化\n\n\n请求数要尽量少\n\n如在请求路径上将多个 Javascript 用逗号合并，服务端一次性返回多个文件\n\n\n路径要尽量短\n\n将多个相互强依赖的应用合并部署到一起\n\n\n依赖要尽量少\n\n可以把依赖的服务先降级或停用\n\n\n不要有单点\n\n将服务无状态化，让实例可以动态伸缩\n把秒杀系统独立出来单独打造一个系统，并且在系统部署上也独立做一个机器集群，避免影响非秒杀商品的机器\n\n\n\n动静分离 §\n\n根据情况把静态数据缓存到离用户近的地方（浏览器、CDN、服务端的 Cache）\n直接缓存 HTTP 连接\n怎么做：\n\nURL 唯一化（如 /id=xxx）\n分离浏览者相关的因素（比如登录信息，这些通过动态请求获取）\n分离时间因素，也通过动态请求获取\n异步化地域因素\n去掉 Cookie（让缓存的静态数据中不含有 Cookie）\n服务端：\n\n生成完整页面\n客户端获取动态内容\n\n\n\n\n架构方案\n\n实体机单机部署：大 Cache 容量，高缓存命中率\n统一 Cache 层\n上 CDN：二级 Cache（一级发现没缓存数据就去二级找，都没有就回源获取数据并缓存到一级、二级缓存）\n\n\n\n热点数据 §\n\n静态热点数据：能提前预测的\n\n通过商业手段（强制让商家登记、对买家每天访问的商品进行大数据计算）\n\n\n动态热点数据：不能提前预测的\n\n（异步）收集交易链路上各个环节中的中间件产品的热点 Key（Nginx、缓存、RPC 服务框架等）\n上报热点，透传给下游系统\n\n\n\n流量削峰 §\n\n排队\n答题：延缓请求，并可以防止买家使用秒杀器作弊\n分层过滤：只在写数据时进行强一致性校验\n\n性能优化 §\n影响：\n\n减少线程等待时间影响不大\n\n减少 CPU 执行时间影响大\n线程数影响大\n\n\n发现瓶颈：\n\n工具：JProfiler、Yourkit\nCPU 使用率超过 95%\n\n\n优化方式：\n减少编码\n\n减少序列化\nJava 极致优化（直接输出流数据、直接使用 Servlet 处理请求）\n并发读优化\n\n\n\n减库存 §\n\n下单减库存：恶意下单\n付款减库存：超卖\n预扣库存（最常见）：同样可能恶意下单（影响小一些），确保最终一致性\n\nPlan B §\n\n降级\n限流：客户端限流、服务端限流\n拒绝服务\n"},"第一期":{"title":"第一期","links":[],"tags":["tag"],"content":""},"经典的-Redis-学习资料":{"title":"经典的 Redis 学习资料","links":[],"tags":["Redis"],"content":"\n\n工具书：《Redis 使用手册》\n\n\n最有用的是「数据结构与应用」的内容\n\n\n工具网站\n\nRedis 命令参考\n\n\n\n\n\n原理书：《Redis 设计与实现》\n\n重点学习 Redis 底层数据结构、RDB 和 AOF 持久化机制、哨兵机制和切片集群的介绍\n出版日期较早，针对的是 Redis 3.0\n\n\n\n实战书：《Redis 开发与运维》\n\n介绍了 Redis 的 Java 和 Python 客户端，以及 Redis 用于缓存设计的关键技术和注意事项，这些内容在其他参考书中不太常见，重点学习\n围绕客户端、持久化、主从复制、哨兵、切片集群等几个方面，着重介绍了在日常的开发运维过程中遇到的问题和“坑”，都是经验之谈，可以帮助提前做规避\n针对 Redis 阻塞、优化内存使用、处理 bigkey 这几个经典问题，提供了解决方案\n\n\n\n扩展阅读\n\n\n《操作系统导论》\n\n和 Redis 直接相关的部分：对进程、线程的定义，对进程 API、线程 API 以及对文件系统 fsync 操作、缓存和缓冲的介绍\n\n\n\n《大规模分布式存储系统：原理解析与架构实战》\n\n分布式系统章节\n\n\n\nRedis 的关键机制和操作系统、分布式系统的对应知识点\n\n\n\n\n\n\n\n《Redis 深度历险：核心原理与应用实践》\n\n"},"背单词":{"title":"背单词","links":[],"tags":["英语","单词"],"content":"准备 §\n\n手机安装不背单词 APP\n浏览器安装插件 不背单词查词\n\n在 APP 添加生词 §\n\n到不背单词首页下拉弹出单词搜索框\n输入单词或短语到搜索框进行搜索\n点击搜索结果\n点击星星图标添加到生词本\n\n\n在网页添加生词 §\n\n划词\n在弹出的窗口点击添加生词\n\n\n开始背单词 §\n\n将生词本设置为正在学习的词书\n\n\n"},"英语":{"title":"英语","links":["Think-in-English","背单词"],"tags":["英语"],"content":"\nGitHub - xiaolai/everyone-can-use-english: 人人都能用英语\nThink in English\n英语学习唯一正确方法具体实践 - 哔哩哔哩\n背单词\nBigShot英语 - 哔哩哔哩视频\n"},"让应用支持-iCloud-同步":{"title":"让应用支持 iCloud 同步","links":[],"tags":["iCloud"],"content":"\n先退出要同步的应用\n下载腾讯柠檬\n点击卸载应用的时候看详细信息，最下面找到应用保存数据的位置\n用访达打开\n复制数据文件夹到 iCloud\n删除原文件夹\n创建软链接\n"},"配置图床":{"title":"配置图床","links":[],"tags":["搭建","图床","Picgo","jsDelivr"],"content":"\n\n配置步骤\n\n在 GitHub 创建图床仓库\n到个人 Settings - Developer settings 创建 Personal access token 给 PicGo 用\n官网下载 PicGo\n\n\n\n\n参考链接\n\n使用 PicGo + Github + JSD 搭建免费图床\njsDelivr\n指定分支：在仓库名后拼接 \\@xx，如 https://cdn.jsdelivr.net /gh/11ze/knowledge-garden\\@main/xx\n\n\n"},"配置自定义域名":{"title":"配置自定义域名","links":[],"tags":["搭建","域名","Vercel","Cloudflare"],"content":"对于 quartz4，需要在 content 目录下放置 vercel.json，用于在点击 Wikilink 时自动添加 .html\n{\n  &quot;routes&quot;: [\n    { &quot;handle&quot;: &quot;filesystem&quot; },\n    { &quot;src&quot;: &quot;/(.*)&quot;, &quot;dest&quot;: &quot;/$1.html&quot; }\n  ]\n}\nVercel + Cloudflare §\n\nHow to Use a Cloudflare Domain with Vercel\n\n\n\n"}}