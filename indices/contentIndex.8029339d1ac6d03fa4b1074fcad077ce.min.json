{"/":{"title":"🪴 11ze's Garden","content":"\n- 欢迎你来到我的数字花园。\n- 推荐的游览姿势：\n  - 随意搜索\n  - 随意跳转\n  - [#Tags](https://wangze.tech/tags/)\n\n- 如果你也想拥有自己的数字花园，请看 [[搭建花园]]。\n- 如果你对 MySQL 感兴趣，请看 [[MySQL 实战 45 讲]]。\n- 如果你对 Redis 感兴趣，请看 [[Redis 核心技术与实战]]。\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E5%8F%91%E5%B8%83%E6%96%B9%E6%A1%88":{"title":"发布方案","content":"\n## 选用方案\n\n- [quartz](https://github.com/jackyzha0/quartz)\n\n## 怎么做\n\n## 注意事项\n\n## 参考文章\n\n- [Making your own Quartz](https://quartz.jzhao.xyz/notes/setup/#making-your-own-quartz)\n- [001\\_部署Obsidian静态知识库网站](https://ob.tianzhongs.ml/001_%e9%83%a8%e7%bd%b2Obsidian%e9%9d%99%e6%80%81%e7%9f%a5%e8%af%86%e5%ba%93%e7%bd%91%e7%ab%99)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E5%8F%91%E5%B8%83%E7%AC%94%E8%AE%B0-404":{"title":"笔记 404","content":"\n- 记录此问题的时间：[[2023-05-12]] 01:26 东八区\n- 现象：\n  - [[油猴脚本]] 在 [[2023-05-12]] 0 点创建，发布失败，改成 2023-05-11，发布成功\n  - 笔记出现在搜索结果，点击自动跳转到 404 页面\n- 猜测：执行发布的 GitHub Action 服务器时间比文档头标记的创建时间早，文档属于未来，所以未发布成功\n- [[2023-05-12]] 08:00 尝试发布成功\n\n- 解决方法：使用 [[ISO8601]] 格式的日期\n- [Page Variables | Hugo](https://gohugo.io/variables/page/)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88":{"title":"同步方案","content":"\n## 多种方案\n\n- Obsidian Sync：官方，要钱\n- Remotely Sync：第三方插件，但自动同步最短间隔 1 分钟（可以手动同步），免费\n- iCloud：实时同步，免费\n\n## 我使用的同步方案（iCloud）\n\n### 优点\n\n免费实时同步文档、插件、设置\n\n### 怎么做\n\n我的设备：iPhone + MacBook\n\n1. iPhone 安装 [[Obsidian]]\n2. 进入 [[Obsidian]] 创建一个打开 iCloud 同步功能的 [[Vault]]\n  2. ![sync-create-new-vault](https://cdn.jsdelivr.net/gh/11ze/static/images/sync-create-new-vault.png)\n3. 此时 iCloud 中会生成 [[Vault]] 目录\n  1. ![sync-created-vault](https://cdn.jsdelivr.net/gh/11ze/static/images/sync-created-vault.png)\n\n5. MacBook 安装 [[Obsidian]]\n6. 用 Obsidian 打开 2 创建的目录\n\n## 遇到的问题\n\n- [[iCloud 同步卡住]]\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95":{"title":"学习方法","content":"\n## 费曼学习法\n\n- \u003e [https://mp.weixin.qq.com/s/mUAQX_2b0Ut3APWB-pyYSQ](https://mp.weixin.qq.com/s/mUAQX_2b0Ut3APWB-pyYSQ)\n   - 1. 在纸上写下要学习的知识点\n\n   - 2. 写下自己对于这个知识点所知的一切, 然后假装讲给一个孩子听\n   - 3. 反复理解: 复习卡住的地方, 直到能用大白话讲清楚为止\n   - 4. 在第二步的基础上进行补充和简化, 循环\n\n## 高效学习: 深度, 归纳和坚持时间\n\n- \u003e [https://time.geekbang.org/column/article/14360](https://time.geekbang.org/column/article/14360)\n\n- 系统地学习（学习模板）\n   - 1. 这个技术出现的背景、初衷和要达到什么样的目标或是要解决什么样的问题\n   - 2. 这个技术的优势和劣势分别是什么，或者说，这个技术的 trade-off 是什么\n   - 3. 这个技术适用的场景\n   - 4. 技术的组成部分和关键点\n   - 5. 技术的底层原理和关键实现\n   - 6. 已有的实现和它之间的对比\n- 系统学习完了？举一反三\n   - 1. 联想, 抽象, 自省\n- 总结和归纳\n   - 1. 学习的开始阶段，可以不急于总结归纳，不急于下判断，做结论，而应该保留部分知识的不确定性，保持对知识的开放状态\n   - 2. 把看到和学习到的信息，归整好，排列好，关联好，总之把信息碎片给结构化掉，然后在结构化的信息中，找到规律，找到相通之处，找到共同之处，进行简化、归纳和总结，最终形成一种套路，一种模式，一种通用方法\n- 分享\n   - 1. 每周写一个 ARTS：Algorithm 是一道算法题，Review 是读一篇英文文章，Technique/Tips 是分享一个小技术，Share 是分享一个观点\n   - 2. 坚持一年\n   - 3. 晒出来, 可以是单一篇文章: 每周学习报告, 可以是多篇文章: 博客\n\n## 十步学习法\n\n- \u003e 《软技能：代码之外的生存指南》\n   - 1. 如何开始——要想开始使用自己所学的，我需要掌握哪些基本知识？\n\n   - 2. 学科范围——我现在学的东西有多宏大？我应该怎么做？\n   - 3. 基础知识——不止在开始阶段，要想使用一项特定的技术，我需要了解基本的用户案例和最常见的问题，也需要知道自己学的哪 20% 就能满足 80% 的日常应用\n- 执行\n   - 说明\n      - 1 - 6 走一遍（所有步骤都是为了 3）\n      - 7 - 10 重复\n      - 先完整过一遍再尝试优化成自己的学习方法\n   - 步骤\n      - 1. 了解全局：网上搜索关键字\n      - 2. 确定范围：缩小到一个特定的范围，一次只学一样东西。如「学习 C#」改为「学习 C# 的基础知识，掌握如何创建一个简单的控制台程序」\n      - 3. 定义目标：不好的成功标准「完学习了关于 C# 语言的基础知识」，好的「我可以利用 C# 语言的主要功能写出一个小的应用程序」\n      - 4. 寻找资源\n      - 5. 创建学习计划：从第四步找到的资源看看别人都是按什么顺序教的\n      - 6. 筛选资源\n      - 7. 开始学习，浅尝辄止：快速学习基础知识，立刻开始实际操作（像玩游戏）\n      - 8. 动手操作，边玩边学：如果我正在学一门新技术或者新的编程语言，我可以先创建一个小项目来测试这一步的效果，记录下尚未找到答案的问题\n      - 9. 全面掌握，学以致用：只需要阅读或观看与当前所学相关的部分，找到 8 的问题答案\n      - 10. 乐为人师，融会贯通：比如对话、写博客，在整理过程中发现问题\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF":{"title":"常见错误","content":"\n## Connection Closed by 20.205.243.166 Port 22\n\n添加以下代码到 `~/.ssh/config`\n\n```bash\nHost github.com\n  HostName ssh.github.com\n  User username\n  Port 443\n```\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83":{"title":"开发环境","content":"\n## 设备\n\n- MacBook Pro（M1）\n- 先更新系统\n\n## Homebrew\n\n- [官网](https://brew.sh/)\n\n```bash\nbrew tap homebrew/cask-drivers\nbrew tap homebrew/cask-fonts\nbrew tap homebrew/cask-versions\nbrew tap buo/cask-upgrade\nbrew tap mongodb/brew\n\nbrew install git-lfs\nbrew install git-flow\n\nbrew install font-jetbrains-mono\nbrew install font-lxgw-wenkai\n\n# 访达插件\nbrew install --cask qlmarkdown # Markdown\nbrew install --cask --no-quarantine syntax-highlight # 代码高亮\nbrew install --cask qlstephen # 查看没有文件扩展名的纯文本文件\n\n# 以下应用，安装后关闭自动检查更新\nbrew install --cask font-hack-nerd-font\nbrew install --cask maczip\nbrew install --cask wechatwebdevtools # 微信小程序开发者工具\nbrew install --cask mini-program-studio # 支付宝小程序开发者工具\nbrew install --cask macs-fan-control\nbrew install --cask mongodb-compass\nbrew install --cask another-redis-desktop-manager\nbrew install --cask iina # 本地音视频播放器\nbrew install --cask cheatsheet # 快捷键提示\nbrew install --cask raycast\n\nbrew install battery # https://github.com/actuallymentor/battery，暂未使用\nbrew install percona-toolkit # MySQL 运维工具\n\nbrew install go\n  # 添加以下内容到 .zshrc 末尾\n  export PATH=\"/Users/wangze/go/bin:$PATH\"\n  export GO111MODULE=on\n  export GOPROXY=https://goproxy.cn\n```\n\n```bash\n# 添加到 ~/.zshrc（需要先配置 Zsh）\nalias updatebrew='brew cleanup --prune=all -q \u0026\u0026 brew upgrade \u0026\u0026 brew cu -ay \u0026\u0026 brew uninstall node@14 node@16 node@18 node@19 --ignore-dependencies -f \u0026\u0026 brew cleanup --prune=all -q \u0026\u0026 npm update --location=global \u0026\u0026 omz update'\n```\n\n## AppStore\n\n- [Bob - 翻译和 OCR](https://apps.apple.com/cn/app/bob-%E7%BF%BB%E8%AF%91%E5%92%8C-ocr-%E5%B7%A5%E5%85%B7/id1630034110?mt=12)\n- [Grammarly](https://download-mac.grammarly.com/Grammarly.dmg)\n- [iHosts](https://apps.apple.com/cn/app/ihosts-etc-hosts-%E7%BC%96%E8%BE%91%E5%99%A8/id1102004240?mt=12)\n- [iShot Pro](https://apps.apple.com/cn/app/ishot-pro-%E4%B8%93%E4%B8%9A%E7%9A%84%E6%88%AA%E5%9B%BE%E8%B4%B4%E5%9B%BE%E5%BD%95%E5%B1%8F%E5%BD%95%E9%9F%B3ocr%E7%BF%BB%E8%AF%91%E5%8F%96%E8%89%B2%E5%B7%A5%E5%85%B7/id1611347086?mt=12)\n- [PasteNow](https://apps.apple.com/us/app/pastenow-instant-clipboard/id1552536109)\n- [WPS Office](https://apps.apple.com/cn/app/wps-office/id1443749478?mt=12)\n- [滴答清单](https://apps.apple.com/cn/app/%E6%BB%B4%E7%AD%94%E6%B8%85%E5%8D%95-%E4%B8%93%E6%B3%A8%E6%97%B6%E9%97%B4%E7%AE%A1%E7%90%86%E5%92%8C%E6%97%A5%E5%8E%86%E6%8F%90%E9%86%92%E4%BA%8B%E9%A1%B9/id966085870?mt=12)\n\n## 软件\n\n- [[Capslock]]\n- [ClashX Pro](https://install.appcenter.ms/users/clashx/apps/clashx-pro/distribution_groups/public)\n- [Chrome](https://www.google.com/intl/zh-CN/chrome/)\n- [Docker Desktop](https://www.docker.com/products/docker-desktop)\n  - 确认 Setting - Resources - Advanced 里的设置\n  - 在 Preferences - Docker Engine 中写入以下内容\n\n    ```json\n    {\n        \"registry-mirrors\": [\n            \"mirrors.ustc.edu.cn\"\n        ],\n        \"log-driver\": \"json-file\",\n        \"log-opts\": {\n            \"max-size\": \"10m\",\n            \"max-file\": \"1\"\n    }\n    ```\n\n- [Grammarly](https://app.grammarly.com/apps)\n- [iTerm2](https://iterm2.com/)\n- [JetBrains Toolbox](https://www.jetbrains.com/zh-cn/toolbox-app/)\n- [Mac Mouse Fix](https://mousefix.org/)\n  - Middle Button\n    - Click：Middle Click\n    - Click And Drag：Mission Control \u0026 Spaces\n  - Invert direction：取消勾选\n- [[Obsidian]]\n- [[Oh My Zsh]]\n- [OneDrive](https://www.microsoft.com/en-sg/microsoft-365/onedrive/download)\n- [Parallels Desktop](https://www.parallels.cn/products/desktop/trial/)\n  - \u003chttps://github.com/MikeWang000000/PD-Runner-Revived/tree/main\u003e\n- [PicGo](https://github.com/Molunerfinn/PicGo/releases)\n  - 安装后打开提示已损坏时执行命令：`sudo xattr -d com.apple.quarantine \"/Applications/PicGo.app\"`\n- [Postman](https://www.postman.com/downloads/)\n- [Rectangle](https://rectangleapp.com/)\n- [Sourcetree](https://www.sourcetreeapp.com/)\n- [Tencent Lemon](https://lemon.qq.com/)\n- [VMware Fusion](https://www.vmware.com/asean/products/fusion/fusion-evaluation.html)\n- [Visual Studio Code](https://code.visualstudio.com/download)\n- [Xmind](https://xmind.app/)\n- [微信](https://mac.weixin.qq.com/?lang=zh_CN)\n- [微信键盘](https://z.weixin.qq.com/)\n- [网易云音乐](https://music.163.com/#/download)\n\n## 其他软件\n\n- [Bartender 4 隐藏菜单栏图标](https://www.macbartender.com/)\n- [Navicat Premium](https://www.navicat.com/en/products/navicat-premium)\n\n## 系统设置\n\n- 关闭 iCloud 同步「桌面与文稿文件夹」✖️\n- 打开「三指拖移」✔️\n- 调度中心\n  - 打开「根据最近的使用情况自动重新排列空间」✔️\n  - 打开「使窗口按应用程序成组」✔️\n- 打开「使用大写锁定键切换“ABC”输入法」✔️\n- 在滚动条中点按，跳到点按的位置\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%8A%A2%E7%BA%A2%E5%8C%85%E7%B3%BB%E7%BB%9F":{"title":"抢红包系统","content":"\n- 不能超抢\n- 剩余的到期需要返还\n- 通常使用的解决高并发问题方案\n\n## 方案一：使用内存操作替代实时的 DB 事务操作\n\n可能丢数据\n\n## 方案二：使用乐观锁替代悲观锁\n\n同时抢的只能有一个能成功，可能手慢的反而能抢到\n\n微信红包系统的高并发解决方案\n\n## 方案三：将关于同一个红包的所有请求聚合到同一个\n\n双维度库表设计：db_xx.t_y_dd xx/y 红包 ID 的 hash 值后三位，dd 的取值范围 01～31，一个月最多 31 天\n\n通过分流 + 队列 + 流控解决高并发场景下库存锁竞争的情况；\n\n通过事务操作串行化保证资金安全，避免出现红包超发、漏发、重复发的情况；\n\n通过红包 ID + 循环天双维度分库表规则提升系统性能。\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%8D%A2%E6%96%B0%E8%AE%BE%E5%A4%87":{"title":"换新设备","content":"\n## 推荐做法\n\n1. clone 文档仓库到本地\n2. 将 .git 移到 iCloud 的 Obsidian 目录下的花园 [[Vault]] 根目录\n\n## 强烈不推荐做法\n\n1. 删掉 iCloud 里的 [[Vault]]\n2. 再走一遍 [[同步方案]]\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%90%AD%E5%BB%BA%E8%8A%B1%E5%9B%AD":{"title":"搭建花园","content":"\n1. [[同步方案]]\n2. [[发布方案]]\n3. [[配置自定义域名]]\n4. [[添加评论区]]\n5. [[配置图床]]\n6. [[配置 Google Analytics]]\n7. [[本库自动提交到 GitHub]]\n8. [[本地预览]]\n9. [[iCloud 不同步指定文件|不同步 .git 文件夹]]\n10. [[换新设备]]\n11. [[问题合集]]\n12. 参考：[Setup | Quartz](https://quartz.jzhao.xyz/notes/setup/)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%94%B6%E8%97%8F%E6%96%87%E7%AB%A0":{"title":"收藏文章","content":"\n## 技术相关\n\n- [Linter上手完全指南](https://github.yanhaixiang.com/linter-guide/theory/history.html#eslint)\n- [2021 年当我们聊前端部署时，我们在聊什么](https://juejin.cn/post/7017710911443959839)\n- [一文搞懂 Redis 架构演化之路](https://mp.weixin.qq.com/s/QssILJLna_v7XQWtV5UMzA)\n- [接口502了，运维和研发谁的锅？](https://mp.weixin.qq.com/s/UEzprqAEeTrdJt1NxTT49A)\n\n## 规范\n\n- [编程中的命名设计那点事](https://coolshell.cn/articles/990.html)\n\n## 方法论\n\n- [去NM的OKR，大坑，得把人逼疯！](https://mp.weixin.qq.com/s/467_77hVU8MxaH_spHHcpw)\n\n## 经济\n\n- [经济是机器怎样运行的](https://open.163.com/newview/movie/free?pid=MBPO9ED98\u0026mid=MBPO9S8IQ)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%96%87%E7%AB%A0%E6%9C%80%E5%90%8E%E6%9B%B4%E6%96%B0%E6%97%B6%E9%97%B4%E9%94%99%E8%AF%AF":{"title":"文章最后更新时间错误","content":"\n## 解决方法\n\n1. 在发布仓库做如下修改，让 Lastmod 比 Date 优先级高\n\n![lastmod-faild.png](https://cdn.jsdelivr.net/gh/11ze/static/images/lastmod-faild.png)\n\n2. 修改发布仓库的 GitHub Action：[Hugo 和 Github Action 正确修改文章的最后更新日期](https://dnwzlx.com/posts/146871a6/)\n\n3. 修改文档仓库的 GitHub Action\n\n在所有 md 文件的第 2 行插入 lastmod: 文件在 git 记录的最后修改时间\n\n```bash\nfind . -name \"*.md\" -type f -print0 | while read -d $'\\0' file\ndo\n    # get file modification time from git\n    modified=$(git log -1 --pretty='format:%cd' --date=format:'%Y-%m-%dT%H:%M:%S+0800' $file)\n\n    # replace lastmod value with the file modification time\n    sed -i '' '2i\\\nlastmod: '${modified}'\\ \n' \"$file\"\ndone\n```\n\n-----\n\n- 20230515：未解决，先用 publishDate\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%9C%AC%E5%9C%B0%E9%A2%84%E8%A7%88":{"title":"本地预览","content":"\n## 准备\n\n1. ⚠️ 不要在你正式写笔记的发布仓库和文档仓库里操作\n2. 复制你要预览的仓库到新文件夹\n3. 进入新文件夹\n\n## 将笔记转成发布仓库支持的格式\n\n⚠️ 这一步会修改你的笔记文档\n\n```bash\ngit submodule update --init --recursive\n\nrm -rf content/.obsidian content/cedict_ts.u8 content/Extras/Templates  \u0026\u0026 mv content/*.md content/Atlas \u0026\u0026 find content/ -name \"*.md\" | xargs -I file  mv -f file content \u0026\u0026  mv content/AboutTheGarden.md content/_index.md\n\nls content/ \u0026\u0026 grep -lr --null 'title' content/* | xargs -0 sed -i -E -r 's/title: \"(.*)/title: \"\\1\"/g'\"\n\nrm -rf content/*.md-E\n```\n\n## 启动服务\n\n```bash\ngo install github.com/jackyzha0/hugo-obsidian\u0026#latest\nhugo-obsidian -input=content -output=assets/indices -index -root=.\n\ngo install github.com/gohugoio/hugo\u0026#v0.96.0\nhugo server\n```\n\n## 参考\n\n- [Preview Changes](https://quartz.jzhao.xyz/notes/preview-changes/#:~:text=hugo-obsidian)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%9C%AC%E5%BA%93%E8%87%AA%E5%8A%A8%E6%8F%90%E4%BA%A4%E5%88%B0-GitHub":{"title":"本库自动提交到 GitHub","content":"\n- 配置 crontab 每天自动执行 [auto_push.sh](https://github.com/11ze/knowledge-garden/blob/main/auto_push.sh)\n  - 可能遇到的问题：[[Crontab 执行提示没有权限]]\n- 由于已配置 GitHub Action，自动提交后会触发 Action 自动部署网站\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%B2%B9%E7%8C%B4%E8%84%9A%E6%9C%AC":{"title":"油猴脚本","content":"\n## 安装说明\n\n- [Greasy Fork - safe and useful user scripts](https://greasyfork.org/en)\n\n## 我发布的脚本\n\n- \u003chttps://github.com/11ze/user-scripts\u003e\n\n## 推荐脚本\n\n- [Endless Google](https://openuserjs.org/scripts/tumpio/Endless_Google): Google 搜索结果列表可以无限下拉\n- [redirect 外链跳转](https://greasyfork.org/en/scripts/416338-redirect-%E5%A4%96%E9%93%BE%E8%B7%B3%E8%BD%AC): 从 QQ 邮箱、知乎等网站点击外链时自动跳转，免去点击步骤\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8C%BA":{"title":"添加评论区","content":"\n- 到 [giscus](https://giscus.app/zh-CN) 生成自己的评论区代码并复制\n- 到发布仓库找到以下文件，将代码粘贴到图中红框位置\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/add-comment-section.png)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6":{"title":"特殊字符","content":"\n- \u0026# 表示邮箱的 @ 符号，否则发布后显示 `email protected`\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F":{"title":"秒杀系统","content":"\n\n主要问题：并发读、并发写\n\n## 关键点\n\n- 高性能\n- 一致性\n- 高可用\n\n## 原则\n\n- 请求数据要尽量少\n   - 减少序列化和反序列化\n   - 字符转化\n- 请求数要尽量少\n   - 如在请求路径上将多个 Javascript 用逗号合并，服务端一次性返回多个文件\n- 路径要尽量短\n   - 将多个相互强依赖的应用合并部署到一起\n- 依赖要尽量少\n   - 可以把依赖的服务先降级或停用\n- 不要有单点\n   - 将服务无状态化，让实例可以动态伸缩\n   - 把秒杀系统独立出来单独打造一个系统，并且在系统部署上也独立做一个机器集群，避免影响非秒杀商品的机器\n\n## 动静分离\n\n- 根据情况把静态数据缓存到离用户近的地方（浏览器、CDN、服务端的 Cache）\n- 直接缓存 HTTP 连接\n- 怎么做：\n   - URL 唯一化（如 /id=xxx）\n   - 分离浏览者相关的因素（比如登录信息，这些通过动态请求获取）\n   - 分离时间因素，也通过动态请求获取\n   - 异步化地域因素\n   - 去掉 Cookie（让缓存的静态数据中不含有 Cookie）\n   - 服务端：\n      - 生成完整页面\n      - 客户端获取动态内容\n- 架构方案\n   1. 实体机单机部署：大 Cache 容量，高缓存命中率\n   2. 统一 Cache 层\n   3. 上 CDN：二级 Cache（一级发现没缓存数据就去二级找，都没有就回源获取数据并缓存到一级、二级缓存）\n\n## 热点数据\n\n- 静态热点数据：能提前预测的\n   - 通过商业手段（强制让商家登记、对买家每天访问的商品进行大数据计算）\n- 动态热点数据：不能提前预测的\n   - （异步）收集交易链路上各个环节中的中间件产品的热点 Key（Nginx、缓存、RPC 服务框架等）\n   - 上报热点，透传给下游系统\n\n## 流量削峰\n\n- 排队\n- 答题：延缓请求，并可以防止买家使用秒杀器作弊\n- 分层过滤：只在写数据时进行强一致性校验\n\n## 性能优化\n\n影响：\n\n- 减少线程等待时间影响不大\n   - 减少 CPU 执行时间影响大\n   - 线程数影响大\n- 发现瓶颈：\n   - 工具：JProfiler、Yourkit\n   - CPU 使用率超过 95%\n- 优化方式：\n- 减少编码\n   - 减少序列化\n   - Java 极致优化（直接输出流数据、直接使用 Servlet 处理请求）\n   - 并发读优化\n\n## 减库存\n\n1. 下单减库存：恶意下单\n2. 付款减库存：超卖\n3. 预扣库存（最常见）：同样可能恶意下单（影响小一些），确保最终一致性\n\n## Plan B\n\n- 降级\n- 限流：客户端限流、服务端限流\n- 拒绝服务\n\n\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E8%83%8C%E5%8D%95%E8%AF%8D":{"title":"背单词","content":"\n## 准备\n\n1. 手机安装不背单词 APP\n2. 浏览器安装 [不背单词查词](https://chrome.google.com/webstore/detail/%E4%B8%8D%E8%83%8C%E5%8D%95%E8%AF%8D%E6%9F%A5%E8%AF%8D/cklfipcjofdnmdolnfngpmokdaejidim)\n\n## 制作生词本\n\n### APP 内添加生词\n\n1. 到不背单词首页下拉弹出单词搜索框\n2. 输入单词或短语到搜索框进行搜索\n3. 点击搜索结果\n4. 点击星星图标添加到生词本\n   1. ![memorize-english-words-1](https://cdn.jsdelivr.net/gh/11ze/static/images/memorize-english-words-1.png)\n\n### 在网页添加生词\n\n1. 划词\n2. 在弹出的窗口点击添加生词\n  1. ![memorize-english-words-2](https://cdn.jsdelivr.net/gh/11ze/static/images/memorize-english-words-2.png)\n\n## 开始背单词\n\n1. 将生词本设置为正在学习的词书\n   1. ![memorize-english-words-3](https://cdn.jsdelivr.net/gh/11ze/static/images/memorize-english-words-3.png)\n   2. ![memorize-english-words-4](https://cdn.jsdelivr.net/gh/11ze/static/images/memorize-english-words-4.png)\n2. 在 APP 进行学习\n\n## 生词来源\n\n1. 英文文章\n2. 英文文档\n3. 生词的例句或英文解释\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E8%8B%B1%E8%AF%AD":{"title":"英语","content":"\n- 跟宝藏 UP 视频学：[【M14】英语学习唯一正确方法具体实践_哔哩哔哩](https://www.bilibili.com/video/BV1PN411c7Bx/?share_source=copy_web)\n- [[背单词]]\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E9%85%8D%E7%BD%AE%E5%9B%BE%E5%BA%8A":{"title":"配置图床","content":"\n- [使用 PicGo + Github + JSD 搭建免费图床 | ZeaLotSean](https://asuka4every.top/build-your-own-img-host/)\n- [jsDelivr](https://www.jsdelivr.com/)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E5%9F%9F%E5%90%8D":{"title":"配置自定义域名","content":"\n## Vercel + Cloudflare\n\n- [How to Use a Cloudflare Domain with Vercel](https://vercel.com/guides/using-cloudflare-with-vercel)\n\n![custom-domain-vercel.png](https://cdn.jsdelivr.net/gh/11ze/static/images/custom-domain-vercel.png)\n\n![custom-domains-cloudflare.png](https://cdn.jsdelivr.net/gh/11ze/static/images/custom-domains-cloudflare.png)\n\n![custom-domains-cloudflare-ssl.png](https://cdn.jsdelivr.net/gh/11ze/static/images/custom-domains-cloudflare-ssl.png)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E9%85%8D%E7%BD%AE-Google-Analytics":{"title":"配置 Google Analytics","content":"\n## 配置方法\n\n1. 到 [Google Analytics（分析）](https://marketingplatform.google.com/about/analytics/) 创建一个媒体资源并获取 ID\n   1. ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/google-analytics-1.png)\n2. 打开发布仓库根目录下的 `config.toml` 文件\n3. 写入：`googleAnalytics = \"G-XXX\"`\n4. 打开发布仓库的 `layouts/partials/header.html` 文件\n5. 在末尾写入：`{{ template \"_internal/google_analytics.html\" . }}`\n\n## 参考文章\n\n- [Google Analytics | Hugo](https://gohugo.io/templates/internal/#google-analytics)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/%E9%97%AE%E9%A2%98%E5%90%88%E9%9B%86":{"title":"问题合集","content":"\n- [[发布笔记 404]]\n- [[文章最后更新时间错误]]\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/00%E5%BC%80%E7%AF%87%E8%AF%8D":{"title":"00｜开篇词","content":"\n- 1 Redis 的“两大维度，三大主线\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-01-1.png)\n\n\n\n  - 应用纬度\n\n    - 缓存应用\n    - 集群应用\n    - 数据结构应用\n\n  - 系统纬度\n\n    - 高性能主线\n\n      - 线程模型\n      - 数据结构\n      - AOF\n      - epoll 网络框架\n\n    - 高可靠主线\n\n      - 主从复制\n      - 哨兵机制\n      - RDB\n\n    - 高可扩展性主线\n\n      - 数据分片\n      - 负载均衡\n\n- 2 Redis 问题画像图\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-01-2.png)\n","lastmodified":"2023-05-20T15:01:12.432019918Z","tags":null},"/01%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E4%B8%AA%E9%94%AE%E5%80%BC%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8C%85%E5%90%AB%E4%BB%80%E4%B9%88":{"title":"01｜基础架构：一个键值数据库包含什么？","content":"\n- 操作模块\n\n  - PUT：新写入或更新一个 key-value 对，如 PUT hello world\n  - GET：根据 K 读取 V\n  - DELETE：根据 K 删除整个 KV 对\n  - SCAN：根据一段 key 的范围返回相应的 value 值\n\n- 访问模式\n\n  - 通过函数库调用的方式供外部应用使用\n  - 通过网络框架以 Socket 通信的形式对外提供键值对操作\n\n- I/O 模型设计\n\n  - 单线程、多线程、多进程\n\n- 索引模块\n\n  - 让键值数据库根据 key 找到 value 的存储位置，进而执行操作\n  - Memcached 和 Redis 采用哈希表作为 key-value 索引\n  - 内存的高性能随机访问特性和哈希表 O(1) 的操作复杂度相匹配\n\n- 存储模块\n\n  - 分配器\n\n    - 内存：读写快，掉电数据丢失\n    - 外存：读写慢，数据持久化\n\n  - 持久化\n\n    - 对于每个键值对都进行落盘保存\n\n      - 数据可靠\n      - 性能差\n\n    - 周期性把内存中的键值数据保存到文件\n\n      - 数据可能丢失\n      - 性能较好\n\n- 从 SimpleKV 到 Redis 的架构图转变\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-02-1.png)\n\n  - ![](https://cdn.nlark.com/yuque/0/2022/png/958759/1667534358392-e54842d3-a965-40ac-876c-772f7b67bb11.png)\n- 从键值数据库开发和运维的辅助工具上做对比\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-02-2.png)\n\n  - ![](https://cdn.nlark.com/yuque/0/2022/png/958759/1667534376952-3b6c9208-f450-470c-98af-8feedaeebb40.png)\n","lastmodified":"2023-05-20T15:01:12.432019918Z","tags":null},"/01%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1-SQL-%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84":{"title":"01｜基础架构：一条 SQL 查询语句是如何执行的？","content":"\n- MySQL 的逻辑链接架构图\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-01-1.png)\n\n  - Server 层（共用）\n    - 连接器\n      - 跟客户端建立连接、获取权限、维持、管理连接\n    - 分析器\n    - 优化器\n    - 执行器\n  - 存储引擎层\n    - 多个不同的存储引擎\n- 0. `mysql\u003e select * from T where ID = 10;`\n- 1. 客户端连接数据库\n  - wait_timeout 参数控制连接器长时间没操作自动断开的时间\n    - 断开后再发送请求会报错\n  - 对已连接用户的权限做了修改，只有新建的连接才会使用新的权限设置\n  - 尽量使用长连接\n    - 问题：可能内存疯涨，因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的，这些资源会在连接断开的时候才释放\n    - 两个解决方案\n      - 1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，主动断开连接，之后要查询再重连\n      - 2. MySQL 5.7 或更新版本，可以在执行一个比较大的操作后，通过执行 没有 mysql_reset_connection 来重新初始化连接资源。\n        - 这个过程不需要重连和重新做权限验证，会将连接恢复到刚刚创建完时的状态\n- 2. 查询缓存\n  - 建议不使用查询缓存，弊大于利\n    - 失效非常频繁，对一个表的更新，表上所有的查询缓存都会被清空\n    - 设置 query_cache_type = DEMAND，对于默认的 SQL 语句都不使用查询缓存，用 SQL_CACHE 显示置顶要使用查询缓存的语句 select SQL_CACHE * from T;\n  - MySQL 8.0 版本删除了此功能\n- 3. 分析器\n  - a）词法分析\n  - b）语法分析\n    - 关注紧接“use near”的内容\n  - 此时知道了要做说明\n- 4. 优化器\n  - 决定使用哪个索引、决定各个表的连接顺序\n  - 后面的文章会单独展开说明优化器的内容\n  - 此时知道了要怎么做\n- 5. 执行器\n  - a）判断执行权限\n  - b）根据表的引擎定义，使用引擎提供的接口\n  - 慢查询日志中的 rows_examined 字段\n    - 执行器每次调用引擎获取数据行的时候累加\n    - 跟引擎扫描行数并不是完全相同的\n      - 可能执行器调用一次，引擎内部扫描了多行\n    - 后面有实战文章单独展开讲存储引擎的内部机制\n- 思考题\n  - 如果表 T 中没有字段 k，而你执行了这个语句 select * from T where k=1, 那肯定是会报“不存在这个列”的错误： “Unknown column ‘k’ in ‘where clause’”。你觉得这个错误是在我们上面提到的哪个阶段报出来的呢？\n    - 分析器\n","lastmodified":"2023-05-20T15:01:12.432019918Z","tags":null},"/02%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%BF%AB%E9%80%9F%E7%9A%84-Redis-%E6%9C%89%E5%93%AA%E4%BA%9B%E6%85%A2%E6%93%8D%E4%BD%9C":{"title":"02｜数据结构：快速的 Redis 有哪些慢操作？","content":"\n- Redis 数据类型和底层数据结构的对应关系\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-02-3.png)\n\n- Redis 使用一个哈希表 O(1) 保存所有键值对\n\n  - 全局哈希表（数组）\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-02-4.png)\n\n\n    - 哈希桶\n    - 哈希桶\n\n    - entry\n    - entry\n\n      - *key\n\n        - String\n\n      - *value\n\n        - String｜List｜Hash｜Set｜Sorted Set\n\n  - 每个数组元素称为一个哈希桶（指针）\n  - 每个哈希桶保存多个键值对数据\n  - 计算键的哈希值就可以知道对应的哈希桶位置\n\n- 哈希冲突\n\n  - 两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中。\n  - 解决方案：链式哈希。同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接。\n  - 当一个桶中的元素过多，访问时间变长时\n\n    - 采用两个全局哈希表，当哈希表 1 不够大时 copy 到更大的哈希表 2\n\n      - 问题：一次性复制会导致 Redis 线程阻塞\n\n    - rehash：增加现有哈希桶的数量\n\n      - 装载因子的大小 = 所有 entry 个数除以哈希表的哈希桶个数\n      - \u003c 1 或者在进行 RDB 和 AOF 重写时禁止 rehash\n\n      - \u003e= 1，且允许进行 rehash 时会进行 rehash\n\n      - \u003e= 5，立马开始 rehash\n\n    - 渐进式 rehash\n\n      - 每次处理请求时，顺带拷贝一部分数据到另一个哈希表。\n      - 定时任务周期性地搬移一些数据到新的哈希表中\n\n- 压缩列表 ziplist 的结构\n\n  - 表头\n\n    - zlbytes：列表长度\n    - zltail：列表尾的偏移量\n    - zllen：entry 个数\n\n  - 表尾 zlend：列表结束，取值默认是 255\n  - 元素 entry\n\n    - prev_len 前一个 entry 的长度\n\n      - 1 字节：上一个 entry 的长度 \u003c 254 字节\n      - 5 字节：1 字节以外的情况\n      - prev_len的第一个字节表示一个entry的开始，如果等于255表示列表结束，如果等于254那后四个字节才是prev_len的实际值，如果小于254，那就不需要后四个字节，直接使用这一个字节表示prev_len的实际值\n      - 当前一节点长度大于等于254时，第一个字节为254(1111 1110)作为标志，后面4个字节组成一个整型用来存储长度\n\n    - encoding 编码方式，1 字节\n    - content 实际数据\n\n  - 其他操作同整数数组、双向列表\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-02-5.png)\n\n\n  - 顺序查找 O(N)\n\n- 跳表 O(logN)：多级索引，通过索引位置的几个跳转，实现数据的快速定位\n- 不同操作的复杂度\n\n  - 单元素操作是基础\n\n    - 每一种集合类型对单个数据实现的增删改查操作\n\n  - 范围操作非常耗时\n\n    - 集合类型中的遍历操作，可以返回集合中的所有数据\n\n      - 用 SCAN 代替遍历操作\n\n  - 统计操作通常高效\n\n    - 集合类型中对集合中所有元素个数的记录\n\n  - 例外情况只有几个\n\n    - 某些数据结构的特殊记录\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/02%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1-SQL-%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84":{"title":"02｜日志系统：一条 SQL 更新语句是如何执行的？","content":"\n- MySQL 的逻辑链接架构图\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-01-1.png)\n- update 语句执行流程\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-02-1.png)\n\n- 重要的日志模块：redo log\n  - 是 InnoDB 引擎特有的日志\n  - WAL 技术 Write-Ahead Logging\n    - 先写日志，再写磁盘\n    - 当有一条记录需要更新的时候，InnoDB 引擎先把记录写到 redo log，并更新内存，引擎会在适当的时候，将这个操作记录更新到磁盘，这个更新往往是在系统比较空闲的时候做\n  - redo log 大小固定，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，所有文件组成一块“粉板”\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-02-2.png)\n    - write pos 是当前记录的位置，一边写一边后移，写到文件末尾后会回到文件开头\n    - checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件\n    - write pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。\n    - 如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n  - crash-safe：有了 redo log，InnoDB 可以保证数据库发生异常重启也不丢失数据\n- 重要的日志模块：binlog（归档日志）\n  - 是 Server 层的日志\n  - statement 格式：记 SQL 语句\n  - row 格式：记录行的内容，记两条，更新前和更新后都有\n    - 建议使用\n  - set sql_log_bin=0 关掉本线程的 binlog 日志\n- redo log 和 binlog 的不同\n  - 1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\n  - 2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。\n    - 逻辑：其他引擎都能用，都讲得通这个“逻辑”\n    - 物理：只有“我“能用，别人没有共享我的”物理格式“\n  - 3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n- binlog 还不能去掉，redolog 只有 InnoDB 有，其他引擎没有，另外 redolog 是循环写，不持久保存，不具备 binlog 的“归档”功能\n- 0. mysql\u003e update T set c=c+1 where ID=2;\n- 两阶段提交\n  - 1. redolog 的 prepare 阶段；2. 写 binlog；3. redolog 的 commit\n  - 在 2 之前崩溃时，重启恢复后发现没有 commit，回滚；备份恢复，没有 binlog。一致\n  - 在 3 之前崩溃，重启恢复后发现虽然没有 commit，但满足 prepare 和 binlog 完整，自动 commit；备份恢复，有 binlog。一致\n  - 日常开发可能也会用到\n- 设置建议\n  - innodb_flush_log_at_trx_commit 建议设置成 1，表示每次事务的 redo log 都直接持久化到磁盘，保证 MySQL 异常重启之后数据不丢失\n  - sync_binlog 建议设置成 1，表示每次事务的 binlog 都持久化到磁盘，保证 MySQL 异常重启之后 binlog 不丢失\n- 思考题\n  - 在什么场景下，一天一备会比一周一备更有优势？\n    - 好处：“最长恢复时间”更短\n    - 在一天一备的模式里，最坏情况下需要应用一天的 binlog。比如，你每天 0 点做一次全量备份，而要恢复出一个到昨天晚上 23 点的备份。一周一备最坏情况就要应用一周的 binlog 。\n  - 它影响了这个数据库系统的哪个指标？\n    - RTO（恢复目标时间）\n- 答疑文章（一）\n  - MySQL 怎么知道 binlog 是完整的？\n    - 一个事务的 binlog 是有完整格式的：\n    - statement 格式的 binlog，最后会有 COMMIT；\n    - row 格式的 binlog，最后会有一个 XID event。\n  - MySQL 5.6.2 之后，引入了 binlog-checksum 参数，用于验证 binlog 内容的正确性\n  - redo log 和 binlog 是怎么关联起来的?\n    - 它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：\n    - 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；\n    - 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。\n  - 处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?\n    - 其实，这个问题还是跟我们在反证法中说到的数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。\n  - 如果这样的话，为什么还要两阶段提交呢？干脆先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。是不是一样的逻辑？\n    - 其实，两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的。\n    - 如果必须要举一个场景，来说明这么做的必要性的话，那就是事务的持久性问题。\n      - 对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。\n      - 两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。\n  - 不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？\n    - 历史原因的话，那就是 InnoDB 并不是 MySQL 的原生存储引擎。MySQL 的原生引擎是 MyISAM，设计之初就有没有支持崩溃恢复。\n    - binlog 没有崩溃恢复的能力\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-02-3.png)\n      - binlog 没有能力恢复“数据页”\n        - 如果图中标的位置，binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。重启后引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1，系统已经认为提交完成了，不会再应用一次 binlog1。但是，binlog 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。如果在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。\n        - 如果优化一下 binlog 的内容，让它来记录数据页的更新可以吗？这其实就是又做了一个 redo log 出来。至少现在的 binlog 能力还不支持崩溃恢复。\n  - 那能不能反过来，只用 redo log，不要 binlog？\n    - 如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。\n    - binlog 有着 redo log 无法替代的功能\n      - 一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。\n      - 一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。\n      - 还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。\n  - redo log 一般设置多大？\n    - redo log 太小的话，会导致很快就被写满，然后不得不强行刷 redo log，这样 WAL 机制的能力就发挥不出来了。所以，如果是现在常见的几个 TB 的磁盘的话，就不要太小气了，直接将 redo log 设置为 4 个文件、每个文件 1GB 吧。\n  - 正常运行中的实例，数据写入后的最终落盘，是从 redo log 更新过来的还是从 buffer pool 更新过来的呢？\n    - 这里涉及到 “redo log 里面到底是什么” 的问题\n    - 实际上，redo log 并没有记录数据页的完整数据，所以它并没有能力自己去更新磁盘数据页，也就不存在“数据最终落盘，是由 redo log 更新过去”的情况。\n    - 1. 如果是正常运行的实例的话，数据页被修改以后，跟磁盘的数据页不一致，称为脏页。最终数据落盘，就是把内存中的数据页写盘。这个过程，甚至与 redo log 毫无关系。\n    - 2. 在崩溃恢复场景中，InnoDB 如果判断到一个数据页可能在崩溃恢复的时候丢失了更新，就会将它读到内存，然后让 redo log 更新内存内容。更新完成后，内存页变成脏页，就回到了第一种情况的状态。\n  - redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？\n    - 在一个事务的更新过程中，日志是要写多次的。\n      - 比如下面这个事务：begin;insert into t1 …insert into t2 …commit;\n      - 这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n      - 所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n      - 但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n      - （这里说的是事务执行过程中不会“主动去刷盘”，以减少不必要的 IO 消耗。但是可能会出现“被动写入磁盘”，比如内存不够、其他事务提交等情况。这个问题我们会在后面第 22 篇文章《MySQL 有哪些“饮鸩止渴”的提高性能的方法？》中再详细展开）。\n    - 单独执行一个更新语句的时候，InnoDB 会自己启动一个事务，在语句执行完成的时候提交。过程跟上面是一样的，只不过是“压缩”到了一个语句里面完成。\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/03%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E4%B8%BA%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81":{"title":"03｜事务隔离：为什么你改了为还看不见？","content":"\n- 隔离型与隔离级别\n  - 读未提交 read uncommitted\n    - 一个事务还没提交时，它做的变更就能被别的事务看到。\n      - 别人改数据的事务尚未提交，我在我的事务中也能读到。\n  - 读提交 read committed\n    - 一个事务提交之后，它做的变更才会被其他事务看到。\n      - 别人改数据的事务已经提交，我在我的事务中才能读到。\n  - 可重复读 repeatable read\n    - 一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n      - 别人改数据的事务已经提交，我在我的事务中也读不到。\n  - 串行化 serializable\n    - 对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n      - 我的事务尚未提交，别人就别想改数据。\n- 事务隔离的实现\n  - 以可重复读为例\n  - 每条记录在更新的时候会同时记录一条回滚操作\n    - 记录上的最新值，通过回滚操作，都可以得到前一个状态的值\n      - ![mysql45-03-1](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-03-1.png)\n    - 系统会判断，当没有事务再需要用到这些回滚日志时，回滚日志才会被删除\n      - 如事务提交之前都可能用到\n      - 不要使用长事务\n    - MySQL 5.5 及之前的版本，回滚日志跟数据字典一起放在 ibdata 文件里，即使长事务最终提交，回滚段被清理，文件也不会变小，只能重建整个库\n- 事务的启动方式\n  - 1. 显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。（set autocommit=1）\n  - 2. set autocommit=0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n    - 建议总是使用 set autocommit=1，通过显示语句的方式来启动事务\n  - commit work and chain\n    - 在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。\n  - 可以在 information_schema 库的 innodb_trx 这个表中查询长事务\n    - 查找持续时间超过 60s 的事务\n      - select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u003e60\n  - 执行 begin 后面的第一个 SQL 语句时，事务才真正启动，如 select，非 begin\n- 思考题\n  - 你现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n    - 从应用开发端来看\n      - 1. 确认是否使用了 set autocommit=0\n        - 在测试环境看，把 MySQL 的 general_log 开起来，随便跑一个业务逻辑，通过 general_log 的日志确认\n        - 一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1\n      - 2. 确认是否有不必要的只读事务\n      - 3. 业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。\n        - 为什么会意外？在后续的文章中会提到这类案例\n    - 从数据库端来看\n      - 1. 监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 / 或者 kill\n      - 2. Percona 的 pt-kill 这个工具不错，推荐使用\n      - 3. 在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题\n      - 4. 如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便\n        - innodb_undo_tablespaces 是控制 undo 是否开启独立的表空间的参数。为 0 表示：undo 使用系统表空间，即 ibdata1。不为 0 表示：使用独立的表空间，一般名称为 undo001 undo002，存放地址的配置项为：innodb_undo_directory。一般 innodb_undo_tablespaces 默认配置为0，innodb_undo_directory 默认配置为当前数据目录\n        - innodb_undo_tablespaces\n          - 默认为 0，即回滚段保存在 ibata 文件中\n          - 设置为 2，表示在 undo 目录下创建 2 个文件（每个默认大小 10m），最多创建 126 个，一般名称为 undo001 undo002\n        - innodb_undo_logs：回滚段个数，默认 128\n        - innodb_undo_directory：回滚日志存放目录，默认为当前数据目录\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/03%E9%AB%98%E6%80%A7%E8%83%BD-IO-%E6%A8%A1%E5%9E%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%95%E7%BA%BF%E7%A8%8B-Redis-%E9%82%A3%E4%B9%88%E5%BF%AB":{"title":"03｜高性能 IO 模型：为什么单线程 Redis 那么快？","content":"\n- Redis 的网络 IO 和键值对读写由一个线程完成\n\n  - 当客户端和 Reids 的网络连接断开时，Redis 不会等待客户端恢复连接\n\n- Redis 的其他功能，比如持久化、异步删除、集群数据同步等，由额外的线程执行\n- 单线程设计机制\n\n  - 多线程编程模式：共享资源的并发访问控制问题\n  - 在内存中完成大部分操作 + 高效的数据结构\n\n- 多路复用机制（select/epoll 机制）\n\n  - 该机制允许内核中同时存在多个监听套接字和已连接套接字\n  - 内核监听这些套接字上的连接请求或数据请求，一旦有请求到达，就交给 Redis 处理\n  - 基于事件的回调机制\n\n    -   事件队列\n\n- 基于多路服用的 Redis 高性能 IO 模型\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-03-1.png)\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/04%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8A":{"title":"04｜深入浅出索引（上）","content":"\n- 每遇到一个新数据库，先关注它的数据模型，分析数据库的适用场景\n- 数据库底层存储的核心基于的数据模型：哈希表、有序数组、二叉树、N 叉树等\n- 哈希表\n  - 以键 - 值（key-value）存储数据的结构\n  - 思路：把值放到数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置\n  - 不可避免出现哈希冲突，其中一种解决方法是用链表存储相同 key 的值，查找时从链表头开始按顺序遍历链表\n  - 适用于只有等值查询的场景\n    - 插入数据很快\n    - 无序，用哈希索引做区间查询很慢\n    - 比如 Memcached 及其他一些 NoSQL 引擎\n- 有序数组\n  - 在等值查询和范围查询场景中的性能非常优秀\n  - 用二分法可以快速找到对应的数据，O(Log(N))\n  - 只适用于静态存储引擎\n    - 插入数据慢，需要挪动插入的记录后面所有的记录\n- 二叉搜索树\n  - 特点\n  - 父节点左子树所有节点的值小于父节点的值\n  - 父节点右子树所有节点的值大于父节点的值\n  - 需要保持这棵树是平衡二叉树\n    - 查询复杂度O(log(N))\n    - 更新复杂度O(log(N))\n- N 叉树\n  - B+ 树就是一种 N 叉树\n  - 相比于二叉树，能够有效减少单次查询的磁盘访问次数\n  - N 取决于数据块的大小\n    - MySQL 5.6 以后可以通过 page 大小间接控制 N 的大小\n  - 被广泛应用在数据库引擎中\n- InnoDB 的索引模型\n  - 使用了 B+ 树索引模型\n  - 每一个索引在 InnoDB 里面对应一颗 B+ 树\n  - 主键索引也被称为聚簇索引（clustered index）\n    - 叶子节点内容是整行数据\n    - 主键查询只需要搜索主键这颗 B+ 树\n    - 整张表的数据其实就是存在主键索引中的，这就是“聚簇索引”的意思\n  - 非主键索引也被称为二级索引（secondary index）\n    - 叶子节点内容是主键的值\n      - 如果把多个列联合起来搞成主键索引，那么二级索引里包含的主键也是多列\n    - 普通索引查询需要先拿到主键，再到主键索引树搜索一次\n      - 这个过程称为回表\n  - 叶子节点是 page（数据页），一个页里面可以存多个行\n    - 页大小 16k，则行个数 = 16k/行大小\n  - 索引维护\n    - 页分裂\n      - 新增加一个数据页，挪动部分数据过去，空间利用率降低大概 50%\n      - 不挪动数据的新增数据页操作不叫页分裂\n    - 当相邻的两个数据页利用率很低的时候会做数据页合并\n  - 主键\n    - 建议使用自增主键\n      - 建议设置 bigint unsigned\n    - 使用业务主键的场景\n      - 1. 只有一个索引\n      - 2. 该索引必须是唯一索引\n      - （典型的 KV 场景）\n    - 没有主键的表，InnoDB 会默认创建一个 RowId 做主键\n    - 加主键都会重建表\n  - 索引只能定位到 page，page 内部是个有序数组，用二分法\n    - 数据页中有页目录，页目录 key 为 id ，value 为槽位，二分搜索页目录定位到槽位中的行记录\n    - 内存数据页和磁盘数据页是一一对应的，持久化的时候直接覆盖写进去\n  - 叶子节点中的数据连接方式\n    - 叶子内是单向链表\n    - 叶子间是双向链表\n- 什么时候需要重建索引\n  - 索引可能因为删除操作、页分裂等原因，导致数据页有空洞\n    - 即空间未释放\n  - 重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，更省空间\n- 思考题\n  - 重建普通 k 索引\n    - alter table T drop index k;\n    - alter table T add index(k);\n  - 重建主键索引\n    - alter table T drop primary key;\n    - alter table T add primary key(id);\n  - 对于上面这两个重建索引的做法，说出你的理解。\n    - 重建索引 k 的做法合理，可以达到省空间的目的\n    - 重建主键的过程不合理\n  - 如果有不合适的\n    - 为什么？\n      - 删除或创建主键都会将整个表重建，导致第一个语句白做\n    - 更好的方法是什么？\n      - 使用 alter table T engine=InnoDB 代替\n        - 触发 MySQL 重建该表，并进行碎片处理\n        - 5.6 版本以后支持 onlineddl，没有行锁，有 mdl 读锁\n      - 在第 12 讲有分析 [[12｜为什么我的 MySQL 会“抖”一下？]]\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/04AOF-%E6%97%A5%E5%BF%97%E5%AE%95%E6%9C%BA%E4%BA%86Redis-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1":{"title":"04｜AOF 日志：宕机了，Redis 如何避免数据丢失？","content":"\n- Redis 作为缓存使用\n\n  - 从数据库读取数据恢复\n  - 当需要恢复时数据库压力大、Redis 响应慢\n\n- 写后日志：先执行命令把数据写入内存，再记录日志\n\n  - 不会阻塞当前的写操作\n  - 记录的命令没有错误\n  - 没来得及记录时，宕机会丢失数据\n  - 在主线程写，写盘压力大可能导致后续操作无法执行\n\n- 日志格式示例\n\n  - Redis 命令 set testkey testvalue\n  - AOF 文件（Append Only File）\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-04-1.png)\n\n\n  - \\*3：命令有三个部分\n  - $3：命令、键或值一共有多少字节\n  - 每个 $n 下一行跟着命令、键或值\n\n- 三种写回策略\n\n  - Always：同步写回\n  - Everysec：每秒写回\n\n    - 优先使用，在可靠性和性能取了一个平衡\n\n  - No：操作系统控制的写回\n\n- 重写机制\n\n  - 如多个操作同一个键值的命令合并为一个命令\n  - 避免重写日志过大\n  - 直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志\n  - 一个拷贝\n\n    - 由后台子进程 bgrewiteaof 完成，避免阻塞主线程\n\n      - fork 创建 bgrewriteaof 子进程时，阻塞主线程，如果实例内存大，执行时间还会更长\n      - 共享主线程内存，主线程执行新写或修改操作时会申请新的内存空间保存新的数据，如果操作的是 bigkey，可能因为申请大空间而面临阻塞风险\n\n  - 两处日志\n\n    - 正在使用的 AOF 日志 + 新的重写日志\n    - 避免竞争文件系统的锁\n\n  - 减小日志大小\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-04-2.png)\n\n  - AOF 非阻塞重写过程\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-04-3.png)\n\n\n- 适用于读操作比较多的场景\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/05%E5%86%85%E5%AD%98%E5%BF%AB%E7%85%A7%E5%AE%95%E6%9C%BA%E5%90%8ERedis-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D":{"title":"05｜内存快照：宕机后，Redis 如何实现快速恢复？","content":"\n- 和 AOF 相比，RDB 记录某一时刻的数据，恢复时直接把 RDB 文件读入内存\n\n  - 类比拍照\n  - 全量快照\n\n- 生成 RDB 文件的方案\n\n  - save：在主线程中执行，会导致阻塞\n  - bgsave：创建一个子进程，复制主线程的页表，专门写入 RDB 文件，避免阻塞。默认配置\n\n    - 共享主线程的所有内存数据\n\n- 快照时数据能修改吗？\n\n  - 读操作：bgsave 子进程和主线程互不影响\n  - 能\n  - 写操作：生成被修改的一块数据的副本，bgsave 子进程继续写 RDB 文件，主线程在副本上进行修改\n  - 写时复制：主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-05-1.png)\n\n\n- 可以每秒做一次快照吗？\n\n  - 磁盘压力\n  - fork bgsave 子进程的过程会阻塞主线程\n\n- 混合使用 AOF 和内存快照\n\n  - AOF 只保留从最后一次快照开始的改动\n\n- 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择\n- 如果允许分钟级别的数据丢失，可以只使用 RDB\n- 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡\n- 持久化有关的风险\n\n  - 服务器内存不足\n\n    - 写时复制为写、修改操作涉及的数据分配相同大小的内存副本\n\n  - 子进程也会占用 CPU 资源\n  - 需要开启定时 RDB 和 AOF 重写时进程一定不要绑定 CPU：子进程会与父进程争夺同一个 CPU 资源（具体搜索关键字找到后面有关绑定 CPU 的章节）\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/05%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8B":{"title":"05｜深入浅出索引（下）","content":"\n- 如何安排联合索引内的字段顺序\n  - 第一原则：如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。\n  - 如果既有联合查询，又有基于 a、b 各自的查询，此时要考虑空间\n    - 比如 a 比 b 大，就建 (a, b) + 单 b\n  - 还有其他情况，需要结合业务分析\n- 查询语句的 where 里面各个判断调换顺序不影响\n- 覆盖索引\n  - 如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果\n  - 覆盖索引可以减少树的搜索次数，显著提升查询性能，是常见的性能优化手段\n  - 要全用上必须是条件 =，不能是 \u003e 或 \u003c\n    - (c, b)，这个索引是当 c 相同时,才按照 b 字段升序或者降序排序建立索引 b那如果 \u003e 的话 相当于可能获取到多个 c 不同的情况\n- 在一个市民信息表上，是否有必要将身份证号和名字建立联合索引？\n  - 如果有一个高频请求是根据身份证号查询姓名，就有必要\n- 前缀索引\n  - 最左前缀原则\n    - 可以是联合索引的最左 N 个字段\n    - 也可以是字符串索引的最左 M 个字符\n- 索引下推\n  - MySQL 5.6 之后引入\n  - 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数\n  - 例子：有个 (name, age) 索引，where name like '张%' and age=10\n    - 因为最左前缀原则，只能用到 name 索引\n    - 5.6 之前：查找到所有张开头的记录，一个个回表找出数据行，对比 age 字段值\n    - 5.6 之后：上一点（可以在索引遍历…）\n- 思考题\n  - 已有条件\n    - 多个索引\n      - primary ab (a, b)\n      - c (c)\n      - ca (c, a)\n      - cb (c, b)\n    - DBA 解释：业务中有两个语句\n      - select * from geek where c=N order by a limit 1;\n      - select * from geek where c=N order by b limit 1;\n    - 所以需要 ca 和 cb，而不是单个 c\n  - 问题\n    - 这样解释对吗，ca 和 cb 是否都是必须的\n      - 只需要 cb\n    - 为什么\n      - 因为存在 ab，普通索引包含主键，即 c + ab =\u003e cab\n    - 题外话\n      - 对于 order by，如果索引合理的话，数据有序的话，就不需要排序了\n- 评论区\n  - 面试题：怎么让 MySQL 的 myisam 引擎支持事务\n    - 用 lock table 实现，但只能实现串行化隔离级别\n    - 因为 mysiam 不支持崩溃恢复，所以即使用 lock table 硬实现，也是问题多多\n    - ACID 里面，原子性和持久性做不到\n    - 隔离性只能实现基本用不上的串行化\n    - 一致性在正常运行的时候依赖于串行化，在异常崩溃的时候也不能保证\n    - 这样实现的事务不要也罢\n  - 订单表，查询时，多个条件，不选则不传，怎么建索引\n    - 老师回复\n      - 按照查询的模式，选最常见的创建联合索引。\n        - 比如，如果时间 + 客户标志用得最多，就创建这两个的联合索引\n      - 比较少用的条件，就单独建，然后查 id 出来跟别的字段的查询结果，在客户端取交集\n    - 跟评\n      - 用 es，相当于全建索引\n        - 好处是快，减轻数据库压力\n        - 坏处是多维护一个中间件\n  - 使用联合索引的时候，联合索引的多个属性都在同一棵树上\n    - 甚至可以认为，其实 InnoDB 的普通索引，都是这个索引字段 + 主键字段的联合索引\n  - 用 key 和 index 创建索引没有区别\n  - 内存数据页和磁盘数据页是一一对应的，持久化的时候直接覆盖写进去\n  - 什么情况下一次取出多个主键回表\n    - 自动，代码版本支持就会这么做\n  - 联合索引是怎么存储的\n    - 联合索引是依次按照联合字段的先后顺序，依次进行排序。如 a, b, c 三个字段是联合索引，则叶子节点存储的是三个字段的数据，且按照先后顺序进行排序；而非叶子节点存储的是第一个关键字的索引。故当执行查询的时候，因为联合索引中是先根据 a 进行排序的，如果 a 没有先确定，直接对 b 或 c 进行查询的话，就相当于是乱序查询，因此联合索引无法生效，此时就相当于是全表查询。\n  - in 速度很快，in 里面的项递增输入的话，理论上会快些\n    - 不用 union all\n    - 如果太多项，可以拆成多个 in()，分批处理\n  - b+ 树中的索引节点应该都是由指针和索引组成。但现在要将磁盘索引节点加载到内存中，这些指针地址是怎么映射的（磁盘和内存指针的映射）\n    - 首先磁盘的数据和数据页是一样的，\n    - 所以磁盘只能记录 “我的第一个叶子节点在 page_n”\n    - 在内存里面也是，然后当把 page_n 读到内存以后，内存里面记录的是“page_n”的内存地址在哪里\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/06%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E6%9C%89%E8%BF%99%E4%B9%88%E5%A4%9A%E9%98%BB%E7%A2%8D":{"title":"06｜全局锁和表锁：给表加个字段怎么有这么多阻碍？","content":"\n- 全局锁\n  - 典型使用场景：做全库逻辑备份。\n    - 使用 MySQL 提供的加全局读锁的方法\n      - Flush tables with read lock（FTWRL）\n      - 整个库进入只读状态\n      - 执行 FTWRL 命令之后由于客户端发生异常断开，MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。\n    - 推荐：可以在可重复读隔离级别下开启一个事务\n      - 备份期间可以正常读写数据库\n      - 需要所有的表的引擎都支持（全库备份）\n      - mysqldump 备份工具使用 -single-transaction 参数，就会开启一个事务，确保拿到一致性视图\n  - 为什么不使用 set global readonly=true？\n    - 建议用 FTWRL\n    - 1. 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。\n    - 2. 将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。\n    - 3. readonly 对 super 权限的用户无效\n- 表级锁\n  - 表锁\n    - 语法：lock tables … read/write\n    - unlock tables 主动释放锁，或者客户端断开的时候自动释放\n    - 除了会限制比的线程的读写，也会限定本线程自己接下来的操作对象\n    - 不推荐使用，若引擎不支持事务，安排升级换引擎。\n      - 升级后把使用 lock/unlock tables 语法的地方换成 begin 和 commit。\n  - 元数据锁 MDL（metadata lock）\n    - 不需要显示使用，在访问一个表的时候会被自动加上\n    - MySQL 5.5 版本中引入\n    - MDL 的作用是防止 DDL（加字段等修改表结构的操作）和 DML（增删改数据）冲突\n    - 当对一个表做增删改查时，加 MDL 读锁。\n    - 当对表做结构变更操作时，加 MDL 写锁。\n    - 读锁之间不互斥，可以有多个线程同时对一张表增删改查\n    - 读写锁之间、写锁之间互斥。如果有两个线程同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n  - 如何安全地给小表加字段？\n    - 1. 解决长事务，事务不提交会一直占着 MDL 锁。\n      - 在 information_schema 库的 innodb_trx 表可以查到当前执行中的事务。\n      - 可以暂定 DDL 或者 kill 掉这个长事务\n    - 2. 热点表，数据量不大的情况\n      - kill 事务不一定管用，kill 后立马有新的请求\n      - 在 alter table 语句里面设定等待时间，拿不到 MDL 写锁就先放弃，重试命令重复加字段过程。\n        - MariaDB 已经合并了 AliSQL 的这个功能，这两个开源分支都支持 DDL NOWAIT/WAIT n 语法\n  - 大表加字段：用 Gh-ost\n- 思考题\n  - 备份一般在备库上执行\n  - 在用 -single-transaction 方法做逻辑备份的过程中，如果主库上的一个小表做了一个 DDL，比如给一个表加了一列\n  - 这时候在备库上会看到什么现象？\n    - Q2 启动了一致性试图，但一致性视图不包含表结构。\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-06-1.png)\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/06%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4":{"title":"06｜数据同步：主从库如何实现数据一致？","content":"\n- 写操作：首先到主库执行，主库将写操作同步给从库\n- 同步流程\n\n  - 主从库第一次同步的流程\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-1.png)\n\n  - 增量复制流程\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-2.png)\n\n  - 1. 全量复制\n\n      - 第一次同步无法避免\n      - 一个实例的数据库不要太大（几 GB 级别合适）\n      - 通过 RDB 文件\n\n        - 二进制文件\n\n    - 不用 AOF 的原因\n\n      - 需要打开 AOF 功能\n\n        - 有很多场景数据不敏感不需要开启 AOF 功能\n        - 刷盘策略选择不当会严重影响 Redis 性能\n\n      - 比 RDB 文件大\n      - 在从库端进行恢复时，用 RDB 的恢复效率高于用 AOF\n\n  - 2. 增量复制\n\n      - 通过命令传播的长连接复制\n\n        - 完成全量复制后，主库通过长连接将后续陆续收到的命令操作同步给从库，可以避免频繁建立连接的开销\n\n    - 网络断连时\n\n      - repl_backlog_buffer\n\n- 主 -\u003e 从 -\u003e 从\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-3.png)\n\n\n  - 从库执行 replicaof IP PORT\n\n    - 1. IP 上的实例执行 bgsave 命令生成 RDB 文件后发给从库\n    - 2. 从库清空当前数据库\n    - 3. 主库会在内存用专门的 replication buffer 记录 RDB 文件生成后收到的所有写操作\n    - 4. 将 replication buffer 的修改操作发给从库\n\n  - 分担全量复制时的主库压力\n\n- replication buffer 和 repl_backlog_buffer 的区别\n\n  - replication buffer：复制缓冲区\n\n    - 从库也相当于一个客户端，会单独分配一个 client buffer，这里用来传播用户的写命令到从库，通常把它叫做 replication buffer\n    - 主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区\n    - 作用：主节点向从节点发送 RDB 文件时，如果又接收写操作，会暂存在缓冲区，等 RDB 文件传输完成，且从节点加载完成后，主节点把缓冲区中的写命令发给从节点进行同步\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-4.png)\n\n    - 对主从同步的影响：如果传输和加载 RDB 文件耗时长，同时主库接收的写命令操作较多，导致缓冲区写满溢出，主库会强制关闭和从库的网络连接，重新开始全量同步\n    - 通过 client-output-buffer-limit-slave 配置项增加缓冲区大小\n\n  - client buffer 超过限制时，主库会强制断开这个 client 连接\n\n    - 此时从库再次发起复制请求，可能导致恶性循环\n\n  - repl_backlog_buffer：复制积压缓冲区\n\n    - 是一个环形缓冲区：为了在从库断开之后能找到主从差异数据而设计\n    - 记录写操作\n    - 所有从库共享\n    - 不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步\n    - 主从断开太久，主库写操作节点越过从库在 repl_backlog_buffer 的读节点时，从库只能全量复制\n    - repl_backlog_size\n\n      - = 缓冲空间大小 * 2\n      - 缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小\n      - 过小可能导致从库复制进度赶不上主库，触发全量复制\n\n    - repl_backlog_buffer 的使用\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-5.png)\n\n\n      - 主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步\n        - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-6.png)\n\n      - 父节点图2\n        - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-7.png)\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/07%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%E5%A6%82%E4%BD%95%E4%B8%8D%E9%97%B4%E6%96%AD%E6%9C%8D%E5%8A%A1":{"title":"07｜哨兵机制：主库挂了，如何不间断服务？","content":"\n- 哨兵机制的基本流程\n\n  - 1. 监控：判断主从库下线\n\n  - 主观下线\n\n    - 哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。\n    - 如果哨兵发现主库或从库对 PING 命令的响应超时了，哨兵就会先把它标记为“主观下线”。\n    - 从库会被直接标记为“主观下线”。\n\n  - 客观下线\n\n  - 大多数的哨兵判断主库主观下线，主库才会标记为客观下线\n\n  - 减少误判\n\n    - 哨兵集群：哨兵机制通常采用多实例组成的集群模式部署\n\n  - 2. 选主：选出新主库（筛选 + 打分）\n\n    - 1. 按照一定的筛选条件去掉不符合条件的从库\n\n      - 在线状态\n      - 网络状态\n\n        - 配置项（ms）down-after-milliseconds * 10\n        - 如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了\n        - 如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好\n        - 此参数可以调节哨兵的敏感程度\n\n    - 2. 按照一定的规则给剩下的从库逐个打分\n\n      - 从库优先级\n\n        - 通过 slave-priority 配置项设置\n\n      - 从库复制进度\n\n        - 和旧主库同步程度最接近的从库得分高\n\n          - salve_repl_offset 最大\n\n      - 从库 ID 号\n\n        - 在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。\n\n    - 3. 得分最高的作为新主库\n    - 新主库的选择过程\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-07-1.png)\n\n  - 3. 通知\n\n    - 1. 让从库执行 replicaof 与新主库同步\n\n      - 4.0 之前全量同步，4.0 之后增量同步，了解 psync2\n\n    - 2. 通知客户端与新主库连接\n\n- 切换过程中，客户端能否正常进行请求操作？\n\n- 客户端使用了读写分离时不会受到影响\n- 写请求失败持续的时间 = 哨兵切换主从的时间 + 客户端感知到新主库的时间\n\n- 如果想要应用程序不感知服务的中断，还需要哨兵或客户端做些什么？\n\n  - 客户端把写失败的请求先缓存起来或写入消息队列中间件中，等哨兵切换完主从后，再把这些写请求发给新主库，只适合对写入请求返回值不敏感的业务，需要业务层做适配\n  - 哨兵主动通知客户端\n\n    - 1. 哨兵将新主库地址写入自己实例的 pub/sub（switch-master 事件）中\n    - 2. 客户端订阅 pub/sub，有数据时，客户端能感知到主库变更，同时可以拿到最新的主库地址\n\n  - 客户端通过 sentinel get-master-addr-by-name 命令从哨兵集群中获取最新的地址\n  - 一般 Redis 的 SDK 都提供了通过哨兵拿到实例地址，再访问实例的方式，直接使用即可\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/07%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D":{"title":"07｜行锁功过：怎么减少锁对性能的影响？","content":"\n- MyISAM 不支持行锁\n- InnoDB 的行锁\n  - 两阶段锁协议：事务中，行锁在需要的时候才加上，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。\n  - 如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n  - 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。\n    - 两种策略\n      - 1. 直接进入等待，直到超时。\n        - 超时时间可以通过 innodb_lock_wait_timeout 设置\n        - 默认 50s。\n      - 2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。\n        - 将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n        - 死锁：每当一个事务被锁，就要看看它所依赖的线程有没有被别的锁住，如此循环，最后判断是否出现连循环等待。\n        - 假设现在已经有999个线程在同一行等锁，新来一个请求也要访问这个行，他要判断有没有死锁要判断 1000 次。然后这个结果乘以 1000。\n      - 正常情况下采用第二种策略，默认也是第二种。\n  - 怎么解决热点行更新导致的性能问题？\n    - 问题的症结：死锁检测要耗费大量的 CPU 资源。\n    - 1. 确保业务一定不会出现死锁，关闭死锁检测（不推荐）\n    - 2. 控制并发度。\n      - a）在中间件或修改 MySQL 源码实现：对于相同行的更新，在进入引擎之前排队，这样 InnoDB 就不会有大量的死锁检测工作。\n      - b）如果做不到第 a 点，可以考虑从设计上优化\n        - 以考虑通过将一行改成逻辑上的多行来减少锁冲突。\n        - 以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。\n- 思考题\n  - 如果要删除一个表里面的前 1w 行数据，选择哪一种方法\n  - 1. 直接执行 delete from T limit 10000;\n    - 单个语句占用时间长，锁的时间也比较长；\n    - 大事务还会导致主从延迟。\n  - 2. 在一个连接中循环执行 20 次 delete from T limit 500;\n    - 选 2。\n  - 3. 在 20 个连接中同时执行 delete from T limit 500;\n    - 认为造成锁冲突。\n- 评论区\n  - 关于本篇思考题\n    - 第二种方法难道不会引起数据一致性问题吗？如果在 InnoDB 中开启了自动事务并且没有显式用 begin, commit 来做的话，在上一次循环结束和下一次循环开始之间如果有其他事务插入了新数据，而且正好位置也在前面 500条，那不就不一致了么\n      - 加个 order by id（假设 id 是表的主键）\n      - 排序后新增的 id 肯定大于要删除的最大 id\n  - 如果有多种锁，必须全部不互斥才能并行。\n- 没有嵌套事务，开启下一个会自动提交上一个\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/08%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84":{"title":"08｜事务到底是隔离的还是不隔离的？","content":"\n- 事务的启动时机\n  - begin/start transaction 命令之后的第一个操作 InnoDB 表的语句，事务才真正启动。\n  - 马上启动一个事务：start transaction with consistent snapshot。\n- 整个专栏，如果没有特别说明，都默认 autocommit = 1。\n  - 事务自动提交设置，默认为1，即除非显示声明一个事务的开始，否则每一个查询都会被当做独立的事务被处理。\n- MySQL 里的两个“视图”的概念\n  - 一个是 view。是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。\n    - 创建视图的语法是 create view …，查询方法和表一样。\n  - 另一个是 InnoDB 在实现 MVCC（多版本并发控制） 时用到的一致性读视图（consistent read view），用于支持 RC（Read Committed，读提交）和 RR（Repeatable Read，可重复读）隔离级别的实现。\n- 视图没有物理结构，作用是事务执行期间用来定义“我能看到什么数据”\n- “快照”在 MVCC 里是怎么工作的？\n  - 秒级创建快照的能力，快照是基于整库的。\n  - InnoDB 的行数据有多个版本（row），每个版本有自己的 row trx_id（严格递增）。\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-08-1.png)\n    - 图中的虚线就是 undo log。\n  - 在实现上，InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。\n    - 活跃：启动了但还没提交。\n    - 数组里事务 ID 的最小值记为低水位。\n    - 当前系统里面已经创建过的事务 ID 的最大值加 1 记为高水位。\n    - 这个视图数组和高水位，就组成了当前事务的一致性视图（read-view）。\n    - 数据版本的可见性规则：基于数据的 row trx_id 和一致性视图的对比结果得到的。\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-08-2.png)\n      - 绿色：表示这个版本是已提交的事务或者是当前事务自己生成的，可见。\n      - 红色：表示是由将来启动的事务生成的，不可见。\n      - 黄色\n        - a）若 row trx_id 在数组中，表示这个版本是由还没提交的事务生成的，不可见；\n        - b）若 row trx_id 不在数组中，表示这个版本是已经提交了的事务生成的，可见。\n  - 翻译：对于一个事务视图，除了自己的更新总是可见以外，有三种情况\n    - 1. 版本未提交，不可见；\n    - 2. 版本已提交，但是是在视图创建后提交的，不可见；\n    - 3. 版本已提交，而且是在视图创建前提交的，可见。\n  - 每个事务或者语句有自己的一致性视图。普通查询语句是一致性读，一致性读会根据 row trx_id 和一致性视图确定数据版本的可见性。\n    - 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；\n    - 对于读提交，查询只承认在语句启动前就已经提交完成的数据；\n- 更新逻辑\n  - 更新数据都是先读后写的。\n  - 当前读：总是读取已经提交完成的最新版本。\n  - 除了 update 语句外，select 语句如果加锁，也是当前读。\n    - 加上 lock in share mode 或 for update。\n- 事务的可重复读是怎么实现的？\n  - 可重复读的核心是一致性读；而事务更新数据的时候，只能用当前读。如果当前的记录的行锁被其他事务占用的话，就需要进入锁等待。\n  - 读提交的逻辑和可重复读的逻辑类似，最主要的区别：\n    - 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；\n    - 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的事务。\n- 为什么表结构不支持“可重复读”？\n  - 因为表结构没有对应的行数据，也没有 row trx_id，因此只能遵循当前读的逻辑。\n  - MySQL 8.0 已经可以把表结构放在 InnoDB 字典里了，也许以后会支持表结构的可重复读。\n- 思考题\n  - 表\n    - id 1 2 3 4\n    - c 1 2 3 4\n    - InnoDB，主键 id\n  - 想要把所有字段 c 和 id 值相等的行的 c 值清零，却改不掉\n    - 1. begin；2. select *from t；3. update t set c=0 where id=c；4. select* from t；结果没变。\n  - 构造出这种情况\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-08-3.png)\n    - 用另一个事务在更新语句前先进行更新\n  - 说明原理\n    - 更新操作是当前读，被抢先更新后的数据版本号不属于自己，看不到，在可重复读下还是读到旧值，此时就出现：数据正确，却更新不了\n  - 在实际业务开发中有没有可能碰到这种情况？\n    - 有\n  - 怎么解决？\n    - 根据更新语句的 affected_rows 判断是否更新成功\n- 评论区\n  - 在同一行数据，最新版本的 row trx_id 是可能会小于旧版本的 row trx_id 的。因为后开启的事务可能先提交。\n  - 只读事务“不分配 trx_id”\n    - 5.6 以后的优化\n    - 其实不是不分配，而是随机分配。\n  - 读提交和当前读\n    - 读提交不加锁\n    - 考虑下，一个语句开始执行之后，执行期间别的事务修改了数据的情况。\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/08%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%93%A8%E5%85%B5%E6%8C%82%E4%BA%86%E4%B8%BB%E4%BB%8E%E5%BA%93%E8%BF%98%E8%83%BD%E5%88%87%E6%8D%A2%E5%90%97":{"title":"08｜哨兵集群：哨兵挂了，主从库还能切换吗？","content":"\n- 本质上哨兵就是一个运行在特定模式下的 Redis 实例。\n- 基于 pub/sub 机制的哨兵集群组成过程（发布/订阅机制）\n\n  - 只有订阅了同一个频道的应用才能通过发布的消息进行信息交换\n  - 哨兵通过 __sentinel__:hello 频道互相发现、通信\n\n- 给主库发送 INFO 命令拿到从库列表，哨兵根据列表上的连接信息和从库建立连接并监控\n- 基于哨兵自身的 pub/sub 功能，实现客户端和哨兵之间的事件通知\n\n  - 重要的频道汇总图\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-08-1.png)\n\n  - 如：客户端执行 SUBSCRIBE * 订阅所有事件\n\n- 由哪一个哨兵执行主从切换？\n\n  - 和主库客观下线的判断过程类似，投票仲裁\n  - 1. 标记主库“主观下线”\n  - 2. 向其他哨兵实例要赞成票\n  - 3. 获得仲裁所需的赞成票后，就可以标记主库为“客观下线”。\n  - 4. 成功标记主库为客观下线的哨兵实例向其他哨兵发送命令，表明希望执行主从切换\n  - 5. 投票（Y/N），确定 Leader\n\n    - 1. 拿到半数以上赞成票\n    - 2. 拿到的票数大于等于哨兵配置文件中的 quorum 值\n    - 每个哨兵只能投一个赞成票，可以给自己投，第一次必投 Y\n    - 所有哨兵同时判断主库主观下线，然后同时得到客观下线的结论时，每个哨兵各自一票（概率极低）\n\n- 要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds\n- 思考题\n\n  - 配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障了，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？\n\n    - 能，两个哨兵都给出主观下线的结果，达到了 quorum 的值\n\n  - 如果可以的话，还能进行主从库自动切换吗？\n\n    - 不能主从切换，选举 Leader 拿不到超过半数的选票（5/2 + 1 = 3）\n\n  - 哨兵实例是不是越多越好呢？\n\n    - 不是。通信次数增多，故障风险变大，选举时间变长\n\n  - 调大 down-after-milliseconds 值，对减少误判有没有好处？\n\n    - 有好处，降低误判的概率，但主从切换时间变长，对业务影响时间变久\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/09%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%A4%9A%E4%BA%86%E6%98%AF%E8%AF%A5%E5%8A%A0%E5%86%85%E5%AD%98%E8%BF%98%E6%98%AF%E5%8A%A0%E5%AE%9E%E4%BE%8B":{"title":"09｜切片集群：数据增多了，是该加内存还是加实例？","content":"\n- 纵向扩展：升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU\n\n  - 实施起来简单、直接\n  - 当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞（耗时长）\n  - 不要求持久化保存 Redis 数据时是一个不错的选择\n  - 受到硬件和成本的限制\n\n- 横向扩展：增加当前 Redis 实例的个数\n\n  - 扩展性更好\n  - 数据切片后，在多个实例之间如何分布？\n  - 客户端怎么确定想要访问的数据在哪个实例上？\n\n- 切片集群是一种保存大量数据的通用机制，可以有不同的实现方案\n\n  - Redis Cluster（官方）\n\n    - 采用哈希槽（Hash Slot）处理数据与实例之间的映射关系\n    - 共有 16384 个哈希槽，个数在客户端和服务端写死\n    - 1. 根据键值对的 key，按照 [CRC16](https://en.wikipedia.org/wiki/Cyclic_redundancy_check) 算法 计算一个 16 bit 的值\n    - 2. 用值对 16384 取模，得到 0～16383 范围内的模数（哈希槽编号）\n    - 数据映射关系：键的哈希值 =\u003e 哈希槽 =\u003e 不同的实例\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-09-1.png)\n\n    - 部署\n\n      - 手动或自动将所有槽分配完后，集群才能正常工作\n      - cluster create 命令创建集群，自动将槽平均分布在实例上\n      - cluster meet 手动建立实例间的连接形成集群，再使用 cluster addslots 制定每个实例上的哈希槽个数\n\n    - 客户端如何定位数据？\n\n      - Redis 实例会把自己的哈希槽信息发给和它相连接的其他实例，实例相互连接后每个实例都有所有哈希槽的映射关系\n      - 客户端将哈希槽信息缓存在本地\n      - 先计算键对应的哈希槽\n      - 然后给相应的哈希槽发送请求\n\n    - 运维人员手动触发进行负载均衡和数据迁移\n    - 常见的变化\n\n      - 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽\n      - 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍\n\n    - 重定向机制\n\n      - 当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，这个实例就会给客户端返回 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址\n\n        - GET hello:key｜(error) MOVED 13320 172.16.19.5:6379\n        - 实例上的数据已全部迁移完成\n          - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-09-9.png)\n\n        - 会更新客户端缓存的哈希槽分配信息\n\n      - 当请求的实例只有一部分迁移到另一个实例，刚好请求的哈希槽已迁移，客户端会收到一条 ASK 报错信息\n\n        - GET hello:key｜(error) ASK 13320 172.16.19.5:6379\n        - 实例上的数据只有部分迁移完成\n          - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-09-3.png)\n        - 不会更新客户端缓存的哈希槽分配信息\n\n    - 迁移数据是同步的，如迁移一个 key 时，会阻塞源节点和目标节点\n\n  - 基于客户端分区\n\n    - SharededJedis\n\n  - 基于代理（proxy）\n\n    - Codis\n\n      - 支持在线扩容\n\n        - 客户端无感知\n\n      - 数据迁移是异步的\n\n        - 速度更快，对性能影响小\n\n    - Twemproxy\n\n    - 不支持在线扩容\n\n- 思考题\n\n  - Redis Cluster 方案的映射流程有什么好处？\n\n    - 哈希槽把数据和节点解耦，key 通过 Hash 计算，只需要关心映射到哪个哈希槽，再通过哈希槽和节点的映射表找到节点，且数据分布更均匀\n    - 数据迁移时以哈希槽为基本单位，简化了节点扩容、缩容的难度\n\n  - Redis 为什么不用表直接记录键值对和实例的对应关系？\n\n    - key 的数量无法预估\n    - Redis Cluster 采用无中心化模式（无 proxy，客户端和服务端直连），客户端需要能正确路由到正确节点，所有节点都要有完整的路由关系，帮助矫正客户端保存的路由关系\n    - 发生数据迁移时，需要修改每个 key 的对应关系，维护成本高\n    - 基于单个表的单线程操作表需要串行执行，性能低\n    - 多线程操作表，涉及加锁开销\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/09%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E5%BA%94%E8%AF%A5%E6%80%8E%E4%B9%88%E9%80%89%E6%8B%A9":{"title":"09｜普通索引和唯一索引，应该怎么选择？","content":"\n- 查询性能\n\n    - 「where = 」时，唯一索引找到了立马返回，普通索引需要找到下一个不等于的值\n\n\n    - 因为 InnoDB 的数据是按数据页为单位读写的，所以性能差距微乎其微\n        - 对于整形字段，一个 16KB 的数据页可以放近千个 key\n\n- change buffer\n\n    - 1. 当需要更新一个数据页时，如果数据页在内存中就直接更新\n\n\n    - 2. 如果数据页还没有在内存中，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中\n\n\n    - 3. 下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行第 2 步缓存在 change buffer 中与这个页有关的操作\n\n        - 这个过程称为 merge\n\n\n        - 除了访问数据页会触发 merge，系统有后台线程会定期 merge\n\n\n        - 在数据库正常关闭的过程中，也会执行 merge 操作\n\n\n    - change buffer 是可以被持久化的数据\n        - 在内存中有拷贝，也会被写到磁盘上\n\n\n    - 减少读磁盘的次数，语句的执行速度得到明显提升\n\n\n    - 数据读入内存需要占用 buffer pool，所以 change buffer 这种方式还能够避免占用内存，提高内存利用率\n\n\n    - 什么条件下可以使用 change buffer？\n\n        - 唯一索引的更新不能使用\n            - 所有的更新操作都要先判断是否违反唯一性约，必须要将数据页读入内存才能判断\n\n\n        - 只有普通索引可以使用\n\n\n    - change buffer 用的是 buffer pool 里的内存，因此不能无限增大\n        - 通过参数 innodb_change_buffer_max_size 动态设置，如 50 表示只能占用 buffer pool 的 50%\n\n\n    - 更新数据的处理流程\n\n        - 更新的目标页在内存中\n\n            - 唯一索引：找到要插入的位置，判断没有冲突，插入\n\n\n            - 普通索引：找到要插入的位置，插入\n\n\n        - 不在内存\n\n            - 唯一索引：读入内存，判断没有冲突，插入\n\n\n            - 普通索引：将更新记录在 change buffer，完成\n\n\n    - 使用场景\n        - 写多读少的业务：效果最好，如账单类、日志类的系统\n            - 视情况可以尽量开大\n\n\n    - 写完马上做查询的业务：不适用，起反作用\n\n- change buffer 和 redo log\n\n    - redo log 主要节省随机写磁盘的 IO 消耗（转成顺序写）\n\n\n    - change buffer 主要节省随机读磁盘的 IO 消耗\n\n\n    - 例子\n\n        - 1. 带 change buffer 的更新过程\n\n            - 图 2\n                - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-09-1.png)\n\n\n\n            - 语句：insert into t(id, k) values(id1, k1), (id2, k2);\n\n\n            - 1. Page 1 在内存中，直接更新内存；\n\n\n            - 2. Page 2 没在内存中，所以在内存的 change buffer 区域记录信息：我要往 Page 2 插入一行\n\n\n            - 3. 将上述两个动作记入 redo log 中（图中 3 和 4）\n\n\n        - 2. 带 chagne buffer 的读过程\n\n            - 图 3\n                - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-09-2.png)\n\n\n\n            - 语句：select * from t where k in (k1, k2);\n\n\n            - 1. 读 Page 1 时直接从内存返回\n                - PS：WAL 之后如果读数据是不是一定要读盘？是不是一定要从 redo log 里面把数据更新以后才能返回？\n                    - 不用，此时 Page1 就有正确的数据，虽然磁盘的还是旧数据\n\n\n            - 2. 读 Page 2 时，从磁盘把 Page 2 读入内存，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果\n\n- 思考题\n    - change buffer 一开始是写内存的，如果这个时候机器掉电重启，会不会导致 change buffer 丢失？\n        - 因为 redo log 也记录了 change buffer 的操作，所以崩溃恢复的时候能找回。\n\n- merge 的执行流程\n\n    - 1. 从磁盘读入数据页到内存（老版本的数据页）；\n\n\n    - 2. 从 change buffer 里找出这个数据页的 change buffer 记录（可能有多个），依次应用，得到新版数据页；\n\n\n    - 3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。\n\n\n    - 此时 merge 过程结束，数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据的操作属于另外一个过程。\n\n- 评论区\n\n    - 系统表空间和数据表空间两个概念\n\n        - 系统表空间就是用来放系统信息的，比如数据字典什么的，对应的磁盘文件是ibdata1\n\n\n        - 数据表空间就是一个个的表数据文件，对应的磁盘文件就是 表名.ibd\n\n\n    - change buffer 相当于推迟了更新操作，那对并发控制相关的是否有影响，比如加锁？我一直以为加锁需要把具体的数据页读到内存中来，才能加锁，然而并不是？\n        - 锁是一个单独的数据结构，如果数据页上有锁，change buffer 在判断“是否能用”的时候，就会认为否\n\n\n    - 在 change buffer 中有此行记录的情况下，再次更改，增加一条记录\n\n\n    - merge 行为之后应该不会再产生 redo log 了吧？\n        - 分成两步考虑\n\n            - 第一步，merge 其实是从磁盘读数据页到内存，然后应用，这一步都是更新的内存，同时写 redolog\n\n\n            - 现在内存变成脏页了，跟磁盘数据不一样。之后就走刷脏页的流程。刷脏页也不用写。\n\n\n    - change buffer 跟普通数据页一样也是存在磁盘里，区别在于 change buffer 是在共享表空间 ibdata1 里。\n\n\n    - redo log 有两种，一种记录普通数据页的改动，一种记录 change buffer 的改动。\n\n\n    - 对数据的修改记录在 change buffer 里的时候，内存里是没有这个物理页的，不存在脏页。\n\n\n    - 真正对磁盘数据页的修改是通过内存里脏页的数据刷回磁盘来完成的，而不是根据 redo log。\n\n\n    - redo 日志有分几十种类型的。redo 做的事情，简单讲就是记录页的变化（WAL 将页变化的乱序写转换成了顺序写）。页是分多种的，比如 B+ 树索引页（主键 / 二级索引）、undo 页（数据的多版本 MVCC）、以及现在的change buffer 页等等，这些页被 redo 记录后，就可以不着急刷盘了。change buffer 记录索引页的变化；但是 change buffer 本身也是要持久化的，而它持久化的工作和其他页一样，交给了 redo 日志来帮忙完成；redo 日志记录的是 change buffer 页的变化。change buffer 持久化文件是 ibdata1，索引页持久化文件是 t.ibd。\n\n\n    - change buffer 和数据页一样，也是物理页的一个组成部分，数据结构也是一颗 B+ 树，这棵 B+ 树放在共享表空间中，默认 ibdata1 中。change buffer 写入系统表空间机制应该和普通表的脏页刷新到磁盘是相同的机制 -- Checkpoint 机制；之所以 change buffer 要写入系统表空间，是为了保证数据的一致性，change buffer 做修改时需要写 redo，在做恢复时需要根据 redo 来恢复change buffer，若是不进行 change buffer 写入系统表空间，也就是不进行持久化，那么在 change buffer 写入内存后掉电（也就是篇尾提出的问题），则无法进行数据恢复。这样也会导致索引中的数据和相应表的相应列中的数据不一致。change buffer 写入到了系统表空间，merge 的时候会先查询 change buffer 里对应的记录，然后进行 merge，因为 change buffer B+ 树的 key 是表空间 ID，所以查询根据表空间 ID 查询 change buffer 会很快。\n\n\n    - change buffer 的写盘策略跟数据一样，内存放不下会触发落盘，还有checkpoint 推进的时候也是可能会出发。\n\n\n    - change buffer 是二级索引的变更缓存, 用于减少二级索引更新时带来的随机 IO。\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/10MySQL-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%97%B6%E5%80%99%E4%BC%9A%E9%80%89%E9%94%99%E7%B4%A2%E5%BC%95":{"title":"10｜MySQL 为什么有时候会选错索引？","content":"\n- 优化器的逻辑\n\n    - 扫描行数\n\n        - 一个索引上不同的值越多（指基数），这个索引的区分度就越好。\n\n\n        - 基数（cardinality）：一个索引上不同的值的个数。\n\n            - 采样统计：InnoDB 默认选择索引的 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面树，就得到这个索引的基数。\n\n\n            - 当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。\n\n\n            - 两种存储索引统计的方式，通过设置参数 innodb_stats_persistent 的值选择\n\n                - 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n\n\n                - 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n\n\n        - 从普通索引拿到一个值后，回到主键索引查出整行数据的代价也要算。\n\n\n        - 由于索引统计信息不准确导致的问题，用 analyze table 命令来解决。\n\n\n    - 是否使用临时表\n\n\n    - 是否排序\n\n- 其他优化器误判的情况\n\n    - 可以在应用端用 force index 来强行指定索引；\n\n\n    - 也可以通过修改语句来引导优化器；\n        - 如，当 xxx order by b limit 1; 最终选择 b 索引而不是 a 索引，可能是因为判断使用 b 就可以不用再排序，此时将语句改成 xxx order by b, a limit 1; 是一个可考虑的解决方法（前提是 SQL 语句语义不变）。\n\n\n    - 还可以通过增加或者删除索引来绕过这个问题。\n\n- 思考题\n\n    - 前面我们在构造第一个例子的过程中，通过 session A 的配合，让 session B 删除数据后又重新插入了一遍数据，然后就发现 explain 结果中，rows 字段从 10001 变成 37000 多。而如果没有 session A 的配合，只是单独执行 delete from t 、call idata()、explain 这三句话，会看到 rows 字段其实还是 10000 左右。你可以自己验证一下这个结果。\n\n\n    - 这是什么原因呢？也请你分析一下吧。\n\n        - session A 还没有提交，所以之前插入的 10 万行数据还不能删除。\n\n\n        - 所以之前的数据每一行都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。\n\n\n        - 因为这个是主键，主键是直接按照表的行数来估计的，而表的行数，优化器直接用的是 show table status 的值（后面有章节详细讲解）。\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/11%E4%B8%87%E9%87%91%E6%B2%B9%E7%9A%84-String%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%A5%BD%E7%94%A8%E4%BA%86":{"title":"11｜“万金油”的 String，为什么不好用了？","content":"\n- [Redis 容量预估工具](http://www.redis.cn/redis_memory/)\n- String 类型\n\n  - 元数据：内存空间记录数据长度、空间使用等信息\n  - int 编码方式：当保存 64 位有符号整数时，会保存为 8 字节的 Long 类型整数\n  - 简单动态字符串（Simple Dynamic String，SDS）结构体的组成\n\n    - 图 SDS\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-11-1.png)\n    - buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\\0”，这就会额外占用 1 个字节的开销\n    - len：占 4 个字节，表示 buf 的已用长度\n    - alloc：也占 4 个字节，表示 buf 的实际分配长度，一般大于 len\n\n  - RedisObject 结构体\n\n    - 图\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-11-2.png)\n\n    - 包含了 8 字节的元数据和一个 8 字节指针\n    - 指针指向实际数据，如 SDS\n    - int 编码：当保存 Long 类型整数时，指针直接赋值为整数数据\n    - embstr 编码：保存 \u003c= 44 字节的字符串数据，元数据、指针和 SDS 是一块连续的内存区域\n    - raw 编码：保存 \u003e 44 字节的字符串数据，给 SDS 分配独立的空间\n\n- 哈希表的每一项是一个 dictEntry 的结构体，指向一个键值对\n\n  - 有三个 8 字节的指针\n  - 分别指向 key、value和下一个 dictEntry\n\n- Redis 使用的内存分配库 jemalloc\n\n  - 根据申请的字节数 N，找一个比 N 大的最接近 N 的 2 的幂次数作为分配的空间\n\n    - 减少频繁分配的次数\n\n- 压缩列表 ziplist\n- 示例：用集合类型保存单值的键值对\n\n  - 图片 ID 1101000060\n  - 对象 ID 3302000080\n  - 二级编码：hset 1101000 060 3302000080\n  - 查找时会遍历压缩列表\n  - Sorted Set 也可以达到类似的效果，不过插入时性能没 Hash 高\n\n    - 需排序，而 Hash 直接插入尾部\n\n- Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据\n\n  - hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数\n  - hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度\n  - 数据一旦用了哈希表保存就不会自动转回成压缩列表\n\n- 选用 Hash 和 Sorted Set 存储时，节省空间，但设置过期会变得困难\n- 选用 String 存储时，可以单独设置每个 key 的过期时间，还可以设置 maxmemory 和淘汰策略，以这种方式控制整个实例的内存上限\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/11%E6%80%8E%E4%B9%88%E7%BB%99%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%AD%97%E6%AE%B5%E5%8A%A0%E7%B4%A2%E5%BC%95":{"title":"11｜怎么给字符串字段加索引？","content":"\n- 1. 直接创建完整索引，这样可能比较占用空间；\n\n- 2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n\n    - 即使前缀完全覆盖了字段内容也会回表，因为不确定是不是真的完整数据\n\n\n    - 在索引上找到数据后还需要回到主键上拿到完整数据进行判断\n\n- 3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题，不支持范围扫描；\n    - index index_name(email(6));\n\n- 4. 创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，需要多一个字段保存 hash 字段，不支持范围扫描。\n    - 比如通过 crc32() 函数得到 hash 值\n\n- 思考题\n\n    - 如果你在维护一个学校的学生信息数据库，学生登录名的统一格式是”学号 @gmail.com\", 而学号的规则是：十五位的数字，其中前三位是所在城市编号、第四到第六位是学校编号、第七位到第十位是入学年份、最后五位是顺序编号。\n\n\n    - 系统登录的时候都需要学生输入登录名和密码，验证正确后才能继续使用系统。就只考虑登录验证这个行为的话，你会怎么设计这个登录名的索引呢？\n\n        - 正向反向的前缀索引重复度都比较高\n\n\n        - 只是维护一个学校\n\n\n        - 因此可以只存入学年份 + 顺序编号，长度是 9 位\n\n\n        - 可以用数字类型来存，只占用 4 个字节，属于最简单的 hash 转换规则\n\n\n        - 更好的做法：学校数据不多，直接整个保存\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/12%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E7%9A%84-MySQL-%E4%BC%9A%E6%8A%96%E4%B8%80%E4%B8%8B":{"title":"12｜为什么我的 MySQL 会“抖”一下？","content":"\n- 当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。\n\n- 内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n\n- 即何时内存中的脏页往硬盘上刷？\n\n    - 1. redo log 满\n        ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-12-1.png)\n\n\n        - 把绿色部分的日志对应的所有脏页都 flush 到磁盘上\n\n\n        - 之后，write pos 到 cp' 之间上可以再写入的 redo log 的区域\n\n\n    - 2. 当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘\n\n        - 不直接把内存淘汰掉，下次需求请求的时候从磁盘读入数据页，然后拿 redo log 出来应用的原因\n\n\n        - 是为了保证每个数据页有两种状态\n\n            - 1. 内存里存在，内存里肯定是正确的结果，直接返回；\n\n\n            - 2. 内存里没有数据，可以肯定数据文件上是正确的结果，读入内存后返回。\n\n\n    - 3. MySQL 认为系统“空闲”的时候\n        - 忙的时候也会找机会刷\n\n\n    - 4. 正常关闭数据库时，会把内存的脏页都 flush 到磁盘上，下次启动时直接从磁盘读数据，启动速度快\n\n\n    - 第 2 种情况是常态\n\n        - InnoDB 用缓冲池管理内存，缓冲池中的内存页有三种状态\n\n            - 1. 还没有使用的；\n                - 很少\n\n\n            - 2. 使用了并且是干净页；\n\n\n            - 3. 使用了并且是脏页。\n\n\n        - 当要读入的数据页没有在内存的时候，必须到缓冲池申请一个数据页\n\n            - 把最久不使用的数据页从内存中淘汰掉\n\n                - 1. 如果是干净页，直接释放出来复用；\n\n\n                - 2. 如果是脏页，必须将脏页刷到磁盘\n\n\n            - 影响性能的情况\n\n                - 1. 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；\n\n\n                - 2. 日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。\n\n\n    - InnoDB 刷脏页的控制策略\n\n        - innodb_io_capacity\n\n            - 1. 建议设置成磁盘的 IOPS\n\n\n            - 2. 通过 fio 工具测试 IOPS\n                - fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest\n\n\n        - InnoDB 刷盘速度主要参考两个因素\n\n            - 1. 脏页比例\n\n                - innodb_max_dirty_pages_pct 脏页比例，默认值 75%\n\n\n                - 平时多关注脏页比例，不要让它经常接近 75%\n\n\n                - 脏页比例是通过 Innodb_buffer_pool_pages_dirty/Innodb_buffer_pool_pages_total 得到的，具体的命令参考下面的代码\n                    - mysql\u003e select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';select @a/@b;\n\n\n                - InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字，计算这个数字的伪代码类似这样\n                    - 伪代码\n                        - F1(M){ if M\u003e=innodb_max_dirty_pages_pct then return 100; return 100*M/innodb_max_dirty_pages_pct;}\n\n\n            - 2. redo log 写盘速度\n                - InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。F2(N) 算法比较复杂，你只要知道 N 越大，算出来的值越大就好了。\n\n\n            - 根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。\n                ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-12-2.png)\n\n\n\n        - 在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。\n\n            - 使用 SSD 这类 IOPS 比较高的设备时，建议设为 0\n\n\n            - MySQL 8.0 中默认值为 0\n\n- 思考题\n\n    - 一个内存配置为 128GB、innodb_io_capacity 设置为 20000 的大规格实例，正常会建议你将 redo log 设置成 4 个 1GB 的文件。\n\n\n    - 但如果你在配置的时候不慎将 redo log 设置成了 1 个 100M 的文件，会发生什么情况呢？又为什么会出现这样的情况呢？\n\n        - 每次事务提交都要写 redo log，如果设置太小，很快就会被写满，write pos 一直追着 CP\n\n\n        - 系统不得不停止所有更新，推进 checkpoint\n\n\n        - 现象：磁盘压力很小，但是数据库出现间歇性的性能下跌\n\n- 评论区\n\n    - redo log 在“重放”的时候，如果一个数据页已经刷过，会识别出来并跳过\n\n        - 基于 LSN（log sequence number 日志序列号）\n\n\n        - 每个数据页头部有 LSN，8字节，每次修改都会变大。\n\n\n        - 对比这个 LSN 跟 checkpoint 的 LSN，比 checkpoint 小的一定是干净页\n\n\n    - 将脏页 flush 到磁盘上是直接将脏页数据覆盖到对应磁盘上的数据\n\n\n    - 断电重启后从 checkpoint 的位置往后扫，已经扫过盘的不会重复应用 redo log\n\n\n    - 名词解释\n\n        - plush 刷脏页\n\n\n        - purge 清 undo log\n\n\n        - merge 应用 change buffer\n            - change buffer 只对非唯一索引有效\n\n\n    - 常见的误用场景\n        - 很多测试人员再做压力测试的时候 出现刚开始 insert update 很快 一会 就出现很慢,并且延迟很大，大部分是因为 redo log 设置太小引起的\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/13%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A1%A8%E6%95%B0%E6%8D%AE%E5%88%A0%E6%8E%89%E4%B8%80%E5%8D%8A%E8%A1%A8%E6%96%87%E4%BB%B6%E5%A4%A7%E5%B0%8F%E4%B8%8D%E5%8F%98":{"title":"13｜为什么表数据删掉一半，表文件大小不变？","content":"\n- 参数 innodb_file_per_table\n\n    - OFF：表的数据放在系统共享表空间，也就是跟数据字典放在一起\n\n\n    - ON：每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中\n\n\n    - 从 5.6.6 版本开始是默认值\n\n\n    - 建议无论使用哪个版本都将这个值设置为 ON\n\n\n    - 因为一个表单独存储为一个文件更容易管理\n\n\n    - 在不需要这个表的时候，通过 drop table 命令可以直接删除这个文件，而如果放在共享表空间，即使表删掉了，空间也不会回收。xia m\n\n\n    - 该章节下面的内容基于 ON 展开\n\n- 数据删除流程\n\n    - 删除一行记录，InnoDB 引擎只会把这个记录标记为删除\n        - 当再插入一个在被删记录位置的记录时，可能复用该位置\n\n\n    - 如果删掉一整个数据页上的所有记录，则整个数据页可以被复用\n\n\n    - 数据页的复用跟记录的复用不同\n\n        - 记录的复用只限于符合范围条件的数据\n\n\n        - 数据页的复用可以复用到任何位置\n\n\n    - 如果相邻的两个数据页利用率都很小，系统会把两个页的数据合到其中一个页，另一个被标记为可复用\n\n\n    - 如果用 delete 命令删除整个表的数据，则所有的数据页都会被标记为可复用，但是磁盘上文件不会变小\n\n- 重建表\n\n    - alter table A engine=InnoDB\n        - 起到收缩表 A 的作用\n\n\n    - 5.5 版本之前\n\n        - 新建跟 A 结构相同的表 B，将 A 的数据按照主键 ID 递增的顺序一行行地读出来插入表 B，然后用 B 替换 A\n\n\n        - 隐含意思：alter table t engine=innodb,ALGORITHM=copy;\n\n\n    - 5.6 版本开始引入 Online DDL，对上面的流程做了优化\n\n        - 1. 建立一个临时文件，扫描表 A 主键的所有数据页；\n\n\n        - 2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n\n\n        - 3. 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n\n\n        - 4. 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n\n\n        - 5. 用临时文件替换表 A 的数据文件。\n\n\n        - 隐含意思：alter table t engine=innodb,ALGORITHM=inplace;\n\n\n    - DDL 之前需要拿 MDL 写锁\n\n        - 在真正拷贝数据之前会退化成读锁\n\n\n        - MDL 读锁不会阻塞增删改操作\n\n\n        - 不直接解锁的原因是为了禁止其他县城对这个表同时做 DDL\n\n\n        - 写锁时间很短，对业务来说可以认为是 Online 的\n\n\n    - 上述操作都会扫描元彪数据和构建临时文件，对于大表，很消耗 IO 和 CPU 资源\n\n        - 如果是线上服务，要小心地控制操作时间\n\n\n        - 推荐使用 gh-ost\n\n- Online 和 inplace\n\n    - 5.6 版本之后，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n        - 临时文件也要占用临时空间\n\n\n    - 关系\n\n        - 1. DDL 过程如果是 Online 的，就一定是 inplace 的；\n\n\n        - 2. 反过来未必，inplace 的 DDL，有可能不是 Online 的。\n            - 截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引（SPATIAL index）就属于这种情况\n\n- optimize table、analyze table 和 alter table 这三种方式重建表的区别\n\n    - 从 MySQL 5.6 版本开始，alter table t engine = InnoDB（也就是 recreate）默认的就是上面优化后的流程了；\n\n\n    - analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\n\n\n    - optimize table t 等于 recreate+analyze。\n        - 新的表基本上统计信息是全新的，建议直接用 alter\n\n- 思考题\n\n    - 1. 一个表 t 文件大小为 1TB；\n\n\n    - 2. 对这个表执行 alter table t engine=InnoDB；\n\n\n    - 3. 发现执行完成后，空间不仅没变小，还稍微大了一点儿，比如变成了 1.01TB。\n\n\n    - 原因？\n        - 本来就很紧凑，没能整出多少剩余空间。重新收缩的过程中，页会按 90% 满的比例来重新整理页数据（10% 留给 UPDATE 使用），未整理之前页已经占用 90% 以上，收缩之后，文件就反而变大了。\n\n- 评论区\n\n    - INFORMATION_SCHEMA.INNODB_BUFFER_PAGE 这里面可以看到每个 page 的尺寸，如果离 16KB 很近，那就说明基本满了，做个统计就行了\n\n\n    - 既然mysql支持了打包数据排序模式，能够更紧凑的分配内存进行排序，那定义表结构的时候，varchar(10)存储hello和varchar(100)存储hello的优势在哪里呢？\n        - 以前不支持紧凑排序的时候有，现在没啥了差别了，小于256都差不多\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/14count-%E8%BF%99%E4%B9%88%E6%85%A2%E6%88%91%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E":{"title":"14｜count(*) 这么慢，我该怎么办？","content":"\n- `count(*)` 的实现方式\n\n    - MyISAM 引擎把一个表的总行数存在磁盘上，执行时直接返回这个树\n\n\n    - InnoDB 引擎每次都需要把数据一行行地从引擎里面读出来，累计行数\n\n\n    - 以上都是在说没有过滤条件的 count(*)\n\n- show table status 命令输出结果有一个 TABLE_ROWS 用于显示这个表当前行数，执行很快，但是这个结果是采样估算的（误差可能达到 40% 到 50%）\n\n- 用缓存系统保存计数\n\n    - 比如用 Redis\n\n\n    - 将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的。\n        - 两个系统间存在数据不一致的时刻\n\n- 在数据库保存计数\n\n    - 新建一个表专门用于计数\n\n\n    - 且全部用 InnoDB 引擎\n\n\n    - 修改计数时使用事务\n\n- 不同的 count 用法（InnoDB）\n\n    - count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\n\n\n    - `count(*)`、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n\n\n    - 分析性能差别的时候的原则\n\n        - 1. server 层要什么就给什么；\n\n\n        - 2. InnoDB 只给必要的值；\n\n\n        - 3. 现在的优化器只优化了 `count(*)` 的语义为“取行数”，其他“显而易见”的优化并没有做。\n\n            - count(主键 id)：遍历整张表，把每一行的 id 值都取出来，返回给 server 层，server 层拿到后判断是不可能为空的，就按行累加。\n\n\n            - count(1)：遍历整张表，但不取值，server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n\n\n            - count(字段)\n\n                - 1. 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n\n\n                - 2. 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n\n\n            - `count(*)`：例外，并不会把全部字段取出来，而是专门做了优化，不取值。`count(*)` 肯定不是 null，按行累加。\n                - MySQL 版本 \u003e= 5.5\n\n\n            - 效率：count(字段) \u003c count(主键 id) \u003c count(1) ≈ count(*)\n\n- 思考题\n    - 在刚刚讨论的方案中，我们用了事务来确保计数准确。由于事务可以保证中间结果不被别的事务读到，因此修改计数值和插入新记录的顺序是不影响逻辑结果的。但是，从并发系统性能的角度考虑，你觉得在这个事务序列里，应该先插入操作记录，还是应该先更新计数表呢？\n\n        - 应该先插入记录再更新计数表\n\n\n        - 因为更新计数表涉及到行锁的竞争，先插入再更新能最大程度地减少了事务之间的锁等待，提升了并发度。\n\n- 评论区\n\n    - count(id) 也是可以使用普通索引的\n\n\n    - count 就是一行行读数据，是一致性读（快照读），不加锁\n\n\n    - count(1) 可以认为是返回了 0 个字段\n","lastmodified":"2023-05-20T15:01:12.436019938Z","tags":null},"/15%E7%AD%94%E7%96%91%E6%96%87%E7%AB%A0%E4%B8%80%E6%97%A5%E5%BF%97%E5%92%8C%E7%B4%A2%E5%BC%95%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98":{"title":"15｜答疑文章（一）：日志和索引相关问题","content":"\n- 业务设计问题\n\n    - 业务上有这样的需求，A、B 两个用户，如果互相关注，则成为好友。设计上是有两张表，一个是 like 表，一个是 friend 表，like 表有 user_id、liker_id 两个字段，我设置为复合唯一索引即 uk_user_id_liker_id。语句执行逻辑是这样的：以 A 关注 B 为例：第一步，先查询对方有没有关注自己（B 有没有关注 A）select * from like where user_id = B and liker_id = A;如果有，则成为好友insert into friend;没有，则只是单向关注关系insert into like;但是如果 A、B 同时关注对方，会出现不会成为好友的情况。因为上面第 1 步，双方都没关注对方。第 1 步即使使用了排他锁也不行，因为记录不存在，行锁无法生效。请问这种情况，在 MySQL 锁层面有没有办法处理？\n        - CREATE TABLE `like` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` int(11) NOT NULL, `liker_id` int(11) NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `uk_user_id_liker_id` (`user_id`,`liker_id`)) ENGINE=InnoDB;CREATE TABLE `friend` ( `id` int(11) NOT NULL AUTO_INCREMENT, `friend_1_id` int(11) NOT NULL, `friend_2_id` int(11) NOT NULL, UNIQUE KEY `uk_friend` (`friend_1_id`,`friend_2_id`), PRIMARY KEY (`id`)) ENGINE=InnoDB;\n\n\n    - 首先，要给“like”表增加一个字段，比如叫作 relation_ship，并设为整型，取值 1、2、3。值是 1 的时候，表示 user_id 关注 liker_id;值是 2 的时候，表示 liker_id 关注 user_id;值是 3 的时候，表示互相关注。\n\n\n    - 然后，当 A 关注 B 的时候，逻辑改成如下所示的样子：应用代码里面，比较 A 和 B 的大小，如果 A \u003c B，就执行下面的逻辑\n        - mysql\u003e begin; /*启动事务*/insert into `like`(user_id, liker_id, relation_ship) values(A, B, 1) on duplicate key update relation_ship=relation_ship | 1;select relation_ship from `like` where user_id=A and liker_id=B;/*代码中判断返回的 relation_ship， 如果是1，事务结束，执行 commit 如果是3，则执行下面这两个语句： */insert ignore into friend(friend_1_id, friend_2_id) values(A,B);commit;\n\n\n    - 如果 A \u003e B，则执行下面的逻辑\n        - mysql\u003e begin; /*启动事务*/insert into `like`(user_id, liker_id, relation_ship) values(B, A, 2) on duplicate key update relation_ship=relation_ship | 2;select relation_ship from `like` where user_id=B and liker_id=A;/*代码中判断返回的 relation_ship， 如果是2，事务结束，执行 commit 如果是3，则执行下面这两个语句：*/insert ignore into friend(friend_1_id, friend_2_id) values(B,A);commit;\n\n\n    - 这个设计里，让“like”表里的数据保证 user_id \u003c liker_id，这样不论是 A 关注 B，还是 B 关注 A，在操作“like”表的时候，如果反向的关系已经存在，就会出现行锁冲突。然后，insert … on duplicate 语句，确保了在事务内部，执行了这个 SQL 语句后，就强行占住了这个行锁，之后的 select 判断 relation_ship 这个逻辑时就确保了是在行锁保护下的读操作。操作符 “|” 是按位或，连同最后一句 insert 语句里的 ignore，是为了保证重复调用时的幂等性。这样，即使在双方“同时”执行关注操作，最终数据库里的结果，也是 like 表里面有一条关于 A 和 B 的记录，而且 relation_ship 的值是 3， 并且 friend 表里面也有了 A 和 B 的这条记录。\n\n- 思考题\n\n    - 创建一个简单的表 t，并插入一行，然后对这一行做修改。mysql\u003e CREATE TABLE `t` (`id` int(11) NOT NULL primary key auto_increment,`a` int(11) DEFAULT NULL) ENGINE=InnoDB;insert into t values(1,2);\n\n\n    - 这时候，表 t 里有唯一的一行数据 (1,2)。假设，执行：mysql\u003e update t set a=2 where id=1;\n        - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-15-1.png)\n\n\n\n    - 仅从现象上看，MySQL 内部在处理这个命令的时候，可以有以下三种选择：\n\n        - 1. 更新都是先读后写的，MySQL 读出数据，发现 a 的值本来就是 2，不更新，直接返回，执行结束；\n            ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-15-2.png)\n\n            - session B 的 update 语句被 blocked 了，加锁这个动作是 InnoDB 才能做的，所以排除选项 1。\n\n\n        - 2. MySQL 调用了 InnoDB 引擎提供的“修改为 (1,2)”这个接口，但是引擎发现值与原来相同，不更新，直接返回；\n            ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-15-3.png)\n\n\n            - session A 的第二个 select 语句是一致性读（快照读)，它是不能看见 session B 的更新的。\n\n\n            - 现在它返回的是 (1,3)，表示它看见了某个新的版本，这个版本只能是 session A 自己的 update 语句做更新的时候生成。所以排除选项 2。\n                - 可以回顾下第 8 篇文章\n\n\n        - 3. InnoDB 认真执行了“把这个值修改成 (1,2)\"这个操作，该加锁的加锁，该更新的更新。\n            - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-15-4.png)\n\n\n\n    - 你觉得实际情况会是以上哪种呢？你可否用构造实验的方式，来证明你的结论？进一步地，可以思考一下，MySQL 为什么要选择这种策略呢？\n        - 验证结果都在 binlog_format=statement 格式下进行\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/16order-by%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84":{"title":"16｜“order by”是怎么工作的？","content":"\n- MySQL 会给每个线程分配一块内存用于排序，称为 sort_buffer\n- select city,name,age from t where city='杭州' order by name limit 1000 ;\n\n  - city varchar 16，name varchar 16，age int 11，city 有索引\n  - 1. 初始化 sort_buffer，确定放入 name、city、age 这三个字段；\n  - 2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id；\n  - 3. 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；\n  - 4. 从索引 city 取下一个记录的主键 id；\n  - 5. 重复步骤 3、4 直到 city 的值不满足查询条件为止；\n  - 6. 对 sort_buffer 中的数据按照字段 name 做快速排序；\n\n    - 可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\n\n  - 7. 按照排序结果取前 1000 行返回给客户端。\n  - 全字段排序\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-16-1.png)\n\n\n- sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。\n- 确定一个排序语句是否使用了临时文件\n\n  - /* 打开optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* @a保存Innodb_rows_read的初始值 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 执行语句 */select city, name,age from t where city='杭州' order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = 'Innodb_rows_read';/* 计算Innodb_rows_read差值，表示整个执行过程扫描了多少行 */select @b-@a;\n\n- 外部排序时，一般使用归并排序算法\n- 如果 MySQL 认为排序的单行长度太大会怎么做呢？\n\n  - max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\n\n    - 如果只算 rowid 还是小于此设置，一样是 rowid 排序，但是会转用磁盘排序\n\n  - 设置值为 16，小于前面查询语句排序的三个字段的总和\n  - 此时因为无法直接返回了，整个执行流程变成下面的样子\n  - 1. 初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n  - 2. 从索引 city 找到第一个满足 city='杭州’条件的主键 id；\n  - 3. 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n  - 4. 从索引 city 取下一个记录的主键 id；\n  - 5. 重复步骤 3、4 直到不满足 city='杭州’条件为止；\n  - 6. 对 sort_buffer 中的数据按照字段 name 进行排序；\n  - 7. 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n\n    - 不需要在服务端再耗费内存存储结果，是直接返回给客户端的\n\n  - rowid 排序\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-16-2.png)\n\n\n- 全字段排序 VS rowid 排序\n\n  - MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n  - 对于 InnoDB 表来说，rowid 排序会要求回表多造成磁盘读，因此不会被优先选择。\n\n- 如果数据天然有序，则 order by 并不需要上面的排序操作，会执行快很多\n\n  - 比如将 city 索引改成 city + name 的联合索引\n\n- 如果建立三个字段的联合索引，还能省去回表过程\n\n  - Explain 结果的 Extra 字段如果有 Using index 则表示使用了覆盖索引\n  - 回表的操作是随机 IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问\n\n- 思考题\n\n  - 假设你的表里面已经有了 city_name(city, name) 这个联合索引，然后你要查杭州和苏州两个城市中所有的市民的姓名，并且按名字排序，显示前 100 条记录。如果 SQL 查询语句是这么写的 ：\n  - mysql\u003e select * from t where city in ('杭州',\"苏州\") order by name limit 100;\n  - 这个语句执行的时候会有排序过程吗，为什么？\n\n    - 有，单个 city 内部的 name 才是递增的\n\n  - 如果业务端代码由你来开发，需要实现一个在数据库端不需要排序的方案，你会怎么实现呢？\n\n    - 分成两个查询语句分别查一百条，然后在业务代码中合并查询结果\n\n  - 进一步地，如果有分页需求，要显示第 101 页，也就是说语句最后要改成 “limit 10000,100”， 你的实现方法又会是什么呢？\n\n    - select * from t where city=\"杭州\" order by name limit 10100; select * from t where city=\"苏州\" order by name limit 10100。\n\n      - 数据量太大时可以把 * 改写成只返回必要的数据\n\n- 评论区\n\n  - varchar(n)，n 的值中，255 是个边界，小于等于 255 需要一个字节记录长度，超过就需要两个字节\n  - 排序相关的内存在排序后就会释放掉，还给系统\n  - 假设给一行的 a 值加 1，执行器先找引擎取行，此时已经加了写锁\n  - 引擎内部自己调用，读取行，不加扫描行数\n\n    - 对于 using index condition 的场景，执行器只调用了一次查询接口，回表是由存储层来完成的，所以扫描行数只算一次，即只算走索引搜索的过程中扫描的行数。\n    - 加索引的时候，要扫描全表，但如果是inplace DDL（@第13篇），你会看到扫描行数是0，也是因为这些扫描动作都是引擎内部自己调用的。\n\n  - Using where 包含了一个“值比较”的过程。\n\n    - using index condiction 索引下推using index 索引覆盖using where 代表过滤元组 可以理解为使用了where using where 和 using index一起出现代表使用了索引过滤数据\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/17%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%9C%B0%E6%98%BE%E7%A4%BA%E9%9A%8F%E6%9C%BA%E6%B6%88%E6%81%AF":{"title":"17｜如何正确地显示随机消息？","content":"\n- 内存临时表\n\n  - explain 结果中 extra 包含 Using temporary，表示的是需要使用临时表\n  - Using filesort 表示需要执行排序操作\n  - 比如执行 order by rand() 的时候就需要用到上面两个\n  \n    - 随机排序完整执行流程图\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-17-1.png)\n\n    - 其中的 pos 是数据的位置信息\n\n- 对于内存表，回表过程只是简单地根据数据行的位置直接访问内存得到数据，MySQL 优化器没有多访问磁盘的顾虑，会直接选择 rowid 排序（排序的行越小越好）\n- 学习技巧：先通过原理分析算出扫描行数，然后再通过查看慢查询日志，来验证自己的结论\n- rowid 的含义：每个引擎用来唯一标识数据行的信息\n\n  - 对于有主键的 InnoDB 表来说，这个 rowid 就是主键 ID；\n  - 对于没有主键的 InnoDB 表来说，这个 rowid 就是由系统生成的；\n  - MEMORY 引擎不是索引组织表。在这个例子里面，你可以认为它就是一个数组。因此，这个 rowid 其实就是数组的下标。\n\n- 磁盘临时表\n\n  - tmp_table_size 配置限制内存表的大小，默认值 16M\n  - 如果临时表过大，就会转成磁盘临时表\n  - 当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n  - 对于使用磁盘临时表的 order by rand()，MySQL 5.6 版本引入了一个新的排序算法：优先队列排序算法\n\n    - set tmp_table_size=1024;set sort_buffer_size=32768;set max_length_for_sort_data=16;/* 打开 optimizer_trace，只对本线程有效 */SET optimizer_trace='enabled=on'; /* 执行语句 */select word from words order by rand() limit 3;/* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\\G\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-17-2.png)\n\n\n      - 结果中，chosen 表示使用了优先队列排序算法\n\n        - 因为没用到临时文件，所以 number_of_tmp_files 是 0\n\n    - 1. 对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；\n    \n    - 如果构成的堆大小超过 sort_buffer_size 的大小，只能使用归并排序算法\n    \n    - 2. 取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n    - 3. 重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n\n- 不用 order by rand() 的随机排序方法（推荐）\n\n  - 随机算法 1\n  \n    - mysql\u003e select max(id),min(id) into @M,@N from t ;set @X= floor((@M-@N+1)*rand() + @N);select * from t where id \u003e= @X limit 1;\n    - 1. 取得表的主键的最大和最小值；\n    \n      - 此操作不需要扫描索引\n    \n    - 2. 用随机函数生成一个最大到最小值之间的数 X = (M-N)*rand() + N；\n    - 3. 取不小于 X 的第一个 ID 的行。\n    \n      - 可以用索引快速定位\n    \n    - 效率高，适用于 ID 严格递增的情况\n    \n      - 即没有空洞\n      - 可以人为对数据进行处理，使数据符合条件\n  \n  - 随机算法 2\n  \n    - mysql\u003e select count(*) into @C from t;set @Y = floor(@C * rand());set @sql = concat(\"select * from t limit \", @Y, \",1\");prepare stmt from @sql;execute stmt;DEALLOCATE prepare stmt;\n    - 1. 取得整个表的行数，记为 C；\n    - 2. 取得 Y = floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。\n    - 3. 再用 limit Y,1 取得一行。\n    - 比算法 1 代价高，但还是比 order by rand() 小很多\n  \n  - 随机算法 3\n  \n    - mysql\u003e select count(*) into @C from t;set @Y1 = floor(@C * rand());set @Y2 = floor(@C * rand());set @Y3 = floor(@C * rand());select * from t limit @Y1，1； //在应用代码里面取Y1、Y2、Y3值，拼出SQL后执行select * from t limit @Y2，1；select * from t limit @Y3，1；\n\n- 思考题\n\n  - 优化算法 3\n  \n  - 将三个 Y 排序，从小的开始查，下一个 Y 从中断的地方接着查\n  - 也可以先取回 id 值，在应用中确定三个 id 值以后，执行三次 where id=X 的语句\n  - 下一章给的答案\n  \n    - 取 Y1、Y2 和 Y3 里面最大的一个数，记为 M，最小的一个数记为 N，然后执行下面这条 SQL 语句：mysql\u003e select * from t limit N, M-N+1;取出来后再拿到三个 Y；再加上取整个表总行数的 C 行，这个方案的扫描行数总共只需要 C+M+1 行。\n\n- 评论区\n\n  - 排序操作是在 server 层做的\n  - 排序过程本身不增加扫描行数，扫描原表和内存表会增加\n  - 只要 sort buffer 足够，就采用优先队列排序，而不用管到底是全字段排序还是 rowid 排序，前提是有 limit 子句\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/18%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%BA%9B-SQL-%E8%AF%AD%E5%8F%A5%E9%80%BB%E8%BE%91%E7%9B%B8%E5%90%8C%E6%80%A7%E8%83%BD%E5%8D%B4%E5%B7%AE%E5%BC%82%E5%B7%A8%E5%A4%A7":{"title":"18｜为什么这些 SQL 语句逻辑相同，性能却差异巨大？","content":"\n- 案例一：条件字段函数操作\n\n  - 原语句：mysql\u003e select count(*) from tradelog where month(t_modified)=7;\n  \n    - 字段值如：2017-7-1\n  \n  - 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能\n  - 但是，优化器并不是要放弃使用这个索引，还可以选择遍历主键索引，也可以选择遍历索引 t_modified\n  - 优化方案：mysql\u003e select count(*) from tradelog where    -\u003e (t_modified \u003e= '2016-7-1' and t_modified\u003c'2016-8-1') or    -\u003e (t_modified \u003e= '2017-7-1' and t_modified\u003c'2017-8-1') or     -\u003e (t_modified \u003e= '2018-7-1' and t_modified\u003c'2018-8-1');\n\n- 案例二：隐式类型转换\n\n  - mysql\u003e select * from tradelog where tradeid=110717;\n  \n    - 相当于：mysql\u003e select * from tradelog where CAST(tradid AS signed int) = 110717;\n  \n  - 因为 tradeid 的字段类型是 varchar(32)，输入的参数是整形，所以该语句需要走全表扫描\n  \n    - 如果字段是整形，输入是字符串，则可以走索引\n  \n  - 数据类型转换的规则\n  - 为什么有数据类型转换就需要走全索引扫描\n  \n    - 这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能。\n\n- 案例三：隐式字符编码转换\n\n  - 两个表的字符集不同，一个是 utf8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引\n  \n    - utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是“按数据长度增加的方向”进行转换的。\n    - 例子：select * from trade_detail where CONVERT(traideid USING utf8mb4)=$L2.tradeid.value; \n  \n  - 优化方案\n  \n    - 1. 把两个表的字段的字符集改成 utf8mb4\n    \n    - 推荐做法\n    \n    - 2. 如果表数据量太大，或者业务上暂时不能做这个 DDL 的话，只能采用修改 SQL 语句的方法\n    \n      - mysql\u003e select d.* from tradelog l , trade_detail d where d.tradeid=CONVERT(l.tradeid USING utf8) and l.id=2; \n\n- 案例都在说同一件事：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n- 虽然执行过程中可能经过函数操作，但是最终在拿到结果后，server 层还是要做一轮判断的。\n- 评论区\n\n  - 表的访问顺序与连接方式、条件字段有关，跟书写顺序无关\n  \n    - 可参考《数据库索引设计与优化》第八章的表访问顺序对索引设计的影响\n  \n  - 先 where，再 order by，最后 limit。\n- 字符串都选 utf8mb4\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/19%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E5%8F%AA%E6%9F%A5%E4%B8%80%E8%A1%8C%E7%9A%84%E8%AF%AD%E5%8F%A5%E4%B9%9F%E6%89%A7%E8%A1%8C%E8%BF%99%E4%B9%88%E6%85%A2":{"title":"19｜为什么我只查一行的语句，也执行这么慢？","content":"\n- 有个表 t：mysql\u003e CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB;\n- 第一类：查询长时间不返回\n\n  - 等 MDL 锁\n\n    - 使用 show processlist 命令查看 Waiting for table metadata lock 的示意图\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-1.png)\n\n    - 出现这个状态表示的是，现在有一个线程正在表 t 上请求或持有 MDL 写锁，把 select 语句堵住了\n    - 简单的复现步骤\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-2.png)\n\n    - 处理方式：找到谁持有 MDL 写锁，kill 掉\n    - 但是，由于在 show processlist 的结果里面，session A 的 Command 列是“Sleep”，导致查找起来很不方便。不过有了 performance_schema 和 sys 系统库以后，就方便多了。（MySQL 启动时需要设置 performance_schema=on，相比于设置为 off 会有 10% 左右的性能损失)\n    - 通过查询 sys.schema_table_lock_waits 这张表，我们就可以直接找出造成阻塞的 process id，把这个连接用 kill 命令断开即可。\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-3.png)\n\n\n  - 等 flush\n\n    - mysql\u003e select * from information_schema.processlist where id=1;\n    - Waiting for table flush 状态示意图\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-4.png)\n\n    - 现在有一个线程正要对表 t 做 flush 操作。MySQL 里面对表做 flush 操作的用法，一般有以下两个：flush tables t with read lock;flush tables with read lock;\n\n      - 如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。\n      - 但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。\n      - 所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。\n\n    - 排查\n\n      - 图 7\n        - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-5.png)\n\n      - 这个例子的排查也很简单，你看到这个 show processlist 的结果，肯定就知道应该怎么做了。\n\n  - 等行锁\n\n    - mysql\u003e select * from t where id=1 lock in share mode;\n    - 由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-6.png)\n\n    - 行锁 show processlist\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-7.png)\n\n\n      - session A 启动了事务，占有写锁，还不提交，是导致 session B 被堵住的原因。\n\n    - MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到是谁占着行锁mysql\u003e select * from t sys.innodb_lock_waits where locked_table='`test`.`t`'\\G\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-8.png)\n\n    - 可以看到，这个信息很全，4 号线程是造成堵塞的罪魁祸首。而干掉这个罪魁祸首的方式，就是 KILL QUERY 4 或 KILL 4。不过，这里不应该显示“KILL QUERY 4”。这个命令表示停止 4 号线程当前正在执行的语句，而这个方法其实是没有用的。因为占有行锁的是 update 语句，这个语句已经是之前执行完成了的，现在执行 KILL QUERY，无法让这个事务去掉 id=1 上的行锁。实际上，KILL 4 才有效，也就是说直接断开这个连接。这里隐含的一个逻辑就是，连接被断开的时候，会自动回滚这个连接里面正在执行的线程，也就释放了 id=1 上的行锁。\n\n- 第二类：查询慢\n\n  - 在连接后执行 set long_query_time=0 可以将慢查询日志的时间阈值设置为 0\n  - 一个例子\n\n    - 800 毫秒mysql\u003e select * from t where id=1；\n\n      - id 上有索引\n\n  - 0.2 毫秒mysql\u003e select * from t where id=1 lock in share mode；\n  - 提示\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-9.png)\n\n  - 复现\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-19-10.png)\n\n  - 带 lock in share mode 的 SQL 语句，是当前读，因此会直接读到 1000001 这个结果，所以速度很快；而 select * from t where id=1 这个语句，是一致性读，因此需要从 1000001 开始，依次执行 undo log，执行了 100 万次以后，才将 1 这个结果返回。\n\n- 思考题\n\n  - begin;select * from t where c=5 for update;commit;\n\n    - c 上没索引\n\n  - 这个语句序列是怎么加锁的呢？\n\n    - RR 隔离级别下，为保证 binlog 记录顺序，非索引更新会锁住全表记录，且事务结束前不会对不符合条件记录有逐步释放的过程。\n    - 在 Read Committed 隔离级别下，会锁上聚簇索引中的所有记录；\n    - 在 Repeatable Read 隔离级别下，会锁上聚簇索引（主键索引）中的所有记录，并且会锁上聚簇索引内的所有 GAP（间隙锁）；\n\n  - 加的锁又是什么时候释放呢？\n\n    - commit 的时候释放\n    - 在上面两个隔离级别的情况下，如果设置了 innodb_locks_unsafe_for_binlog 开启 semi-consistent read 的话，对于不满足查询条件的记录，MySQL 会提前放锁，不过加锁的过程是不可避免的。\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/20%E5%B9%BB%E8%AF%BB%E6%98%AF%E4%BB%80%E4%B9%88%E5%B9%BB%E8%AF%BB%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98":{"title":"20｜幻读是什么，幻读有什么问题？","content":"\n\n- InnoDB 的默认事务隔离级别是可重复读\n- 和下一章共用的表：CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  `d` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n- 幻读\n\n  - 幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n  - 1. 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n  - 2. 幻读仅专指“新插入的行”。\n\n- 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”\n- 幻读有什么问题？\n\n  - 语义上被破坏，比如，假设只把所有 d = 5 的行锁住，不准别的事务进行读写操作，此时更新别的未被锁住的 d != 5 的行，让 d = 5\n  - 数据一致性问题\n\n    - 即使把要即将要改成 d = 5 的行也锁住，还是拦不住插入 d = 5 的行\n\n- 解决\n\n  - InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n  \n    - 间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-20-1.png)\n\n    - 间隙锁记为开区间\n  \n  - 跟间隙锁存在冲突关系的，是“往这个间隙中插入一个记录”这个操作。间隙锁之间都不存在冲突关系。\n  - 间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。\n  \n    - 如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。\n\n- 间隙锁和 next-key lock 的引入带来的问题\n\n  - 加大了加锁范围，降低并发度\n\n- 上面的讨论都是在可重复度隔离级别下的，间隙锁在此级别下才会生效\n- 如果改成读提交，就没有间隙锁，同时也不会有上面的问题，但同时也需要把 binlog 格式设置为 row\n\n  - 常见的配置组合：读提交 + binlog_format=row\n\n- 思考题\n\n  - 图\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-20-2.png)\n\n\n    - B 和 C 都会进入锁等待状态\n  \n  - 原因是什么\n  \n    - desc，向右扫描变成向左扫描\n    - 前开后闭没变\n    - 加锁范围\n    \n      - (20, 25) (15, 20] (5, 10]\n\n- 评论区\n\n  - MySQL 里单引号双引号一样\n  - \u003c= 是间隙锁还是行锁？\n  \n    - 找第一个值是，按等值，找下一个值，按范围查找\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/21%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E5%8F%AA%E6%94%B9%E4%B8%80%E8%A1%8C%E7%9A%84%E8%AF%AD%E5%8F%A5%E9%94%81%E8%BF%99%E4%B9%88%E5%A4%9A":{"title":"21｜为什么我只改一行的语句，锁这么多？","content":"\n- 规则的前提说明\n\n  - 加锁策略可能改变，下面的只限于 5.x 系列 \u003c= 5.7.24，8.0 系列 \u003c= 8.0.13\n\n- 间隙锁在可重复读隔离级别下才有效\n\n  - 读提交在外键场景下也有\n\n- 两个原则、两个优化、一个 bug\n\n  - 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n  - 原则 2：查找过程中访问到的对象才会加锁。\n\n    - 逐个加\n\n  - 优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n  - 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n  - 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n    - MySQL 8.0.18 版本已修复\n\n- 八个案例\n\n  - lock in share mode 只锁覆盖索引，而执行 for update 时，系统人为接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁；\n\n    - 说明锁是加在索引上的\n\n  - 要用 lock in share mode 给行加读锁避免数据被更新的话，必须得绕过覆盖索引的优化，在查询字段中加入索引中不存在的字段\n\n    - 比如，将查询语句 select id from t where c=5;改成 select d from t where c=5 lock in share mode;\n\n  - 等价的语句加锁范围不一定相同\n\n  - 比如等值查询和范围查询\n\n  - delete 语句加锁的逻辑跟 select … for update 类似\n  - 在删除数据的时候尽量加 limit\n\n  - 不仅可以控制删除数据的条数，还可以减小加锁的范围\n\n  - 加 next-key lock 实际上是分成来两步，先加间隙锁，然后再加行锁\n\n- 小结\n\n  - 读提交隔离级别下还有一个优化：语句执行过程中加上的行锁，在语句执行完成后，就要把“不满足条件的行”上的行锁直接释放，不需要等到事务提交\n\n    - 锁的范围更小，锁的时间更短\n    - 不少业务默认使用读提交隔离级别的原因\n    - 只对 update 有效，delete 无效\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/22MySQL%E6%9C%89%E5%93%AA%E4%BA%9B%E9%A5%AE%E9%B8%A9%E6%AD%A2%E6%B8%B4%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E6%96%B9%E6%B3%95":{"title":"22｜MySQL有哪些“饮鸩止渴”提高性能的方法？","content":"\n- 短连接风暴\n\n  - max_connections 参数控制一个 MySQL 实例同时存在的连接数上限\n\n    - 超过这个数，系统就会拒绝接下来的连接请求，并报错提示“Too many connections”\n    - 只要连着就会计数\n\n  - 解决方案\n\n    - 一、先处理掉那些占着连接但是不工作的线程\n\n        - wait_timeout 参数设置一个线程在多少秒后会被 MySQL 直接断开连接\n        - 在服务端执行命令：kill connection + id\n\n          - 直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。\n\n      - 在 show processlist 的结果里找到可以踢掉的连接\n\n        -   先断开事务外空闲的连接\n        -   还不够的情况下再考虑断开事务内空闲太久的连接\n\n          -   会导致事务回滚\n\n        -   查看事务具体状态\n\n          -   查 information_schema 库的 innodb_trx 表\n\n    - 二、减少连接过程的消耗\n\n      - 使用 --skip-grant-tables 参数启动 MySQL，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内\n      - 风险极高，MySQL 8.0 会默认把 --skip-networking 参数打开，表示只能被本地客户端连接\n\n- 慢查询性能问题\n\n  - 1. 索引没有设计好\n\n    - MySQL 5.6 后创建索引支持 Online DDL，对于高峰期数据库，最高校的做法是直接 alter table\n\n      - 理想流程\n\n        - 1. 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；\n        - 2. 执行主备切换；\n        - 3. 这时候主库是 B，备库是 A。在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。\n\n    - 会有大量 binlog 日志，所以需要先关闭\n    - 但是，会导致 binlog 缺少这个 DDL 语句，需要另一个知识点（主备同步协议），在后面的文章有说明\n\n      - 假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样：1. 在实例 X 上执行 stop slave。2. 在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。3. 执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。4. 到实例 X 上执行以下语句序列：set GTID_NEXT=\"server_uuid_of_Y:gno\";begin;commit;set gtid_next=automatic;start slave;这样做的目的在于，既可以让实例 Y 的更新有 binlog 记录，同时也可以确保不会在实例 X 上执行这条更新。接下来，执行完主备切换，然后照着上述流程再执行一遍即可。\n\n    - 更稳妥的做法是考虑类似 gh-ost 的方案\n\n  - 2. SQL 语句没写好\n\n    - 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式\n    - 查看是否重写成功\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-22-1.png)\n\n\n  - 3. MySQL 选错了索引\n\n    - 在原语句加上 force index\n    - 使用查询重写功能给语句加上 force index\n\n  - 通过此过程可以预先发现问题\n\n    - 1. 上线前，在测试环境，把慢查询日志（slow log）打开，并且把 long_query_time 设置成 0，确保每个语句都会被记录入慢查询日志；\n    - 2. 在测试表里插入模拟线上的数据，做一遍回归测试；\n    - 3. 观察慢查询日志里每类语句的输出，特别留意 Rows_examined 字段是否与预期一致。（我们在前面文章中已经多次用到过 Rows_examined 方法了，相信你已经动手尝试过了。如果还有不明白的，欢迎给我留言，我们一起讨论）。\n\n  - 全量测试时，使用工具检查所有的 SQL 语句的返回结果\n\n    - 比如 [pt-query-digest](https://docs.percona.com/percona-toolkit/pt-query-digest.html)\n\n- QPS 突增问题\n\n  - 最理想的情况是让业务把功能下掉\n  - 对于从数据库端处理\n\n    - 1. 一种是由全新业务的 bug 导致的。假设你的 DB 运维是比较规范的，也就是说白名单是一个个加的。这种情况下，如果你能够确定业务方会下掉这个功能，只是时间上没那么快，那么就可以从数据库端直接把白名单去掉。\n    - 2. 如果这个新功能使用的是单独的数据库用户，可以用管理员账号把这个用户删掉，然后断开现有连接。这样，这个新功能的连接不成功，由它引发的 QPS 就会变成 0。\n    - 3. 如果这个新增的功能跟主体功能是部署在一起的，那么我们只能通过处理语句来限制。这时，我们可以使用上面提到的查询重写功能，把压力最大的 SQL 语句直接重写成\"select 1\"返回。\n\n      - a. 如果别的功能里面也用到了这个 SQL 语句模板，会有误伤；\n      - b. 很多业务并不是靠这一个语句就能完成逻辑的，所以如果单独把这一个语句以 select 1 的结果返回的话，可能会导致后面的业务逻辑一起失败。\n\n- 思考题\n\n  - 你是否碰到过，在业务高峰期需要临时救火的场景？你又是怎么处理的呢？\n\n    - 如果一个数据库是被客户端的压力打满导致无法响应的，重启数据库是没用的。因为重启之后，业务请求还会再发。而且由于是重启，buffer pool 被清空，可能会导致语句执行得更慢。\n    - 有时候一个表上会出现多个单字段索引（而且往往这是因为运维工程师对索引原理不够清晰做的设计），这样就可能出现优化器选择索引合并算法的现象。但实际上，索引合并算法的效率并不好。而通过将其中的一个索引改成联合索引的方法，是一个很好的应对方案。\n    - 客户端程序的连接器，连接完成后会做一些诸如 show columns 的操作，在短连接模式下这个影响就非常大了。\n\n      - 这个提醒我们，在 review 项目的时候，不止要 review 我们自己业务的代码，也要 review 连接器的行为。一般做法就是在测试环境，把 general_log 打开，用业务行为触发连接，然后通过 general log 分析连接器的行为。\n\n    - 如果你的数据库请求模式直接对应于客户请求，这往往是一个危险的设计。因为客户行为不可控，可能突然因为你们公司的一个运营推广，压力暴增，这样很容易把数据库打挂。在设计模型里面设计一层，专门负责管理请求和数据库服务资源，对于比较重要和大流量的业务，是一个好的设计方向。\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/23MySQL-%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%E7%9A%84":{"title":"23｜MySQL 是怎么保证数据不丢的？","content":"\n- 只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。\n- binlog 的写入机制\n\n  - 写入逻辑：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。\n\n    - 一个事务的 binlog 是要确保一次性写入的，不能被打断\n    - 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。\n    - 事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图所示。\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-23-1.png)\n\n\n      - 图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。\n      - 图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。\n      - write 和 fsync 的时机，是由参数 sync_binlog 控制的：\n\n        - 1. sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；\n        - 2. sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；\n        - 3. sync_binlog=N(N\u003e1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。\n\n          - 如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。\n\n- redo log 的写入机制\n\n  - 都要先写到 redo log buffer\n\n    - 不用每次生成后都直接持久化到磁盘\n\n      - 如果事务执行期间 MySQL 异常重启，这部分日志丢了，由于事务并没有提交，所以没损失\n\n    - 事务没提交，这时日志也有可能被持久化到磁盘\n\n  - redo log 的存储状态\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-23-2.png)\n\n  - 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数\n\n    - 1. 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 ;\n    - 2. 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；\n    - 3. 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。\n\n  - InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。\n\n    - 没有提交的事务的 redo log 也会\n\n  - 另外两个会让没有提交的事务的 redo log 写入到磁盘的场景\n\n    - 1. 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统的 page cache。\n    - 2. 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交，如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘。\n\n- 通常我们说 MySQL 的“双 1”配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1。也就是说，一个事务完整提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog。\n- 组提交机制\n\n  - 日志逻辑序列号（log sequence number，LSN）\n\n    - 单调递增，用来对应 redo log 的一个个写入点\n    - 每次写入长度为 length 的 redo log， LSN 的值就会加上 length。\n    - LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log\n\n  - 一次组提交里面，组员越多，节约磁盘 IOPS 的效果越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了。\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-23-3.png)\n\n\n    - trx1 先到达，会被选为 leader\n    - 开始写盘，因为组里有了三个事务，所以 LSN 变成了最大值 160\n    - 等到 trx1 返回时，所有 LSN 小于等于 160 的 redo log 都已经被持久化到磁盘，所以 trx2 和 trx3 可以直接返回\n\n  - 在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好。\n  - 为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。\n\n    - 两阶段提交\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-23-4.png)\n\n    - 两阶段提交细化\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-23-5.png)\n\n    - 写 binlog 是分成两步的\n\n      - 1. 先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件；\n      - 2. 调用 fsync 持久化。\n\n    - MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后\n    - 3 执行很快，所以 binlog 的组提交效果通常不如 redo log 的效果好\n\n  - 提升 binlog 组提交的效果\n\n    - 1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\n    - 2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n    - 两个条件是 或 的关系\n\n- WAL 机制是减少磁盘写，但每次提交事务都要写 redo log 和 binlog，磁盘读写没减少？\n\n  - 1. redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快；\n  - 2. 组提交机制，可以大幅度降低磁盘的 IOPS 消耗。\n\n- MySQL 出现 IO 性能瓶颈的提升性能方法\n\n  - 1. 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方法是基于“额外的故意等待”来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险。\n  - 2. 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000）。这样做的风险是，主机掉电时会丢 binlog 日志。\n  - 3. 将 innodb_flush_log_at_trx_commit 设置为 2。这样做的风险是，主机掉电的时候会丢数据。\n\n    - 不建议设置为 0（只保存在内存中）\n    - 0 跟 2 的性能差不多，但 2 的风险更小\n\n- 实际上数据库的 crash-safe 保证的是：\n\n  - 1. 如果客户端收到事务成功的消息，事务就一定持久化了；\n\n    - 双 1 配置\n\n  - 2. 如果客户端收到事务失败（比如主键冲突、回滚等）的消息，事务就一定失败了；\n  - 3. 如果客户端收到“执行异常”的消息，应用需要重连后通过查询当前状态来继续后续的逻辑。此时数据库只需要保证内部（数据和日志之间，主库和备库之间）一致就可以了。\n\n- 思考题\n\n- 你的生产库设置的是“双 1”吗？ 如果平时是的话，你有在什么场景下改成过“非双 1”吗？你的这个操作又是基于什么决定的？\n\n  - 1. 业务高峰期\n  - 2. 备库延迟\n  - 3. 用备份恢复主库的副本，应用 binlog 的过程\n  - 4. 批量导入数据的时候\n\n- 我们都知道这些设置可能有损，如果发生了异常，你的止损方案是什么？\n- 一般情况下，把生产库改成“非双 1 ”配置，是设置innodb_flush_logs_at_trx_commit=2sync_binlog=1000\n\n- 评论区\n\n  - 看到的“binlog的记录”，也是从 page cache 读的page cache 是操作系统文件系统上的\n\n    - ls 的结果也是\n\n  - 为什么 binlog cache 是每个线程自己维护的，而 redo log buffer 是全局共用的？\n\n    - binlog存储是以 statement 或者 row 格式存储的，而 redo log 是以 page 页格式存储的。page 格式，天生就是共有的，而 row 格式，只跟当前事务相关\n    - 我跟这位同学一样，在这里联系到 binlog 的格式，statement 记录的是更新的 SQL，但是要写上下文，因此不能中断，要不同步到从库无法恢复一样的数据内容\n\n  - 如果       sync_binlog = N       binlog_group_commit_sync_no_delay_count = M       binlog_group_commit_sync_delay = 很大值这种情况 fsync 什么时候发生\n\n    - sync_delay 和 sync_no_delay_count 的逻辑先走，因此该等还是会等。等到满足了这两个条件之一，就进入 sync_binlog 阶段。这时候如果判断 sync_binlog=0，就直接跳过，还是不调 fsync。\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/24MySQL-%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E4%B8%BB%E5%A4%87%E4%B8%80%E8%87%B4%E7%9A%84":{"title":"24｜MySQL 是怎么保证主备一致的？","content":"\n- 本章的内容是所有 MySQL 高可用方案的基础\n- 将备库设置为只读模式（readonly）\n\n  - 1. 防止误操作\n  - 2. 防止切换逻辑有 bug，比如切换过程中出现双写造成主备不一致\n  - 3. 可以用 readonly 状态判断节点的角色\n  - 4. readonly 设置对超级权限用户（super）是无效的，用于同步更新的线程拥有超级权限\n\n- 一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图。（主备同步内部流程）\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-24-1.png)\n\n\n  - 主备关系由备库指定\n  - 搭建完成后由主库决定“要发数据给备库”\n\n- 一个事务日志同步的完整过程（基于长连接）\n\n  - 1. 在备库 B 通过 change master 命令设置主库 A 的 IP、端口、用户名、密码，以及从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量\n  - 2. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n  - 3. 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n  - 4. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\n  - 5. sql_thread 读取中转日志，解析出日志里的命令，并执行。\n\n    - 后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程跟本章讲的原理没有直接关系\n\n- binlog 的三种格式对比\n\n  - statement\n\n    - 记录 SQL 原文\n\n      - unsafe 的，比如一个 delete 语句，在主库跟在备库的执行结果可能不一样\n\n        - 有些语句执行依赖上下文，比如会有 SET TIMESTAMP=时间戳 用来设置接下来的 now() 函数的返回时间\n\n    - 比如带了 limit，在主备上用到了不同的索引\n\n    - 可能导致数据不一致\n\n  - raw\n\n    - 记录变更前和变更后的数据或被删的数据，是安全的\n    - 很占空间\n\n  - mixed = statement + row\n\n    - MySQL 自己判断执行的语句应该使用哪种格式的日志\n    - 用得不多\n\n  - 建议设置为 row\n\n- 查看 binlog\n\n  - 首先通过 show variables like 'log_%' 查看 log_bin 参数是否为 ON\n  - mysql\u003e show binary logs; #获取binlog文件列表\n  - mysql\u003e show binlog events; #只查看第一个binlog文件的内容\n  - mysql\u003e show binlog events in 'mysql-bin.000001';#查看指定binlog文件的内容\n  - mysql\u003e show master status； #查看当前正在写入的binlog文件\n  - 需要借助 mysqlbinlog 工具，用下面这个命令解析和查看 binlog 中的内容\n\n    - 比如事务的 binlog 是从 8900 这个位置开始的，所以可以用 start-position 参数来指定从这个位置的日志开始解析mysqlbinlog -vv data/master.000001 --start-position=8900;\n\n- 越来越多的场景要求把格式设置为 row，最直接的好处是可以恢复数据\n\n  - delete 语句\n\n    - 记录了被删的数据\n\n  - insert 语句\n\n    - 把语句转成 delete 执行即可\n\n  - update 语句\n\n    - binlog 记录了修改前和修改后的整行数据\n    - 对调两行信息再到数据库里面执行即可\n\n  - MariaDB 的 [Flashback](https://mariadb.com/kb/en/flashback/) 工具就是基于上面的原理回滚数据\n\n    - 前提：binlog_format=rowbinlog_row_image=FULL\n\n  - 标准做法\n\n    - 1. 用 mysqlbinlog 工具解析出来\n    - 2. 把解析结果整个发给 MySQL 执行\n    - 类似于：将 master.000001 文件里面从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行。mysqlbinlog master.000001 --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;\n\n- 循环复制问题\n\n  - 实际生产上使用比较多的是双 M 结构（互为主备）\n\n    - 相比于主从，在切换时不用修改主备关系\n\n  - 业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n  - 解决（在某些场景下还是有可能出现死循环，看下一章）\n\n    - 1. 规定两个库的 server id 必须不同\n    - 2. 一个备库接到 binlog 并重放时，生成与原 binlog 的 server id 相同的新的 binlog\n    - 3. 每个库在收到从自己的主库发过来的日志后，先判断 server id\n\n- 思考题\n\n  - 什么场景下会出现死循环？\n\n  - 一种场景是，在一个主库更新事务后，用命令 set global server_id=x 修改了 server_id。等日志再传回来的时候，发现 server_id 跟自己的 server_id 不同，就只能执行了。\n  - 三个 M\n\n    - 可以通过暂时修改 server id 解决\n    - 但出现循环复制时应该考虑是不是数据本身已经失去可靠性\n\n  - 怎么解决？\n\n- 评论区\n\n  - binlog 准备写到 binlog file 时都会先判断写入后是否超过设置的 max_binlog_size 值如果超过，rotate 自动生成下一个 binlog file 记录这条 binlog 信息\n\n    - 一个事务的 binlog 日志不会被拆到两个 binlog 文件，所以会等到日志写完才 rotate，所以可以看到超过配置大小上限的 binlog 文件\n\n  - 如果一张表并没有主键，插入的一条数据和这张表原有的一条数据所有字段都是一样的，然后对插入的这条数据做恢复，会不会把原有的那条数据删除？\n\n    - 会删除一条，有可能删除到之前的那条\n    - 因为表没有主键的时候，binlog 里面就不会记录主键字段即，binlog 不会记录 InnoDB 隐藏的主键 id 字段\n\n  - 如果“redo 没有及时刷盘，binlog 刷盘了”之后瞬间数据库所在主机掉电，主机重启，MySQL 重启以后，这个事务会丢失；会引起日志和数据不一致，这也是要默认设置双 1 的原因之一\n  - 主库 ssd，备库机械硬盘，此时可以试试备库非双 1\n  - 联表一般在业务层面进行\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/25MySQL-%E6%98%AF%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84":{"title":"25｜MySQL 是怎么保证高可用的？","content":"\n- 正常情况下，只要主库执行更新生成的所有 binlog，都可以传到备库并被正确地执行，备库就能达到跟主库一致的状态，这就是最终一致性\n- 主动切换的场景\n\n  - 1. 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n  - 2. 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n\n    - 很快\n\n  - 3. 备库 B 执行完成这个事务，我们把这个时刻记为 T3\n\n- 主备延迟\n\n  - T3 - T1\n  - 在备库执行 show slave status 命令，返回结果的 seconds_behind_master 表示当前备库延迟了多少秒\n\n    - 1. 每个事务的 binlog 都有一个记录主库上写入的时间的时间字段\n\n      - 计算完之后手动修改备库时间，不会自动修正\n\n    - 2. 备库取出当前正在执行的事务的时间字段的值，计算与当前系统时间的差值\n\n  - 备库在连接到主库的时候会通过 SELECT UNIX_TIMASTAMP() 函数获得当前主库的系统时间\n\n    - 如果主库时间跟自己时间不一样，会在计算时自动扣掉这个差值\n\n  - 来源\n\n    - 备库比主库所在的机器性能差\n\n    - 这种情况可以设置备库非双 1\n\n    - 备库压力大\n\n    - 比如一些不适合在主库跑的大查询放在了备库上，此时压力来到备库\n    - 可以多接几个从库分担压力\n    - 通过 binlog 输出到外部系统，比如 Hadoop 或 es，让外部系统提供统计类查询的能力\n\n      - 工具可以了解下 canal\n\n  - 大事务\n\n    - 如果一个语句在主库执行了 10 分钟，那在备库上也要执行很久\n\n      - 不要一次性修改、删除太多数据\n\n    - 大表 DDL\n\n      - 计划内的 DDL 建议用 gh-ost 方案（看第 13 篇）\n\n  - 备库的并行复制能力（在下一篇）\n\n- 从库和备库概念上差不多，把会在 HA 过程中被选成新主库的称为备库\n- 主备切换：\n- 可靠性优先策略\n\n  - 1. 判断备库 B 现在的 seconds_behind_master，持续重试，如果小于某个值才进入下一步\n  - 2. 把主库 A 改成只读状态\n  - 3. 判断备库 B 的 seconds_behind_master 的值是否为 0，持续重试\n  - 4. 把备库 B 改成可读写状态\n  - 5. 把业务请求切到备库 B\n  - 一般由专门的 HA 系统完成此流程\n\n- 可用性优先策略\n\n- 把 4、5 调整到最开始执行\n- 可能会出现数据不一致\n- 适用场景之一\n\n  - 一个专门负责操作日志的库，数据不一致可以通过 binlog 修补，短暂的不一致也不会引发业务问题同时，业务系统依赖于这个日志写入逻辑，如果这个库不可写，会导致线上的业务操作无法执行\n\n- 思考题\n\n  - 什么原因导致的？\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-25-1.png)\n\n\n    - 一种是大事务（包括大表 DDL、一个事务操作很多行）；\n    - 还有一种情况比较隐蔽，就是备库起了一个长事务，比如begin; select * from t limit 1;然后就不动了\n\n  - 怎么确认？\n\n    - 看一下备库当前执行的命令\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/26%E5%A4%87%E5%BA%93%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E5%BB%B6%E8%BF%9F%E5%A5%BD%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%97%B6":{"title":"26｜备库为什么会延迟好几个小时？","content":"\n- 多线程复制机制 = 将单线程 sql_thread 拆成多个线程\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-26-2.png)\n\n\n  - coordinator 就是原来的 sql_thread，但不再更新数据，只负责读取中转日志和分发事务真正更新日志的变成 worker 线程，个数由参数 slave_parallel_workers 决定一般设置 8～16 之间最好（32 核物理机的情况）需要留资源给读查询\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-26-1.png)\n\n  - 分发时的基本要求\n\n    - 1. 不会造成更新覆盖。这就要求更新同一行的两个事务必须分发到同一个 worker 中\n    - 2. 同一个事务不能被拆开\n\n- 为了解决备库一直追不上更新压力较大的主库的问题\n- MySQL 5.5 版本的并行复制策略\n\n  - 官方 5.5 版本不支持并行复制\n\n    - 下面两个策略没有被合并\n\n  - 按表分发策略\n\n    - 如果两个事务更新不同的表，就可以并行， 如果有跨表的事务就需要把两张表放在一起考虑\n    - 按表并行复制线程模型\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-26-3.png)\n\n\n    - 每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。\n    - 假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。此时事务 T 的分配规则：1. 由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。2. 按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。3. 事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。4. 每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。5. 这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。6. coordinator 继续读下一个中转日志，继续分配事务。\n    - 每个事务在分发的时候，跟所有 worker 的冲突关系包括三种情况：\n\n      - 1. 如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;\n      - 2. 如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；\n      - 3. 如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n\n  - 按行分发策略\n\n    - 如果两个事务没有更新相同的行，它们在备库上可以并发执行\n    - 需要同时考虑主键和唯一键\n    - 执行 update t1 set a=1 where id=2 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:1. key=hash_func(db1+t1+“PRIMARY”+2), value=2; 这里 value=2 是因为修改前后的行 id 值不变，出现了两次。2. key=hash_func(db1+t1+“a”+2), value=1，表示会影响到这个表 a=2 的行。3. key=hash_func(db1+t1+“a”+1), value=1，表示会影响到这个表 a=1 的行。\n    - 消耗更多的计算资源\n\n  - 两个方案有一些约束条件\n\n    - 1. 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；\n    - 2. 表必须有主键；\n    - 3. 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n\n  - 按行策略遇到一个语句要删除 100 万行数据类似的情况时，hash 表要记录 100 万个项，耗内存解析 binlog 计算 hash 值，对于大事务，成本很高\n\n    - 设置阈值，单个事务如果超过设置的行数阈值，就暂时退化为单线程模式1. coordinator 暂时先 hold 住这个事务；2. 等待所有 worker 都执行完成，变成空队列；3. coordinator 直接执行这个事务；4. 恢复并行模式。\n\n- MySQL 5.6 版本的并行复制策略\n\n  - 按库并行\n  - hash 表的 key = 数据库名\n  - 不要求 binlog 的格式\n\n- MariaDB 的并行复制策略\n\n  - 利用了 redo log 组提交优化（group commit）的特性\n\n    - 1. 能够在同一组里提交的事务，一定不会修改同一行；\n    - 2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n  - 实现\n\n    - 1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；\n    - 2. commit_id 直接写到 binlog 里面；\n    - 3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；\n    - 4. 这一组全部执行完成后，coordinator 再去取下一批。\n\n  - 之前的思路：分析 binlog，并拆分到 worker 上MariaDB 的策略：模拟主库的并行模式\n  - 但是没有实现“真正的模拟主库并发度”目标主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的\n\n- MySQL 5.7 的并行复制策略\n\n  - 由参数 slave-parallel-type 控制并行复制策略\n\n    - 1. 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n    - 2. 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。\n\n      - 同时处于“执行状态”的所有事务不可以并行因为可能由由于锁冲突而处于锁等待状态的事务\n      - 这里的思想是：1. 同时处于 prepare 状态的事务，在备库执行时是可以并行的；2. 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n      - 备库如何知道事务的二阶段提交状态（依赖 redo log，备库接收到的是 binlog）\n\n        - 主库在写 binlog 的时候会给这些 binlog 里面记 commit_id 和sequence_no，来说明事务之间在主库上并行 prepare 的状态；备库是通过解析 binlog 拿到 commit_id 和 sequence_no，来决定要怎么并发的。\n\n  - binlog 的组提交相关参数\n\n    - 1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync；\n    - 2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n    - 用于故意拉长 binlog 从 write 到 fsync 的时间，减少 binlog 的写盘次数同时可以用来制造更多的“同时处于 prepare 阶段的事务”，增加备库复制的并行度\n\n- MySQL 5.7.22 的并行复制策略\n\n  - MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n  - 相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n\n    - 1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\n    - 2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\n    - 3. WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n      - 基本用不到\n\n  - 2、3 的 hash 值 = 库名 + 表名 + 索引名 + 值，如果表上除了主键索引外，还有其他唯一索引，对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值\n  - 跟 MySQL 5.5 版本的按行分发策略差不多，但有优势\n\n    - 1. writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；\n    - 2. 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；\n    - 3. 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。\n\n  - 对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。\n\n- 5.7 版本新增的备库并行策略修改了 binlog 的内容，说明 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要考虑这个因素\n- 思考题\n\n  - 假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。\n  - 这时候，你为了更快地让备库追上主库，要开并行复制。在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？\n\n    - WRITESET\n\n  - 你选择的原因是什么？\n  - 如果设置另外两个参数，你认为会出现什么现象呢？\n\n    - COMMIT_ORDER 的话，由于主库是单线程压力模式，所以每个事务的 commit_id 都不同\n    - 由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。\n\n- 评论区\n\n  - 存在主从的 binlog event 写入顺序不一致的情况\n  - 对同一行的修改会因为行锁而不能同时进入 commit 状态，所以 commit_id 不会相同\n  - 每个事务都有两个数字表示它在执行提交阶段的时间范围，构成区间 (c1, c2)。如果两个事务的区间有交集，就是可以并行的。这里 c1 是事务启动的时候，当前系统里最大的 commit_id；一个事务提交的时候，commit_id + 1.\n\n    - 进入 prepare 的时候就给这个事务分配 commitid，这个 commitid 就是当前系统最大的一个 commitid\n\n  - 作者回复: 我也建议尽量少使用外键，我自己理解的几个原因吧1. 这个关系应该维护在开发系统的逻辑中，放在数据库里面，比较隐蔽，容易忘记2. 外键约束可能会导致有些更新失败3. 外键约束（尤其是级联更新）容易出现非预期的结果\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/27%E4%B8%BB%E5%BA%93%E5%87%BA%E9%97%AE%E9%A2%98%E4%BA%86%E4%BB%8E%E5%BA%93%E6%80%8E%E4%B9%88%E5%8A%9E":{"title":"27｜主库出问题了，从库怎么办？","content":"\n- 基于位点的主备切换\n\n  - change master 命令：CHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password MASTER_LOG_FILE=$master_log_name MASTER_LOG_POS=$master_log_pos  \n  - 最后两个参数就是位点参数：从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步\n  - 其中一种取同步位点的方法\n\n    - 1. 等待新主库把中转日志全部同步完成；\n    - 2. 在新主库上执行 show master status 命令，得到当前最新的 File 和 Position；\n    - 3. 取原主库故障的时刻 T；\n    - 4. 用 mysqlbinlog 工具解析新主库的 File，得到 T 时刻的位点。mysqlbinlog File --stop-datetime=T --start-datetime=T\n\n  - 得到的位置不准确：比如旧主库执行完成一个 insert 语句插入数据，并且将 binlog 传给了要成为新主库的实例和从库，传完后掉电。此时，从库执行 binlog 后有了新数据，新主库可能又再次把 binlog 传过来，会报主键重复错误。\n\n    - 两种解决方法\n    - 1. 主动跳过一个事务：set global sql_slave_skip_counter=1;start slave;\n\n      - 此方法需要在从库刚开始连接到新主库的时候持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能设计的所有事务。\n\n    - 2. 通过设置 slave_skip_error 参数，直接设置跳过指定的错误。在执行主备切换时，经常会遇到：a. 1062 错误，插入数据时唯一键冲突；b. 1032 错误，删除数据时找不到行。\n\n- GTID（Global Transaction Identifier，全局事务 ID）\n\n  - MySQL 5.6 版本引入\n\n    - 因为前面的方法复杂且容易出错\n\n  - 一个事务在提交的时候生成的，格式：GTID=server_uuid:gno\n\n    - server_uuid：实例第一次启动时自动生成，全局唯一\n    - gno：整数，初始值 1，每次提交事务的时候分配给这个事务，并加 1\n\n  - 官方文档的 GTID 格式定义容易造成误解：GTID=source_id:transaction_idqi d\n\n    - source_id：server_uuid\n    - transaction_id：实际是 gno\n    - 在 MySQL 里 transaction_id 就是指事务 id，事务 id 是在事务执行过程中分配的，如果这个事务回滚了，事务 id 也会递增，不连续递增。而 gno 是在事务提交的时候才会分配，连续递增。\n\n  - 启动 GTID 模式：启动 MySQL 实例时加上参数 gtid_mode=on 和 enforce_gtid_consistency=on\n  - 每个事务跟一个 GTID 一一对应，GTID 两种生成方式\n\n    - 1. 如果 gtid_next=automatic，代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。  a. 记录 binlog 的时候，先记录一行 SET   @@SESSION.GTID_NEXT=‘server_uuid:gno’;  b. 把这个 GTID 加入本实例的 GTID 集合。\n    - 2. 如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next='current_gtid’ 指定为 current_gtid，那么就有两种可能：  a. 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；  b. 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。\n\n  - 每个 MySQL 实例都维护了一个 GTID 集合，用来对应“这个实例执行过的所有事务”。\n\n- 基于 GTID 的主备切换\n\n  - change master 命令：CHANGE MASTER TO MASTER_HOST=$host_name MASTER_PORT=$port MASTER_USER=$user_name MASTER_PASSWORD=$password master_auto_position=1 \n\n    - master_auto_position=1 表示这个主备关系使用的是 GTID 协议\n\n  - 实例 B 执行 start slave 命令，取 binlog 逻辑：1. 建立连接2. 实例 B 把 set_b 发给主库3. 主库算出两个 GTID 集合的差集（所有存在于 set_a 但不存在 set_b 的 GTID 集合），判断本地是否包含差集需要的所有 binlog 事务  a 不包含，直接返回错误  b 确认全部包含，从 binlog 找出第一个不在 set_b 的事务，发给 B4. 从这个事务开始往后读文件，按顺序取 binlog 发给 B 执行\n  - 取位点的工作由主库内部自动完成\n\n- GTID 和在线 DDL\n- 思考题\n\n  - 你在 GTID 模式下设置主从关系的时候，从库执行 start slave 命令后，主库发现需要的 binlog 已经被删除掉了，导致主备创建不成功。这种情况下，你觉得可以怎么处理呢？\n\n    - 1. 如果业务允许主从不一致的情况，那么可以在主库上先执行 show global variables like ‘gtid_purged’，得到主库已经删除的 GTID 集合，假设是 gtid_purged1；然后先在从库上执行 reset master，再执行 set global gtid_purged =‘gtid_purged1’；最后执行 start slave，就会从主库现存的 binlog 开始同步。binlog 缺失的那一部分，数据在从库上就可能会有丢失，造成主从不一致。\n    - 2. 如果需要主从数据一致的话，最好还是通过重新搭建从库来做。\n    - 3. 如果有其他的从库保留有全量的 binlog 的话，可以把新的从库先接到这个保留了全量 binlog 的从库，追上日志以后，如果有需要，再接回主库。\n    - 4. 如果 binlog 有备份的情况，可以先在从库上应用缺失的 binlog，然后再执行 start slave。\n\n- 评论区\n\n  - 一主多从，即使采用半同步，也只能保证 binlog 至少在两台机器上，没有一个机制能够选出拥有最完整 binlog 的从库作为新的主库。\n\n    - 直接使用MHA工具，在配置文件里面选择 candidate_master，选择使用了半同步复制的备库就行了。[MHA 工具介绍](https://www.cnblogs.com/--smile/p/11475380.html)\n\n  - 如果在从库上执行了单独的操作，导致主库上缺少 GTID，那么可以在主库上模拟一个与从库 B 上 GTID 一样的空事务，这样主从同步就不会报错了。\n  - 在 Docker 中跑 MySQL 没有问题\n  - 慎用 reset master；等同于删数据\n  - MySQL 是怎么快速定位 binlog 里面的某一个 GTID 位置的？答案是，在 binlog 文件头部的 Previous_gtids 可以解决这个问题。\n  - sql_slave_skip_counter 跳过的是一个 event，由于 MySQL 总不能执行一半的事务，所以既然跳过了一个 event，就会跳到这个事务的末尾，因此 set global sql_slave_skip_counter=1;start slave 是可以跳过整个事务的。\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/28%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E6%9C%89%E5%93%AA%E4%BA%9B%E5%9D%91":{"title":"28｜读写分离有哪些坑？","content":"\n- 1. 客户端直连\n\n  - 查询性能稍微好点，整体架构简单，排查问题更方便\n  - 主备切换、库迁移等操作时，客户端会感知到，并且需要调整数据库连接信息\n  - 一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发\n\n- 2. 带 proxy 的架构\n\n  - 对客户端友好，连接维护、后端信息等工作都由 proxy 完成\n  - 对后端维护团队的要求更高，需要高可用，整体架构比较复杂\n\n- 过期读：在从库上会读到系统的一个过期状态\n- 强制走主库方案\n\n  - 1. 对于必须要拿到最新结果的请求，强制将其发到主库上\n  - 2. 对于可以读到旧数据的请求，才将其发到从库上\n\n- sleep 方案\n\n  - 不精确\n\n- 判断主备无延迟方案\n\n  - 三种方法\n  - 1. 每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。\n\n    - seconds_behind_master 的单位是秒，可能精度不够\n\n  - 2. 对比位点\n\n    - Master_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；Relay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。如果Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos这两组值完全相同，就表示接收到的日志已经同步完成。\n\n  - 3. 对比GTID 集合\n\n    - Auto_Position=1 ，表示这对主备关系使用了 GTID 协议。Retrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；Executed_Gtid_Set，是备库所有已经执行完成的 GTID 集合。如果这两个集合相同，也表示备库接收到的日志都已经同步完成。\n\n  - 后两种准确度更高，但还不够\n\n    - 可能还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-28-1.png)\n\n\n- 配合 semi-sync（半同步复制）\u0008 方案\n\n  - semi-sync 的设计\n\n    - 1. 事务提交的时候，主库把 binlog 发给从库；\n    - 2. 从库收到 binlog 以后，发回给主库一个 ack，表示收到了；\n    - 3。 主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。\n\n  - 如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。\n  - 存在问题\n\n    - 1. 一主多从的时候，在某些从库执行查询请求会存在过期读的现象；\n\n      - 主库只要等到一个从库的 ack，就开始给客户端返回确认\n\n    - 2. 在持续延迟的情况下，可能出现过度等待的问题。\n\n      - 如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。\n\n- 等主库位点方案\n\n  - 主备持续延迟一个事务\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-28-2.png)\n\n  - 1. trx1 事务更新完成后，客户端马上执行 show master status 得到当前主库执行到的 File 和 Position；\n  - 2. 选定一个从库执行查询语句；\n  - 3. 在从库上执行 select master_pos_wait(File, Position, 1)；\n\n    - a. 参数 file 和 pos 指的是主库上的文件名和位置；\n    - b. timeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。\n    - 这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。等于 0：代表这个 file 和 postion 已经执行过；大于 0：代表在时间内已经执行到这个 file 和 position，并且已经执行了 n 条事务。\n\n  - 4. 如果返回值是 \u003e=0 的正整数，则在这个从库执行查询语句；\n  - 5. 否则，到主库执行查询语句。\n\n- 等 GTID 方案\n\n  - \u003e= MySQL 5.7.6\n\n  - select wait_for_executed_gtid_set(gtid_set, 1);\n\n    - 1. 等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；\n    - 2. 超时返回 1。\n\n  - 1. trx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；\n\n    - 将参数 session_track_gtids 设置为 OWN_GTID，然后通过 API 接口 mysql_session_track_get_first 从返回包解析出 GTID 的值。\n\n  - 2. 选定一个从库执行查询语句；\n  - 3. 在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；\n  - 4. 如果返回值是 0，则在这个从库执行查询语句；\n  - 5. 否则，到主库执行查询语句。\n\n- 方案可以混合使用\n- 思考题\n\n  - 假设你的系统采用了我们文中介绍的最后一个方案，也就是等 GTID 的方案，现在你要对主库的一张大表做 DDL（加减索引、增加字段在最后一列），可能会出现什么情况呢？\n\n    - 假设，这条语句在主库上要执行 10 分钟，提交后传到备库就要 10 分钟（典型的大事务）。那么，在主库 DDL 之后再提交的事务的 GTID，去备库查的时候，就会等 10 分钟才出现。\n    - 这样，这个读写分离机制在这 10 分钟之内都会超时，然后走主库。\n\n  - 为了避免这种情况，你会怎么做呢？\n\n    - 这种预期内的操作，应该在业务低峰期的时候，确保主库能够支持所有业务查询。然后把读请求都切到主库，再在主库上做 DDL。等备库延迟追上以后，再把读请求切回备库。\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/29%E5%A6%82%E4%BD%95%E5%88%A4%E6%96%AD%E4%B8%80%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E4%B8%8D%E6%98%AF%E5%87%BA%E9%97%AE%E9%A2%98%E4%BA%86":{"title":"29｜如何判断一个数据库是不是出问题了？","content":"\n- select 1 判断\n\n  - select 1 这样的方法是不是已经被淘汰了呢，但实际上使用非常广泛的 MHA（Master High Availability），默认使用的就是这个方法。\n  - 只能说明这个库的进程还在，不能说明主库没问题\n  - mysqladmin ping 机制也属于同一类\n\n- 建议把 innodb_thread_concurrency 设置为 64~128 之间的值\n\n  - 达到上限时，select 1 能正常返回\n  - 控制 InnoDB 的并发线程上限。\n  - 一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。\n  - 并发连接：达到几千个影响不大，占内存而已\n  - 并发查询：CPU 杀手\n  - 在线程进入锁等待以后，并发线程的计数会减一\n\n- 查表判断\n\n  - 一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行：mysql\u003e select * from mysql.health_check; \n  - 空间满了之后，此方法失效，因为系统还是可以正常读数据的\n\n- 更新判断\n\n  - 常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。这条更新语句类似于：mysql\u003e update mysql.health_check set t_modified=now();\n\n    - 但是主备下会出现行冲突（导致主备同步停止）\n\n  - 为了让主备之间的更新不产生冲突，可以在 mysql.health_check 表上存入多行数据，并用 A、B 的 server_id 做主键。表 health_check（id，t_modified）/* 检测命令 */insert into mysql.health_check(id, t_modified) values (@@server_id, now()) on duplicate key update t_modified=now();\n  - 此方案还会又判断慢的问题\n\n    - 检测命令需要的资源少，可能系统已经负载严重，但是检测还是能在超时前正常返回\n\n- 上面的都是外部检测\n- 内部统计\n\n  - MySQL 5.6 版本以后提供的 performance_schema 库，就在 file_summary_by_event_name 表里统计了每次 IO 请求的时间。\n  - 打开所有的 performance_schema 项，性能会下降 10% 左右。\n  - 打开 redo log 的时间监控\n\n    - mysql\u003e update setup_instruments set ENABLED='YES', Timed='YES' where name like '%wait/io/file/innodb/innodb_log_file%';\n\n  - 检测方法\n\n    - 1. 假设单次 IO 请求时间超过 200 毫秒属于异常\n    - 2. /* 检测 */mysql\u003e select event_name,MAX_TIMER_WAIT FROM performance_schema.file_summary_by_event_name where event_name in ('wait/io/file/innodb/innodb_log_file','wait/io/file/sql/binlog') and MAX_TIMER_WAIT\u003e200*1000000000;\n    - 3. /* 清空之前的统计信息 */mysql\u003e truncate table performance_schema.file_summary_by_event_name;\n\n- 优先考虑 update 系统表，然后再配合增加检测 performance_schema 的信息。\n- 评论区\n\n  - 怎么之前遇到空间满了，数据库都登不上了，所有的连接都连不上，更不用执行 select 语句了\n\n    - 空间满本身是不会导致连不上的。\n    - 但是因为空间满，事务无法提交，可能会导致接下来外部事务重试，新重试的业务还是堵在提交阶段，持续累积可能会把连接数用满\n\n  - 外部检测：检测时间点的信息内部统计：取到的是一段时间内的信息\n  - DDL：一般是指加减索引、增加字段在最后一列\n  - drop 列是很麻烦的，尽量不做。业务代码直接无视这个列就好了\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/3-2-1-%E7%9A%84%E6%9C%89%E8%B6%A3%E6%83%B3%E6%B3%95":{"title":"3-2-1 的有趣想法","content":"\n内容摘抄自：\u003chttps://jamesclear.com/3-2-1\u003e\n\n## 想法\n\nIf you're searching for more time this year, start with a clean slate and choose what to add to your days rather than starting with a full schedule and trying to figure out what to eliminate.\n\n如果你今年正在寻找更多的时间，那就从一块干净的石板开始，选择在你的日子里增加什么，而不是从一个完整的时间表开始，试图找出要取消的东西。\n\nI was reviewing some old notes to myself recently and I found this one:You just need to have the courage to eliminate everything that doesn't directly feed what you really want.\n\n我最近回顾了一些给自己的旧笔记，我发现了这一条：你只需要有勇气消除那些不能直接满足你真正想要的东西的一切。\n\nWhen something fascinates you, pay attention to the details. The person who thinks, \"That was cool\" is a consumer. The person who thinks, \"How did they make something that cool?\" is on the path to being a creator.\n\n当一件事情让你着迷时，要注意细节。认为 \"这很酷 \"的人是一个消费者。而认为 \"他们是如何做出这么酷的东西的？\"的人则是在成为创造者的道路上。\n\nDon't just taste the recipe, look for the ingredients.\"\n\n不要只是品尝食谱，要寻找其中的成分\"。\n\n\"You never change things by fighting the existing reality. To change something, build a new model that makes the existing model obsolete.\"\n\n你永远不会通过对抗现有的现实来改变事情。要改变一些东西，就要建立一个新的模式，使现有的模式变得过时。\n\n\"It doesn't make sense to continue wanting something if you're not willing to do what it takes to get it.\n\n\"如果你不愿意做任何事情来得到它，那么继续想要它是没有意义的。\n\n\"There seemed to be endless obstacles preventing me from living with my eyes open, but as I gradually followed up clue after clue it seemed that the root cause of them all was fear.\"\n\n似乎有无穷无尽的障碍阻止我睁开眼睛生活，但当我逐渐追踪一条又一条的线索时，似乎所有的根源都是恐惧。\n\n\"Never be limited by other people's limited imaginations. If you adopt their attitudes, then the possibility won't exist because you'll have already shut it out… You can hear other people's wisdom, but you've got to re-evaluate the world for yourself.\"\n\n永远不要被其他人的有限想象力所限制。如果你采用他们的态度，那么这种可能性就不会存在，因为你已经把它拒之门外了……你可以听到别人的智慧，但你必须为自己重新评价这个世界。\n\n\"Before you throw more time at the problem, throw more focused action at the problem. You don’t need more time, you need fewer distractions.\"\n\n在你花更多的时间解决问题之前，先把更多的注意力集中在问题上。你不需要更多的时间，你需要更少的干扰。\n\n\"With the creative process, the key is to create a lot and edit a lot.\n\nMake more than you need, then remove everything that isn't exceptional.\"\n\n在创作过程中，关键是要大量创作，大量编辑。\n\n创作超过你的需要，然后删除一切不出众的东西。\n\n\"When you need to learn quickly, learn from others.\n\nWhen you need to learn deeply, learn from experience.\"\n\n\"当你需要快速学习的时候，向别人学习。\n\n当你需要深入学习时，就从经验中学习\"。\n\n\"It's rarely doing the work that is hard, it's starting the work. Once you begin, it’s often less painful to continue working. This is why—in the beginning—it is often more important to build the habit of getting started than it is to worry about whether or not you are doing enough.\"\n\n\"很少工作是困难的，难的是开始工作。一旦你开始工作，继续工作往往就不那么痛苦了。这就是为什么在开始时，养成开始工作的习惯往往比担心你是否做得够多更重要。\n\nEnvision where you are headed in great detail. Don't talk yourself out of it. Don't encourage yourself to be realistic. You will have to wrestle with reality soon enough. Don't be your own bottleneck at this stage.\n\n详细地设想你要去的地方。不要劝说自己放弃。不要鼓励自己要现实一点。你将不得不很快与现实搏斗。在这个阶段，不要成为你自己的瓶颈。\n\n\"It's easier to ask forgiveness than it is to get permission.\"\n\n请求宽恕比获得许可更容易。\n\n\"Everything is a lesson. Learn enough lessons and the failures become useful.\"\n\n每件事都是一个教训。学到足够的教训，失败就会变得有用。\n\nGreek philosopher **Epicurus** on desire and contentment:\n\n\"Do not spoil what you have by desiring what you have not; remember that what you now have was once among the things you only hoped for.\"\n\n不要因为渴望你没有的东西而破坏你所拥有的东西；记住你现在所拥有的东西曾经是你只希望得到的东西之一。\n\n\"A phrase I heard recently and found useful: I agree with the idea, but I disagree with the tone.\n\nMany ideas get dismissed because they are delivered in a cocky or hostile or dismissive tone—or because of who delivers them.\n\nSeparate substance from style.\"\n\n我最近听到的一句话，发现很有用：我同意这个想法，但我不同意这个语气。\n\n许多想法被驳回是因为它们是以傲慢、敌意或轻蔑的语气提出的--或者是因为谁提出的。\n\n把内容和风格分开。\n\nScientist and systems engineer, **Donella Meadows**, on intellectual humility and learning from others:\n\n\"Remember, always, that everything you know, and everything everyone knows, is only a model. Get your model out there where it can be viewed. Invite others to challenge your assumptions and add their own.\"\n\n“永远记住，你所知道的一切，以及每个人所知道的一切，都只是一个模型。把你的模型放在可以看到的地方。邀请其他人挑战你的假设并添加他们自己的假设。”\n\nIs what I'm about to do today connected to what I'm going to value over the long-term?\n\n我今天要做的事与我要长期重视的事有关吗？\n\n\"Whoever has the most fun, wins.\"\n\n“谁玩得最开心，谁就是赢家。”\n\n\"If you need 10 of something, make 30. Then pick the best.\"\n\n“如果你需要 10 个东西，就做 30 个。然后挑选最好的。”\n\n\"Many people won't attempt something unless they can find an example of someone else who is already doing it. Rely on this type of thinking too much and you'll never do anything interesting.\n\n“许多人不会尝试某事，除非他们能找到其他人已经在做的例子。过分依赖这种思维方式，你永远不会做任何有趣的事情。\n\nYour path through life is unique. It is important to extract lessons from the experiences of others, but you can't wait for a perfect example to take action. You are the example.\"\n\n你的人生道路是独一无二的。从别人的经验中吸取教训很重要，但你不能等到一个完美的例子才采取行动。你就是榜样。”\n\n## 思考\n\nImagine all your responsibilities and obligations vanish overnight.\n\nWhat would you miss doing? What would you choose to add back to your life?\n\n想象一下，你所有的责任和义务一夜之间消失了。\n\n你会怀念做什么？你会选择在你的生活中增加什么？\n\nWhat can I do today to improve by 1%?\n\n我今天能做什么来提高 1%？\n\nWhere do I want to be in 10 years? What can I do in the next 5 minutes to contribute to that outcome?\n\n10年后我想在哪里？在接下来的5分钟内，我可以做什么来促进这一结果？\"\n\nIf you could spend 30 minutes today creating whatever you want, what would you create?\n\n如果你今天可以花30分钟创造你想要的东西，你会创造什么？\n\nHow would my daily schedule change if I did a little more of what I'm great at and a little less of what I'm not great at?\n\n如果我多做一点我擅长的事，少做一点我不擅长的事，我的日常安排会有什么变化？\n\nIs it better to delay getting started by weeks or months so I can be fully prepared? Or is it better to start right now with little to no preparation?\n\n是推迟几周或几个月开始，以便我能够做好充分准备？还是在几乎没有准备的情况下现在就开始比较好？\n\nWhere am I spending energy trying to please someone who actually doesn't care?\n\n我在哪里花精力去讨好一个实际上并不关心的人呢？\n\nThis thing that I am unhappy about… is it actually hard to change or is it simply hard to have the courage to change it?\n\n我不高兴的这件事……究竟是很难改变，还是只是很难有勇气去改变？\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/30%E7%AD%94%E7%96%91%E6%96%87%E7%AB%A0%E4%BA%8C%E7%94%A8%E5%8A%A8%E6%80%81%E7%9A%84%E8%A7%82%E7%82%B9%E7%9C%8B%E5%8A%A0%E9%94%81":{"title":"30｜答疑文章（二）：用动态的观点看加锁","content":"\n- CREATE TABLE `t` (  `id` int(11) NOT NULL,  `c` int(11) DEFAULT NULL,  `d` int(11) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `c` (`c`)) ENGINE=InnoDB;insert into t values(0,0,0),(5,5,5),(10,10,10),(15,15,15),(20,20,20),(25,25,25);\n- 不等号条件里的等值查询\n\n- 通过树搜索的方式定位记录的时候，用的是“等值查询”的方法\n\n- show engine innodb status 命令输出的信息中国呢，LATESTADETECTED DEADLOCK 记录了最后一次死锁信息\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-30-1.png)\n\n\n  - 1. 由于锁是一个个加的，要避免死锁，对同一组资源，要按照尽量相同的顺序访问；\n  1. 在发生死锁的时刻，for update 这条语句占有的资源更多，回滚成本更大，所以 InnoDB 选择了回滚成本更小的 lock in share mode 语句，来回滚。\n\n- 所谓“间隙”，其实根本就是由“这个间隙右边的那个记录”定义的。\n- 思考题\n\n  - 空表的间隙的定义\n\n    - 一个空表只有一个间隙比如执行：begin; select * from t where id\u003e1 for update;加锁范围：next_key lock (-∞, supremum]\n\n- 评论区\n\n  - 删除数据，导致锁扩大的描述：“因此，我们就知道了，由于 delete 操作把 id=10 这一行删掉了，原来的两个间隙 (5,10)、(10,15）变成了一个 (5,15)。”我觉得这个提到的(5, 10) 和 (10, 15)两个间隙会让人有点误解，实际上在删除之前间隙锁只有一个(10, 15)，删除了数据之后，导致间隙锁左侧扩张成了5，间隙锁成为了(5, 15)。\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/31%E8%AF%AF%E5%88%A0%E6%95%B0%E6%8D%AE%E5%90%8E%E9%99%A4%E4%BA%86%E8%B7%91%E8%B7%AF%E8%BF%98%E8%83%BD%E6%80%8E%E4%B9%88%E5%8A%9E":{"title":"31｜误删数据后除了跑路，还能怎么办？","content":"\n- 1. 使用 delete 语句误删数据行；\n- 2. 使用 drop table 或者 truncate table 语句误删数据表；\n- 3. 使用 drop database 语句误删数据库；\n- 4. 使用 rm 命令误删整个 MySQL 实例。\n- 误删行\n\n  - 恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。\n  - 预防\n\n    - 1. 把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。\n    - 2. 代码上线前，必须经过 SQL 审计。\n\n  - delete 全表很慢，应该优先考虑使用 truncate table 或者 drop table 命令\n\n- 误删库 / 表\n\n  - 即使配置了 binlog_format=row，记录的还是 statement 格式，binlog 只有一个 truncate/drop 语句，不足以恢复数据\n  - 恢复方法：使用全量备份 + 增量日志的方式\n  - 1. 加速数据恢复：使用 mysqlbinlog 命令时加上 -database 参数指定误删表所在的库\n  - 2. 应用日志时跳过误操作的语句的 binlog\n\n    - 1. 如果原实例没有使用 GTID 模式，只能在应用到包含错误语句的 binlog 文件时，先用 -stop-position 参数执行到误操作之前的日志，再用 -start-position 从误操作之后的日志继续执行\n    - 2. 如果实例使用了 GTID 模式，假设误操作命令的 GTID 时 gtid1，执行 set gtid_next=gtid1; begin; commit; 把这个 GTID 加到临时实例的 GTID 集合，之后顺序执行 binlog 的时候会自动跳过误操作的语句\n\n  - 上述使用 mysqlbinlog 方法恢复数据不够快\n\n    - 1. mysqlbinlog 不能指定只解析一个表的日志\n    - 2. 单线程\n\n  - 加速方法之一：在用备份恢复出临时实例之后，把实例设置成线上备库的从库\n\n    - 1. 在 start slave 之前，先通过执行change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表；\n    - 2. 这样做也可以用上并行复制技术，来加速整个数据恢复过程。\n    - 如果备库上没有日志的话，从备份中下载恢复\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-31-1.png)\n\n\n  - 建议把上述恢复功能做成自动化工具，并且经常拿出来演练\n\n- 延迟复制备库\n\n  - MySQL 5.6 引入\n  - 延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。\n  - 备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。\n  - 随时可以得到一个，只需要最多再追 n 秒，就可以恢复出数据的临时实例，也就缩短了整个数据恢复需要的时间。\n\n- 预防误删库 / 表的方法\n\n  - 第一条建议是，账号分离。这样做的目的是，避免写错命令。\n  - 第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。\n\n    - 1. 在删除表之前，必须先对表做改名操作，然后观察一段时间。\n    - 2. 改表名时，要求给表名加固定的后缀（比如 _to_be_deleted），删除表的动作必须通过管理系统执行，并且只能删除固定后缀的表\n\n- rm 删除数据\n\n  - 重做即可\n\n- 思考题\n\n  - 误删数据事件\n\n    - 登错环境\n\n- 评论区\n\n  - 不同的浏览器浏览文件可能会截断或乱码\n\n    - 可以把脚本放到 git 上，然后把 git 地址和文件的 md5 发给要执行的人\n\n  - 修改生产的数据，或者添加索引优化，都要先写好四个脚本：备份脚本、执行脚本、验证脚本、回滚脚本\n  - 通过 chatrr +i 命令给所有重要的文件增加了 i 权限属性，这样哪怕 root 用户都无法直接删除文件。\n- rename 很快\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/32%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E6%9C%89-kill-%E4%B8%8D%E6%8E%89%E7%9A%84%E8%AF%AD%E5%8F%A5":{"title":"32｜为什么还有 kill 不掉的语句？","content":"\n- 两个 kill 命令\n\n  - 1. kill query + 线程 id\n\n    - 终止这个线程中正在执行的语句\n\n  - 2. kill connection + 线程 id\n\n    - connection 可以不写\n    - 断开这个线程的连接\n    - 会先停止正在执行的语句\n\n- 使用了 kill 命令，却没能断开这个连接。再执行 show processlist 命令，看到这条语句的 Command 列显示的是 Killed。\n- 收到 kill 以后，线程做什么？\n\n  - 告诉执行线程：这条语句已经不需要继续执行了，可以开始“执行停止的逻辑了”\n\n    - 跟 Linux 的 kill 命令类似，kill -N pid 并不是让进程直接停止，而是给进程发一个信号，然后进程处理这个信号，进入终止逻辑。只是对于 MySQL 的 kill 命令来说，不需要传信号量参数，就只有“停止”这个命令。\n\n  - 实现上，当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：\n\n    - 1. 把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；\n\n      - 如果 session B 处于锁等待，并不能知道状态变化，还是会继续等待。\n\n    - 2. 给 session B 的执行线程发一个信号。\n\n      - 发信号的目的：让 session B 退出等待，处理 1 设置的状态\n\n- kill 无效的两类情况\n\n  - 1. 线程没有执行到判断线程状态的逻辑\n\n    - 相同的还有由于 IO 压力过大，读写 IO 的函数一直无法返回，导致不能及时判断线程的状态\n    - 语句执行到能判断到线程状态已经变成了 KILL_QUERY 或者 KILL_CONNECTION 的时候，再进入终止逻辑阶段。\n    - 如果一个线程的状态是KILL_CONNECTION，就把Command列显示成Killed。\n\n  - 2. 终止逻辑耗时较长\n\n    - 1. 超大事务执行期间被 kill，触发回滚操作\n    - 2. 大查询回滚，查询过程生成了比较大的临时文件 + 此时文件系统压力大 =\u003e 删除临时文件可能需要等待 IO 资源\n    - 3. DDL 命令执行到最后阶段，被 kill 需要删除中间过程的临时文件，同 2\n\n- 执行 Ctrl+C 的时候，是 MySQL 客户端另外启动一个连接发送一个 kill query 命令\n- 另外两个关于客户端的误解\n\n  - 如果库里面的表特别多，连接就会很慢。\n\n    - 每个客户端在和服务端建立连接的时候，需要做的事情就是 TCP 握手、用户校验、获取权限。但这几个操作，显然跟库里面表的个数无关。（第一章）\n    - 我们感知到的连接过程慢，其实并不是连接慢，也不是服务端慢，而是客户端慢。\n\n      - 客户端在连接成功后：1. 执行 show databases2. 切到 db1 库，执行 show tables3. 把这两个命令的结果用于构建一个本地的哈希表（最耗时）\n      - 如果在连接命令中加上 -A，就可以关掉这个自动补全的功能，然后客户端就可以快速返回了。\n      - –quick 也可以跳过\n\n  - –quick\n\n    - 是让客户端变快\n    - MySQL 客户端发送请求后，接收服务端返回结果的方式有两种：1. 一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果你用 API 开发，对应的就是 mysql_store_result 方法。2. 另一种是不缓存，读一个处理一个。如果你用 API 开发，对应的就是 mysql_use_result 方法。\n\n      - 默认第一种\n\n        - 查询的返回结果不会很多的话，都推荐用这个\n\n      - 加上 -quick 参数后使用第二种\n\n    - 采用不缓存的方式，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢\n    - 参数效果\n\n      - 1. 跳过表名自动补全功能\n      - 2. mysql_store_result 需要申请本地内存来缓存查询结果，如果查询结果太大，会耗费较多的本地内存\n      - 3. 不会把执行命令记录到本地的命令历史文件\n\n- 发现一个线程处于 Killed 状态，可以做的事情：通过影响系统环境，让 Killed 状态尽快结束\n\n  - 1. 并发度问题，临时调大 innodb_thread_concurrency 的值或停掉别的线程，让出位子给这个线程执行\n  - 2. 回滚逻辑由于 IO 资源限制，通过减少系统压力让它加速\n\n- 思考题\n\n  - 如果你碰到一个被 killed 的事务一直处于回滚状态，你认为是应该直接把 MySQL 进程强行重启，还是应该让它自己执行完成呢？\n\n    - 让它自己结束\n\n  - 为什么呢？\n\n    - 因为重启之后该做的回滚动作不能少\n    - 可以先做主备切换，切到新主库提供服务\n\n  - 减少系统压力，加速终止逻辑\n\n- 评论区\n\n  - 并非所有的 DDL 操作都可以通过主从切换来实现\n\n    - 只有 改索引、 加最后一列、删最后一列其他的大多数不行，比如删除中间一列\n\n  - kill 的影响只有回滚，恢复到执行前的状态，没有其他的\n  - 遇到错误时：pstack \u003cpid of mysqld\u003e \u003e /tmp/pstack.1\n","lastmodified":"2023-05-20T15:01:12.440019958Z","tags":null},"/33%E6%88%91%E6%9F%A5%E8%BF%99%E4%B9%88%E5%A4%9A%E6%95%B0%E6%8D%AE%E4%BC%9A%E4%B8%8D%E4%BC%9A%E6%8A%8A%E6%95%B0%E6%8D%AE%E5%BA%93%E5%86%85%E5%AD%98%E6%89%93%E7%88%86":{"title":"33｜我查这么多数据，会不会把数据库内存打爆？","content":"\n- 全表扫描对 server 层的影响\n\n  - 服务端并不需要保存一个完整的结果集，取数据和发数据的流程（边读边发）：\n\n    - 1. 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。2. 重复获取行，直到 net_buffer 写满，调用网络接口发出去。（发给 socket send buffer）3. 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。4. 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-33-1.png)\n\n\n  - show processlist 结果看到 State 一直处于“Sending to client”，表示服务器端的网络栈写满了（上一节讲到的 -quick 参数就可能导致这种情况）\n\n    - 可以考虑将 net_buffer_length 参数设置为更大的值\n    - 等待客户端接收结果\n\n  - “Sending data”状态\n\n    - 一个查询语句的状态变化（这里略去了其他无关的状态）：\n\n      - MySQL 查询语句进入执行阶段后，首先把状态设置成“Sending data”；然后，发送执行结果的列相关的信息（meta data) 给客户端；再继续执行语句的流程；执行完成后，把状态设置成空字符串。\n\n    - 不一定是指正在发送数据，而可能是处于执行器过程中的任意阶段\n\n- 全表扫描对 InnoDB 的影响\n\n  - 内存的数据页是在 Buffer Pool (BP) 中管理的，在 WAL 里 Buffer Pool 起到了加速更新的作用。而实际上，Buffer Pool 还有一个更重要的作用，就是加速查询。\n\n    - 由于有 WAL 机制，当事务提交的时候，磁盘上的数据页是旧的，此时如果有一个查询要读这个数据页，并不需要把 redo log 应用到数据页。因为这时候内存数据页的结果是最新的， 直接读内存页就可以了\n\n  - Buffer Pool 对查询的加速效果依赖于一个重要的指标：内存命中率\n\n    - show engine innodb status 结果查看，一般情况下，一个稳定服务的线上系统，要保证响应时间符合要求的话，内存命中率要在 99% 以上。\n    - Buffer pool hit rate 表示命中率\n    - InnoDB Buffer Pool 的大小是由参数 innodb_buffer_pool_size 确定的，一般建议设置成可用物理内存的 60%~80%。\n\n  - InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。\n\n    - 用链表实现\n    - 没有改进前：遇到全表扫描时内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢\n    - 改进的 LRU 算法\n      - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-33-2.png)\n\n\n      - 靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。\n      - 1. 状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。\n      - 2. 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。\n      - 3. 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：  a. 若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；  b. 如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。\n\n- 思考题\n\n  - 如果由于客户端压力太大，迟迟不能接收结果，会导致 MySQL 无法发送结果而影响语句执行。但，这还不是最糟糕的情况。\n  - 你可以设想出由于客户端的性能问题，对数据库影响更严重的例子吗？或者你是否经历过这样的场景？你又是怎么优化的？\n\n    - 造成长事务\n    - 如果前面的语句有更新，意味着它们在占用着行锁，会导致别的语句更新被锁住；\n    - 读的事务会导致 undo log 不能被回收，导致回滚段空间膨胀\n\n- 评论区\n\n  - 大查询常见的做法：分批取，然后每一批拿到最大的一个 id（主键值），下一批查询的时候用 where id \u003e N 这种写法\n  - 一个大查询不会打爆，但是很多并发查询还是可能打爆的\n  - MyISAM 引擎也不会爆内存，跟 InnoDB 一样\n  - 更新之间会互相等锁的问题。同一个事务，更新之后要尽快提交，不要做没必要的查询，尤其是不要执行需要返回大量数据的查询。\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/34%E5%88%B0%E5%BA%95%E5%8F%AF%E4%B8%8D%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8-join":{"title":"34｜到底可不可以使用 join ？","content":"\n- Index Nested-Loop Join（NLJ）\n\n  - 1. 使用 join 语句，性能比强行拆成多个但表执行 SQL 语句的性能要好；\n  - 2. 如果使用 join 语句的话，需要让小表做驱动表\n  - 前提是“可以使用被驱动表的索引”\n\n- Simple Nested-Loop Join\n\n  - MySQL 没用\n\n- Block Nested-Loop Join（BNL）\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-34-1.png)\n\n\n  - 1. 被驱动表没有索引\n  - 2. 驱动表中取出所有满足条件的数据，读入线程内存 join_buffer 中\n\n    - 如果 join_buffer 满了，进入下一步，比较完放入结果集后，清空 join_buffer，回到这一步\n    - join_buffer_size 设置 join_buffer 的大小\n\n  - 3. 扫描被驱动表，把每一行拿出来跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回\n\n    - 跟 Simple xx join 一样的扫描行数\n    - 不同的是一个是每一行都在驱动表全表扫描作比较，一个在内存比较\n\n  - 不用分段时，选哪个表做驱动表都一样\n\n    - 1. 两个表都做一次全表扫描 M+N\n    - 2. 内存中的判断次数 M*N\n\n  - 分段时，选择小表做驱动表\n\n    - 驱动表 N 行，被驱动表 M 行\n    - N 越大，分段次数越多，M 被扫的次数越多\n    - 调大 join_buffer_size 可以加快没用到被驱动表索引的 join 语句\n\n- 能不能用 join 语句？\n\n  - 如果可以使用 Index Nested-Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的；\n  - 判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样，有就不用\n\n- 选择大表还是小表做驱动表\n\n  - 总是应该用小表\n  - 小表：在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。\n\n- 思考题\n\n  - 如果被驱动表是一个大表，并且是一个冷数据表，除了查询过程中可能会导致 IO 压力大以外，你觉得对这个 MySQL 服务还有什么更严重的影响吗？（这个问题需要结合上一篇文章的知识点）\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/35join-%E8%AF%AD%E5%8F%A5%E6%80%8E%E4%B9%88%E4%BC%98%E5%8C%96":{"title":"35｜join 语句怎么优化？","content":"\n- Multi-Range Read 优化（MRR）\n\n  - 目的：尽量使用顺序读盘\n  - 因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n\n    - MRR 的设计思路\n\n  - 优化后的执行流程\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-35-1.png)\n\n\n    - 1. 根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;\n\n      - read_rnd_buffer：MySQL 的随机读缓冲区。当按任意顺序读取行时（例如按照排序顺序）将分配一个随机读取缓冲区，进行排序查询时，MySQL 会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度。\n\n    - 2. 将 read_rnd_buffer 中的 id 进行递增排序；\n    - 3. 排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。\n    - read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。\n\n  - 想要稳定地使用 MRR 优化的话，需要设置set optimizer_switch=\"mrr_cost_based=off\"。\n\n    - 官方文档的说法，是现在的优化器策略，判断消耗的时候，会更倾向于不使用 MRR，把 mrr_cost_based 设置为 off，就是固定使用 MRR 了。\n\n  - 提升性能的核心：在索引 a 上做一个范围查询，拿到足够多的主键 id，通过排序后，再去主键索引查数据，才能体现出“顺序性”的优势。\n  - 用了 order by 就不要用 MRR 了\n\n- Batched Key Access（BKA）\n\n  - MySQL 5.6\n  - 对 NLJ 算法的优化\n\n    - NLJ 用不到 join_buffer，BKA 可以\n    - 每多一个 join，就多一个 join_buffer\n\n  - 启用方法，在执行 SQL 语句之前，先设置：set optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-35-2.png)\n\n\n    - 前两个参数的作用是要启用 MRR。BKA 算法的优化要依赖于 MRR。\n\n  - MySQL · 特性分析 · 优化器 MRR \u0026 BKA：[PolarDB 数据库内核月报](http://mysql.taobao.org/monthly/2016/01/04/)\n  - 并不是“先计算两个表 join 的结果，再跟第三个表 join”，而是直接嵌套查询的。\n\n- BNL 算法的性能问题\n\n- BNL 算法对系统的影响\n\n- 1. 可能会多次扫描被驱动表，占用磁盘 IO 资源；\n- 2. 判断 join 条件需要执行 M*N 次对比（M、N 分别是两张表的行数），如果是大表就会占用非常多的 CPU 资源；\n- 3. 可能会导致 Buffer Pool 的热数据被淘汰，影响内存命中率。\n\n- 如果一个使用 BNL 算法的 join 语句，多次扫描一个冷表，而且这个语句执行时间超过 1 秒，就会在再次扫描冷表的时候，把冷表的数据页移到 LRU 链表头部。\n- 业务正常访问的数据页，没有机会进入 young 区域。\n- 影响 Buffer Pool 的正常运作\n\n- 减小影响的方法：增大 join_buffer_size 的值，减少对被驱动表的扫描次数\n- 执行语句之前，通过理论分析和查看 explain 结果的方式，确认是否要使用 BNL 算法，如果确认优化器会使用，就需要做优化\n\n- BNL 转 BKA\n\n- 1. 一些情况下，直接在被驱动表上建索引\n- 2. 不能建索引时，使用临时表\n\n- 1. 把被驱动表中满足条件的数据放到临时表中\n- 2. 为了让 join 使用 BKA 算法，给临时表的字段加上索引\n- 3. 让驱动表和临时表做 join 操作\n- SQL：create temporary table temp_t(id int primary key, a int, b int, index(b))engine=innodb;insert into temp_t select * from t2 where b\u003e=1 and b\u003c=2000;select * from t1 join temp_t on (t1.b=temp_t.b);\n\n- 这里用内存临时表的效果更好create temporary table temp_t(id int primary key, a int, b int, index (b))engine=memory;insert into temp_t select * from t2 where b\u003e=1 and b\u003c=2000;select * from t1 join temp_t on (t1.b=temp_t.b);\n\n- 思路：用上被驱动表的索引，触发 BKA 算法\n\n- 扩展 -hash join\n\n- Mysql 8.0.18 已经支持 Hash-join8.0.20 版本以上官方已经移除BNL的支持，全部替换成 hash -join\n- join_buffer 维护的无序数组替换成哈希表\n\n- N * M =\u003e 1 * M\n\n- 自己在业务端实现\n\n- 1. select * from t1;取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构，比如 C++ 里的 set、PHP 的数组这样的数据结构。\n- 2. select * from t2 where b\u003e=1 and b\u003c=2000; 获取表 t2 中满足条件的 2000 行数据。\n- 3. 把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。\n\n- 执行效率：hash join \u003e 临时表\n\n- BKA 优化是 MySQL 已经内置支持的，建议默认使用；\n- 评论区\n\n- where in (?)，？的多个值不需要排序\n- 固态硬盘的顺序写还是比随机写快\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/36%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%B4%E6%97%B6%E8%A1%A8%E5%8F%AF%E4%BB%A5%E9%87%8D%E5%90%8D":{"title":"36｜为什么临时表可以重名？","content":"\n- 临时表和内存表不同\n\n  - 内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine=memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。\n  - 而临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。临时表也可以使用 Memory 引擎。\n\n- 临时表的特性\n\n  - 1. 建表语法是 create temporary table …。\n  - 2. 一个临时表只能被创建它的 session 访问，对其他线程不可见。\n\n    - 在 session 结束的时候会自动删除临时表\n\n      - 不用担心数据删除问题\n\n    - 不同 session 的临时表可以重名\n\n  - 3. 临时表可以与普通表同名。\n  - 4. session A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。\n  - 5. show tables 命令不显示临时表。\n\n- 临时表的应用\n\n  - 经常被用在复杂查询的优化过程中\n  - 典型：分库分表系统的跨库查询\n\n    - 第一种思路：在 proxy 层的进程代码中实现排序\n\n      - 1. 开发工作量比较大\n      - 2. 对 proxy 端压力大：内存、CPU\n\n    - 第二种思路：把各个分库拿到的数据，汇总到一个 MySQL 实例的一个表中，然后在这个汇总实例上做逻辑操作。\n\n      - 1. 在汇总库创建临时表\n      - 2. 在分库拿到需要的数据，插入到临时表中\n\n- 临时表可以重名\n\n  - 物理上的文件\n\n  - #sql{进程 id}_{线程 id}_ 序列号.frm 文件保存表结构定义\n\n    - 通过 select @@tmpdir 命令可以查看临时文件目录\n\n  - 5.6 以及之前的版本：#sql{进程 id}_{线程 id}_ 序列号.ibd 存放数据文件\n  - 5.7 开始：MySQL 引入了一个临时文件表空间，专门用来存放临时文件的数据。不需要再创建 ibd 文件了。\n\n  - 内存里面\n\n    - 每个表对应一个 table_def_key\n\n      - 普通表：库名 + 表名\n      - 临时表：库名 + 表名 + server_id + thread_id\n\n    - 在实现上，每个线程都维护了自己的临时表链表。这样每次 session 内操作表的时候，先遍历链表，检查是否有这个名字的临时表，如果有就优先操作临时表，如果没有再操作普通表；在 session 结束的时候，对链表里的每个临时表，执行 “DROP TEMPORARY TABLE + 表名”操作。\n\n- 临时表和主备复制\n\n  - 只在 binlog_format=statment/mixed 的时候，binlog 中才会记录临时表的操作。\n\n    - row 格式会记录操作的数据\n\n      - 删除临时表的语句会被改写，因为备库找不到临时表会报错\n      - /* generated by server */ 说明是被服务端改写过的语句\n\n  - MySQL 在记录 binlog 的时候，会把主库执行这个语句的线程 id 写到 binlog 中。这样，在备库的应用线程就能够知道执行每个语句的主库线程 id，并利用这个线程 id 来构造临时表的 table_def_key：\n\n- 本章的内存表都是用户手动创建的\n\n  - 内存临时表在 17 章和下一章有介绍\n\n- 思考题\n\n  - 可以用 alter table 修改临时表的表名，不能使用 rename 语法的原因？\n\n    - 在实现上，执行 rename table 语句的时候，要求按照“库名 / 表名.frm”的规则去磁盘找文件，但是临时表在磁盘上的 frm 文件是放在 tmpdir 目录下的，并且文件名的规则是“#sql{进程 id}_{线程 id}_ 序列号.frm”，因此会报“找不到文件名”的错误。\n\n- 评论区\n\n  - “临时表会自动回收”这个功能，主要用于“应用程序异常断开、MySQL异常重启”后，不需要主动去删除表。平时正常使用的时候，建议用完手动删除。\n\n    - 如果 A 客户端在执行过程中创建了临时表，用完了连接就放回池子里面，没有做别的清理工作，然后新的客户端 B 复用这个连接，就可能会看到 A 的临时表。具体要看连接池怎么实现的。\n\n  - 一般一个事务创建临时表以后，读写分离就会默认接下来的请求都路由到主库去了\n  - 用户没有显示指定主键的话，InnoDB 引擎会自己创建一个隐藏的主键，但是这个主键对 server 层是透明的，优化器用不上。\n  - 启以后 MySQL 会扫描临时目录，把表都删掉；\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/37%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E4%BC%9A%E4%BD%BF%E7%94%A8%E5%86%85%E9%83%A8%E4%B8%B4%E6%97%B6%E8%A1%A8":{"title":"37｜什么时候会使用内部临时表？","content":"\n- union 执行流程\n\n  - (select 1000 as f) union (select id from t1 order by id desc limit 2);这条语句用到了 union，它的语义是，取这两个子查询结果的并集。并集的意思就是这两个集合加起来，重复的行只保留一行。\n  - 创建临时表，执行第一个查询，拿到 1000，放入临时表，执行第二个查询，拿到 1000 和 999，1000 由于违反唯一性约束插入失败，接着放入 999 后返回，最后从临时表中按行取出数据，返回结果，并删除临时表\n  - 改成 union all 则没有去重的语义，执行时不需要临时表\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-37-1.png)\n\n\n- group by 执行流程\n\n  - select id%10 as m, count(*) as c from t1 group by m;创建临时表（m(pk)，c），扫表 t1 的索引 a，取出 id 并计算出 x，放入临时表/计数，完成后根据 m 做排序，得到结果集返回给客户端\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-37-2.png)\n\n  - order by null 可以跳过对结果集的排序\n  - 内存临时表的大小是有限制的，参数 tmp_table_size 就是控制这个内存大小的，默认是 16M。\n\n    - 如果超出，就会转成磁盘临时表\n\n  - 磁盘临时表默认使用 InnoDB 引擎\n\n- group by 优化方法 -- 索引\n\n  - 数据有序，就不需要临时表排序了\n\n    - 如果可以确保输入的数据是有序的，那么计算 group by 的时候，就只需要从左到右，顺序扫描，依次累加。\n\n  - 在 MySQL 5.7 版本支持了 generated column 机制，用来实现列数据的关联更新\n\n    - alter table t1 add column z int generated always as(id % 100), add index(z);\n\n  - MySQL 5.6 及之前的版本，你也可以创建普通列和索引\n  - 例子：select id%10 as m, count(*) as c from t1 group by m;可以改写成：select z, count(*) as c from t1 group by z;\n\n    - z 字段的值 = id%10\n\n- group by 优化方法 -- 直接排序\n\n  - 在 group by 语句中加入 SQL_BIG_RESULT 这个提示（hint），就可以告诉优化器：这个语句涉及的数据量很大，请直接用磁盘临时表。\n  - MySQL 的优化器一看，磁盘临时表是 B+ 树存储，存储效率不如数组来得高。所以，既然你告诉我数据量很大，那从磁盘空间考虑，还是直接用数组来存吧。\n\n    - 数组存放了每一个 id%10，最后排序，计数\n\n- 总结指导原则\n\n  - 1. 如果对 group by 语句的结果没有排序要求，要在语句后面加 order by null；\n  - 2. 尽量让 group by 过程用上表的索引，确认方法是 explain 结果里没有 Using temporary 和 Using filesort；\n  - 3. 如果 group by 需要统计的数据量不大，尽量只使用内存临时表；也可以通过适当调大 tmp_table_size 参数，来避免用到磁盘临时表；\n  - 4. 如果数据量实在太大，使用 SQL_BIG_RESULT 这个提示，来告诉优化器直接使用排序算法得到 group by 的结果。\n\n- 评论区\n\n  - 如果只需要去重，不需要执行聚合函数，distinct 和 group by 那种效率高一些呢？\n\n    - 只需要去重的话，如果没有 limit，是一样的；有 limit 的话，distinct 快些。\n\n  - sort_buffer、join_buffer、内存临时表和磁盘临时表 都是 server 层的，引擎间共用\n  - 需要创建临时表的时候，与当前访问数据的引擎无关，都是默认创建内存临时表，内存不够了转磁盘临时表（默认是 innodb 表）\n  - 内存表的主键不是保证有序的\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/38%E9%83%BD%E8%AF%B4-InnoDB-%E5%A5%BD%E9%82%A3%E8%BF%98%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8-Memory-%E5%BC%95%E6%93%8E":{"title":"38｜都说 InnoDB 好，那还要不要使用 Memory 引擎？","content":"\n- 内存表的数据组织结构\n\n  - InnoDB 引擎把数据放在主键索引上，其他索引上保存的是主键 id。这种方式，我们称之为索引组织表（Index Organizied Table）。\n  - 而 Memory 引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，我们称之为堆组织表（Heap Organizied Table）。\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-38-1.png)\n\n  - 1. InnoDB 表的数据总是有序存放的，而内存表的数据就是按照写入顺序存放的；\n  - 2. 当数据文件有空洞的时候，InnoDB 表在插入新数据的时候，为了保证数据有序性，只能在固定的位置写入新值，而内存表找到空位就可以插入新值；\n  - 3. 数据位置发生变化的时候，InnoDB 表只需要修改主键索引，而内存表需要修改所有索引；\n  - 4. InnoDB 表用主键索引查询时需要走一次索引查找，用普通索引查询的时候，需要走两次索引查找。而内存表没有这个区别，所有索引的“地位”都是相同的。\n  - 5. InnoDB 支持变长数据类型，不同记录的长度可能不同；内存表不支持 Blob 和 Text 字段，并且即使定义了 varchar(N)，实际也当作 char(N)，也就是固定长度字符串来存储，因此内存表的每行数据长度相同。\n\n- 内存表也支持 B-Tree 索引的\n\n  - alter table t1 add index a_btree_index using btree (id);\n\n- 不建议在生产环境使用普通内存表\n\n  - 1. 锁粒度问题\n\n    - 不支持行锁，只支持表锁\n\n  - 2. 数据持久化问题\n\n    - M - S 架构下，比如备库重启，内存表被清空，此时内存表被清空，导致主备同步停止\n    - 双 M 架构下，在备库重启的时候，备库 binlog 里的 delete 语句就会传到主库，然后把主库内存表的内容删除。\n\n- 建议把普通内存表都用 InnoDB 代替\n\n  - 例外：内存临时表\n\n    - 1. 临时表不会被其他线程访问，没有并发性的问题；\n    - 2. 临时表重启后也是需要删除的，清空数据这个问题不存在；\n    - 3. 备库的临时表也不会影响主库的用户线程。\n\n- 思考题\n\n  - 假设你刚刚接手的一个数据库上，真的发现了一个内存表。备库重启之后肯定是会导致备库的内存表数据被清空，进而导致主备同步停止。这时，最好的做法是将它修改成 InnoDB 引擎表。\n  - 假设当时的业务场景暂时不允许你修改引擎，你可以加上什么自动化逻辑，来避免主备同步停止呢？\n\n    - 先避免备库重启的时候数据丢失：set sql_log_bin=off;alter table tbl_name engine=innodb;由于主库重启后，会往 binlog 写 delete from tbl_name，传到备库，备库的同名的表数据也会被清空，所以不会出现主备同步停止的问题\n    - 如果主库变成新备库，重复上面的操作\n    - 所以，如果我们不能直接修改主库上的表引擎，可以配置一个自动巡检的工具，在备库上发现内存表就把引擎改了。\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/39%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E6%98%AF%E8%BF%9E%E7%BB%AD%E7%9A%84":{"title":"39｜自增主键为什么不是连续的？","content":"\n- 自增值保存在哪儿？\n\n  - 表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。\n  - MyISAM 引擎的自增值保存在数据文件中。\n  - InnoDB\n\n    - 在 MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。\n    - 在 MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。\n\n- 自增值修改机制\n\n  - 1. 如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；\n  - 2. 如果插入数据时 id 字段指定了具体的值，就直接使用语句里指定的值。\n\n    - 如果大于当前自增值，则会将插入的值的下一个大于的值作为自增值（基于步长）\n\n- 自增值的修改时机\n\n  - insert into t values(null, 1, 1); 发现没指定自增值，获取表当前的自增值（假设是 2）将传入的行改成 (2, 1, 1)将表的自增值改成 3继续执行插入操作发生唯一键冲突，插入失败\n\n    - 第一种原因：唯一键冲突\n\n  - 第二种原因：事务回滚，自增值不回退\n\n    - 两个事务，前一个拿到自增值，后一个再拿到自增值，前一个执行失败，如果回退，将导致主键冲突\n    - 为了解决主键冲突有两种方法，但是影响性能\n\n- 自增锁的优化\n\n  - MySQL 5.0 版本，自增锁的范围是语句级别，等语句执行完才释放，影响并发度\n  - MySQL 5.1.22 引入一个新策略，新增参数 innodb_autoinc_lock_mode，默认值 1\n\n    - 1. 这个参数的值被设置为 0 时，表示采用之前 MySQL 5.0 版本的策略\n    - 2. 这个参数的值被设置为 1 时：  a. 普通 insert 语句，自增锁在申请之后就马上释放；  b. 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；\n\n      - 关于 b，如果像参数设置 2 一样，将会导致主备不一致（binlog_format=statement），因为事务的 binlog 是记录到一起的，在备库是连续，但在主库时却不一定是连续拿到自增值\n      - 这里说的批量插入数据，包含的语句类型是 insert … select、replace … select 和 load data 语句。\n      - b 的设定是因为“不知道要预先申请多少个 id”\n\n    - 3. 这个参数的值被设置为 2 时，所有的申请自增主键的动作都是申请后就释放锁。\n\n      - 推荐，需配合 binlog_format=row\n\n  - 在 8.0.3 版本后，innodb_autoinc_lock_mode 默认值已是 2\n\n- 对于批量插入数据的语句，MySQL 有一个批量申请自增 id 的策略：\n\n  - 1. 语句执行过程中，第一次申请自增 id，会分配 1 个；\n  - 2. 1 个用完以后，这个语句第二次申请自增 id，会分配 2 个；\n  - 3. 依此类推，同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。\n  - 最后一次申请的如果没用完就浪费掉了\n\n    - 第三种原因\n\n- 思考题\n\n  - 在最后一个例子中，执行 insert into t2(c,d) select c,d from t; 这个语句的时候，如果隔离级别是可重复读（repeatable read），binlog_format=statement。这个语句会对表 t 的所有记录和间隙加锁。\n  - 你觉得为什么需要这么做呢？\n\n- 评论区\n\n  - 在 binlog 为 statement 的情况下。语句 A 先获取 id=1，然后 B 获取 id=2，接着 B 提交，写 binlog，再 A 写 binlog。这个时候如果 binlog 重放，是不是会发生 B 的 id 为 1，而 A的 id 为 2 的不一致的情况？\n\n    - 不会因为 binlog 在记录这种带自增值的语句之前，会在前面多一句，用于指定“接下来这个语句要需要的 自增 ID 值是多少”，而这个值，是在主库上这一行插入成功后对应的自增值，所以是一致的\n\n      - 跟这里不冲突，因为这里是在说主库事务中不能连续拿到的问题\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/40insert-%E8%AF%AD%E5%8F%A5%E7%9A%84%E9%94%81%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%A4%9A":{"title":"40｜insert 语句的锁为什么这么多？","content":"\n- insert … select 语句\n\n  - 并发 insert 场景\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-40-1.png)\n\n\n    - 实际的执行效果是，如果 session B 先执行，由于这个语句对表 t 主键索引加了 (-∞,1]这个 next-key lock，会在语句执行完成后，才允许 session A 的 insert 语句执行。\n    - 但如果没有锁的话，就可能出现 session B 的 insert 语句先执行，但是后写入 binlog 的情况。于是，在 binlog_format=statement 的情况下，binlog 里面就记录了这样的语句序列：insert into t values(-1,-1,-1);insert into t2(c,d) select c,d from t;这个语句到了备库执行，就会把 id=-1 这一行也写到表 t2 中，出现主备不一致。\n\n  - 是很常见的在两个表之间拷贝数据的方法\n  - 在可重复读隔离级别下，这个语句会给 select 的表里扫描到的记录和间隙加读锁。\n\n- insert 循环写入\n\n  - 如果 insert 和 select 的对象是同一个表，则有可能会造成循环写入。这种情况下，我们需要引入用户临时表来做优化。\n  - 怕边遍历原表边插入数据会查到刚插入的新数据，所以会先把查询结果放到临时表，再取出来进行插入操作\n  - 这里需要给子查询加入 limit，不然就会全表扫描，导致给所有记录和空隙加锁\n\n    - 8.x 优化了\n\n- insert 唯一键冲突\n  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-40-2.png)\n\n\n  - insert 语句如果出现唯一键冲突，会在冲突的唯一值上加共享的 next-key lock(S 锁)。因此，碰到由于唯一键约束导致报错后，要尽快提交或回滚事务，避免加锁时间过长。\n  - 唯一键冲突加锁\n  - 一个经典的死锁场景\n    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-40-3.png)\n\n\n    - A 先加锁，B、C 发现唯一键冲突（c 是唯一索引，所以读是当前读），都加上读锁（间隙锁不互斥所以加成功，读、写锁会互斥，所以都在等待行锁释放），A 回滚，B、C 继续执行，都要加上写锁，互相等待对方的行锁，于是出现了死锁\n\n- insert into … on duplicate key update\n\n  - 这个语义的逻辑是，插入一行数据，如果碰到唯一键约束，就执行后面的更新语句。\n\n    - 会给索引 c 上 (5,10] 加一个排他的 next-key lock（写锁）。\n\n  - 如果有多个列违反了唯一性约束，就会按照索引的顺序，修改跟第一个索引冲突的行。\n  - 执行这条语句的 affected rows 返回的是 2，很容易造成误解。\n\n    - 真正更新的只有一行，只是在代码实现上，insert 和 update 都认为自己成功了，update 计数加了 1， insert 计数也加了 1。\n\n- 评论区\n\n  - 关于 insert 造成死锁的情况，并非只有 insert，delete 和 update 都可能造成死锁问题，核心还是插入唯一值冲突导致的线上的处理办法可以是 1 去掉唯一值检测 2 减少重复值的插入 3 降低并发线程数量\n  - 关于数据拷贝大表，建议采用 pt-archiver，这个工具能自动控制频率和速度，建议在低峰期进行数据操作\n  - 一般 select …lock in share mode 就是共享锁；select … for update 和 IUD 语句，就是排他锁。\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/41%E6%80%8E%E4%B9%88%E6%9C%80%E5%BF%AB%E5%9C%B0%E5%A4%8D%E5%88%B6%E4%B8%80%E5%BC%A0%E8%A1%A8":{"title":"41｜怎么最快地复制一张表？","content":"\n- 逻辑导数据\n\n  - 在两张表中拷贝数据，最简单地使用 insert … select 语句即可实现\n  - 将数据写到外部文本文件，然后再写回目标表\n\n    - 1. mysqldump 方法\n\n      - a. 将数据导出成一组 INSERT 语句：mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction --set-gtid-purged=OFF db1 t --where=\"a\u003e900\" --result-file=/client_tmp/t.sql\n      - b. 将结果拿到目标库里执行：mysql -h127.0.0.1 -P13000 -uroot db2 -e \"source /client_tmp/t.sql\"\n\n        - source 并不是一条 SQL 语句，而是一个客户端命令。1. 打开文件，默认以分号为结尾读取一条条的 SQL 语句；2. 将 SQL 语句发送到服务端执行\n        - binlog 记录了真正被执行的 INSERT 语句\n\n    - 2. 导出 CSV 文件\n\n      - a. 将查询结果导出到服务端本地目录select * from db1.t where a\u003e900 into outfile '/server_tmp/t.csv';\n\n        - 会将结果保存在服务端\n        - secure_file_priv 限制文件生成位置\n\n          - empty：不限制\n          - 路径字符串：只能在这个指定目录或它的子目录下\n          - NULL：禁止执行 select … into outfile\n\n        - 遇到同名文件报错\n        - 该命令不会生成表结构文件\n\n          - mysqldump 提供了一个–tab 参数，可以同时导出表结构定义文件和 csv 数据文件mysqldump -h$host -P$port -u$user ---single-transaction --set-gtid-purged=OFF db1 t --where=\"a\u003e900\" --tab=$secure_file_priv\n\n      - b. load data  命令将数据导入目标表：load data infile '/server_tmp/t.csv' into table db2.t;\n\n        - 如果 binlog_format=statement，1. 主库执行完成后，将 /server_tmp/t.csv 文件的内容直接写到 binlog 文件中。2. 往 binlog 文件中写入语句 load data local infile ‘/tmp/SQL_LOAD_MB-1-0’ INTO TABLE `db2`.`t`。3. 把这个 binlog 日志传到备库。4. 备库的 apply 线程在执行这个事务日志时：  a. 先将 binlog 中 t.csv 文件的内容读出来，写入到本地临时目录 /tmp/SQL_LOAD_MB-1-0 中；  b. 再执行 load data 语句，往备库的 db2.t 表中插入跟主库相同的数据。\n          - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-41-1.png)\n\n        - load data 命令有两种用法：\n\n          - 1. 不加“local”，是读取服务端的文件，这个文件必须在 secure_file_priv 指定的目录或子目录下；\n          - 2. 加上“local”，读取的是客户端的文件，只要 mysql 客户端有访问这个文件的权限即可。这时候，MySQL 客户端会先把本地文件传给服务端，然后执行上述的 load data 流程。\n\n  - 都可以跨引擎使用\n\n- 物理拷贝方案（最快）\n\n  - MySQL 5.6\n\n    - 1. 执行 create table r like t，创建一个相同表结构的空表；\n    - 2. 执行 alter table r discard tablespace，这时候 r.ibd 文件会被删除；\n    - 3. 执行 flush table t for export，这时候 db1 目录下会生成一个 t.cfg 文件；\n    - 4. 在 db1 目录下执行 cp t.cfg r.cfg; cp t.ibd r.ibd；这两个命令（这里需要注意的是，拷贝得到的两个文件，MySQL 进程要有读写权限）；\n    - 5. 执行 unlock tables，这时候 t.cfg 文件会被删除；\n    - 6. 执行 alter table r import tablespace，将这个 r.ibd 文件作为表 r 的新的表空间，由于这个文件的数据内容和 t.ibd 是相同的，所以表 r 中就有了和表 t 相同的数据。\n\n  - 只能全表拷贝\n  - 需要到服务器上拷贝数据，无法登录数据库主机时无法使用\n  - InnoDB 专属\n\n- 思考题\n\n  - 我们前面介绍 binlog_format=statement 的时候，binlog 记录的 load data 命令是带 local 的。既然这条命令是发送到备库去执行的，那么备库执行的时候也是本地执行，为什么需要这个 local 呢？\n\n    - 1. 为了确保备库应用 binlog 正常。因为备库可能配置了 secure_file_priv=null，所以如果不用 local 的话，可能会导入失败，造成主备同步延迟。\n    - 2. 使用 mysqlbinlog 工具解析 binlog 文件，并应用到目标库的情况。使用下面命令 ：mysqlbinlog $binlog_file | mysql -h$host -P$port -u$user -p$pwd把日志直接解析出来发给目标库执行。增加 local，就能让这个方法支持非本地的 $host。\n\n  - 如果写到 binlog 中的命令不带 local，又会出现什么问题呢？\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/42grant-%E4%B9%8B%E5%90%8E%E8%A6%81%E8%B7%9F%E7%9D%80-flush-privileges-%E5%90%97":{"title":"42｜grant 之后要跟着 flush privileges 吗？","content":"\n- 不用\n- 在 MySQL 里面，用户名 (user)+ 地址 (host) 才表示一个用户，因此 ua@ip1 和 ua@ip2 代表的是两个不同的用户。\n- 全局权限\n\n  - 保存在 mysql.user 表\n  - 给用户 ua 赋一个最高权限，语句：grant all privileges on *.* to 'ua'@'%' with grant option;\n\n    - 同时更新了磁盘和内存\n    - 1. 磁盘上，将 mysql.user 表里，用户’ua’@’%'这一行的所有表示权限的字段的值都修改为‘Y’；\n    - 2. 内存里，从数组 acl_users 中找到这个用户对应的对象，将 access 值（权限位）修改为二进制的“全 1”。\n    - 在这个 grant 命令执行完成后，如果有新的客户端使用用户名 ua 登录成功，MySQL 会为新连接维护一个线程对象，然后从 acl_users 数组里查到这个用户的权限，并将权限值拷贝到这个线程对象中。之后在这个连接中执行的语句，所有关于全局权限的判断，都直接使用线程对象内部保存的权限位。\n    - revoke 命令也一样\n\n- db 权限\n\n  - 保存在 mysql.db 表\n  - 让用户 ua 拥有库 db1 的所有权限：grant all privileges on db1.* to 'ua'@'%' with grant option;\n\n    - 1. 磁盘上，往 mysql.db 表中插入了一行记录，所有权限位字段设置为“Y”；\n    - 2. 内存里，增加一个对象到数组 acl_dbs 中，这个对象的权限位为“全 1”。\n    - 每次需要判断一个用户对一个数据库读写权限的时候，都需要遍历一次 acl_dbs 数组\n    - acl_dbls 是一个全局数组\n    - 如果已经 use database_name，则在切换出该库之前，session 就一直有该库权限\n\n- 表权限和列权限\n\n  - 表权限定义存放在表 mysql.tables_priv 中，列权限定义存放在表 mysql.columns_priv 中。这两类权限，组合起来存放在内存的 hash 结构 column_priv_hash 中。\n  - column_priv_hash 也是一个全局对象\n\n- 如果内存的权限数据和磁盘数据表相同的话，不需要执行 flush privileges。\n- 如果我们都是用 grant/revoke 语句来执行的话，内存和数据表本来就是保持同步更新的。\n\n  - flush privileges 语句可以用来重建内存数据，达到一致状态。\n\n- flush privileges 使用场景\n\n  - 直接手动修改系统权限表时\n\n- grant 命令加了 identified by ‘密码’\n\n  - 1. 如果用户’ua’@’%'不存在，就创建这个用户，密码是 pa；\n  - 2. 如果用户 ua 已经存在，就将密码修改成 pa。\n  - 不建议的写法，容易不慎把密码给改了\n\n- 评论区\n\n  - 文章内容总结\n    - ![Uploading file...3lmt9]()\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/43%E8%A6%81%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8%E5%88%86%E5%8C%BA%E8%A1%A8":{"title":"43｜要不要使用分区表？","content":"\n- 分区表：对于引擎层，n 个表对于 server 层，1 个表\n- 分区策略\n\n  - MyISAM 分区表\n  - InnoDB 分区表\n  - 通用分区策略：每次访问都由 server 层控制\n\n    - MyISAM 分区表使用的分区策略\n    - 性能较差\n    - 5.7.17 开始标记为即将弃用8.0 开始不允许使用\n    - 打开分区表时，如果分区过多，超过 open_files_limit 参数设置的值时会报错，默认 1024\n\n  - 本地分区策略：引擎内部自己管理打开分区的行为\n\n    - InnoDB 和 NDB 引擎支持了\n    - 没有通用分区策略会报错的问题：innodb_open_files 参数控制打开多少个文件后自动关闭一些之前打开的文件\n\n- 分区表的 server 层行为\n\n  - 1. MySQL 在第一次打开分区表的时候，需要访问所有的分区；\n  - 2. 在 server 层，认为这是同一张表，因此所有分区共用同一个 MDL 锁；\n  - 3. 在引擎层，认为这是不同的表，因此 MDL 锁之后的执行过程，会根据分区表规则，只访问必要的分区。\n\n- 分区表的应用场景\n\n  - 对业务透明，代码更简洁\n  - 清理历史数据方便\n\n    - 删掉分区：alter table t drop partition …会直接删除分区文件，效果跟 drop 普通表类似\n    - 与使用 delete 语句删除数据相比，速度快，对系统影响小\n\n- 注意事项\n\n  - 1. 分区并不是越细越好。\n  - 2. 分区也不要提前预留太多，在使用之前预先创建即可。比如，如果是按月分区，每年年底时再把下一年度的 12 个新分区创建上即可。对于没有数据的历史分区，要及时的 drop 掉。\n\n- 其他分区方法：[官方手册](https://dev.mysql.com/doc/refman/8.0/en/partitioning-types.html)\n- 思考题\n\n  - 文章中举例只用到了日期字段，没有自增主键，如果要定义这个表的主键，怎么定义？为什么？\n\n    - MySQL 要求主键包含所有的分区字段\n\n      - 这里必须创建联合主键\n\n    - 从利用率上看，应该创建 (ftime, id)\n\n      - InnoDB 要求至少有一个索引，以自增字段作为第一个字段，所以还要创建一个 id 的单独索引\n\n    - 上面的方案反过来也可以 (id, ftime) (ftime)\n\n- 评论区\n\n  - 分区表的用法跟普通表，在 sql 语句上是相同的。\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/44%E7%AD%94%E7%96%91%E6%96%87%E7%AB%A0%E4%B8%89%E8%AF%B4%E4%B8%80%E8%AF%B4%E8%BF%99%E4%BA%9B%E5%A5%BD%E9%97%AE%E9%A2%98":{"title":"44｜答疑文章（三）：说一说这些好问题","content":"\n- join 的写法\n\n  - 在 MySQL 里，NULL 跟任何值执行等值判断和不等值判断的结果，都是 NULL。这里包括， select NULL = NULL 的结果，也是返回 NULL。\n\n    - where a.f2=b.f2 就表示，查询结果里面不会包含 b.f2 是 NULL 的行\n\n  - 使用 left join 时，左边的表不一定是驱动表。\n  - 如果需要 left join 的语义，就不能把被驱动表的字段放在 where 条件里面做等值判断或不等值判断，必须都写在 on 里面\n\n- distinct 和 group by 的性能\n\n  - 如果只需要去重，不需要执行聚合函数，distinct 和 group by 哪种效率高一些呢？\n\n    - 没有索引时一样\n    - select a,count(*) from t group by a order by null;这条语句的逻辑是：按照字段 a 分组，计算每组的 a 出现的次数。在这个结果里，由于做的是聚合计算，相同的 a 只出现一次。37 章有关于 group by 的相关内容\n\n- 思考题\n\n  - 查看了一下 innodb_trx，发现这个事务的 trx_id 是一个很大的数（281479535353408），而且似乎在同一个 session 中启动的会话得到的 trx_id 是保持不变的。当执行任何加写锁的语句后，trx_id 都会变成一个很小的数字（118378）。\n  - 你可以通过实验验证一下，然后分析看看，事务 id 的分配规则是什么，以及 MySQL 为什么要这么设计呢？\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/45%E8%87%AA%E5%A2%9E-id-%E7%94%A8%E5%AE%8C%E6%80%8E%E4%B9%88%E5%8A%9E":{"title":"45｜自增 id 用完怎么办？","content":"\n- 表定义的自增值达到上限后的逻辑是：再申请下一个 id 时，得到的值保持不变。\n- row_id\n\n  - InnoDB 表没有指定主键时，会创建一个不可见的，长度为 6 个字节的 row_id。\n  - row_id 是一个长度 8 字节的无符号长整形\n  - 但是 InnoDB 只留了 6 个字节的长度给 row_id 用\n\n    - 1. row_id 写入表中的值范围，是从 0 到 248-1；\n    - 2. 达到上限后从 0 开始，写入时会覆盖原有的行\n\n- Xid\n\n  - redo log 和 binlog 相配合时都有的一个共同字段\n  - MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。\n  - global_query_id 是一个纯内存变量，重启之后就清零了\n\n    - 1. 重启后会清零\n\n      - 不同事务的 Xid 可能相同\n\n  - 2. 重启后会重新生成新的 binlog 文件\n\n    - 同一个 binlog 文件里，Xid 唯一\n    - 达到上限（超大）后从 0 开始，还是可能不唯一，但是只存在于理论上\n\n  - 长度是 8 个字节，上限超大\n\n- Innodb trx_id\n\n  - 第 8 篇讲事务可见性用到的事务 id（transaction id）\n  - Xid 由 server 层维护，InnoDB 内部使用 Xid 是为了在 InnoDB 事务和 server 之间做关联\n  - InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。\n\n    - 对于正在执行的事务，可以从 information_schema.innodb_trx 表中看到事务的 trx_id。\n    - 对于只读事务，InnoDB 不分配 trx_id，在表中查看到的很大的 trx_id 只是显示用的\n\n      - 把当前事务的 trx 变量的指针地址转成整数，再加上 2^48\n\n        - 1. 因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx 还是在 innodb_locks 表里，同一个只读事务查出来的 trx_id 就会是一样的。\n        - 2. 如果有并行的多个只读事务，每个事务的 trx 变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的 trx_id 就是不同的。\n        - 加上是为了避免跟真正的 trx_id 一样\n\n      - 不分配的好处\n\n        - 可以减小事务视图里面活跃事务数组的大小\n        - 可以减少 trx_id 的申请次数（减少并发事务申请 trx_id 的锁冲突）\n\n    - select 语句后面加上 for update 则不是只读事务\n    - 1. update 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1， 因此在一个事务中至少加 2；\n    - 2. InnoDB 的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id 值并不是按照加 1 递增的。\n\n  - InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。\n  - 重启 MySQL时 max_trx_id 不会清零\n\n    - 理论上，MySQL 实例运行得足够久，trx_id 达到上限后从 0 开始，就会持续出现脏读\n\n- thread_id\n\n  - 4 个字节，达到 2^32 - 1 后重置为 0，然后继续增加\n  - 不会在 show processlist 看到两个相同的 thread_id\n\n    - MySQL 设计了一个唯一数组：循环尝试插入自增 1 的线程 id 直到成功\n\n- 小结\n\n  - 1. 表的自增 id 达到上限后，再申请时它的值就不会改变，进而导致继续插入数据时报主键冲突的错误。\n  - 2. row_id 达到上限后，则会归 0 再重新递增，如果出现相同的 row_id，后写的数据会覆盖之前的数据。\n  - 3. Xid 只需要不在同一个 binlog 文件中出现重复值即可。虽然理论上会出现重复值，但是概率极小，可以忽略不计。\n  - 4. InnoDB 的 max_trx_id 递增值每次 MySQL 重启都会被保存起来，所以我们文章中提到的脏读的例子就是一个必现的 bug，好在留给我们的时间还很充裕。\n  - 5. thread_id 是我们使用中最常见的，而且也是处理得最好的一个自增 id 逻辑了。\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/About-Atlas":{"title":"About Atlas","content":"","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Capslock":{"title":"Capslock","content":"\n## 功能\n\n加强 Caps 键功能\n\n## 安装\n\n[Github](https://github.com/Vonng/Capslock)\n\n## 单击 Caps 切换输入法\n\n- 打开配置文件 `~/.config/karabiner/karabiner.json`\n- 做如下修改：\n  - 找到 `caps_lock` 的 `to_if_alone`\n  - 将 `key_code` 改成 `caps_lock`\n  - 找到 `spacebar = language switch`\n  - 删除所在 `{}` 代码块\n- 目的：维持单点 Caps 切换输入法\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Crontab-%E6%89%A7%E8%A1%8C%E6%8F%90%E7%A4%BA%E6%B2%A1%E6%9C%89%E6%9D%83%E9%99%90":{"title":"Crontab 执行提示没有权限","content":"\n- Mac 的解决方案：[How to Fix Cron \"Operation not permitted\" error in macOS - ITPro Helper](https://itprohelper.com/how-to-fix-cron-operation-not-permitted-error-in-macos/)\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Laravel-Pint-%E4%BD%BF%E7%94%A8":{"title":"Laravel Pint 使用","content":"\n参考：\n\n- https://laraveldaily.com/post/laravel-pint-pre-commit-hooks-github-actions\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Linux-%E5%AE%89%E8%A3%85-oh-my-zsh":{"title":"Linux 安装 oh-my-zsh","content":"\n## 安装 Zsh\n\n- \u003chttps://github.com/ohmyzsh/ohmyzsh/wiki/Installing-ZSH\u003e\n\n  ```shell\n  sudo apt install zsh\n\n  # 查看所有可用 shell\n  chsh -l\n\n  # 将终端默认 shell 切换到 zsh，后面要输入实际看到的 zsh 路径\n  chsh -s /bin/zsh\n\n  # 新开一个终端确认是否切换成功\n  echo $SHELL\n  ```\n\n## 安装 Oh-my-zsh\n\n- \u003chttps://ohmyz.sh/#install\u003e\n\n## 插件\n\n- git clone 到 .oh-my-zsh/custom/plugins\n  - \u003chttps://github.com/zsh-users/zsh-syntax-highlighting/blob/master/INSTALL.md\u003e\n  - \u003chttps://github.com/zsh-users/zsh-autosuggestions/blob/master/INSTALL.md#oh-my-zsh\u003e\n- autojump\n  - Ubuntu：sudo apt install autojump\n  - Centos：yum install aotojump-zsh\n- 修改 ~/.zshrc 文件的内容\n  - `plugins=(git autojump zsh-autosuggestions zsh-syntax-highlighting)`\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/MySQL-%E5%AE%9E%E6%88%98-45-%E8%AE%B2":{"title":"MySQL 实战 45 讲","content":"\n\u003e 内容整理自极客时间[《MySQL 实战 45 讲》](https://time.geekbang.org/column/intro/100020801)\n\n## 章节分类\n\n| 分类名     | 章节 |\n| ---------- | ---- |\n| 基础知识   | 01   |\n| 索引       |     04、05、09、10、11、15、16、18 |\n| 事务       |      03、08、20|\n| 锁         |     06、07、13、19、20、21、30、40 |\n| 日志与主备 |     02、12、23、24、25、26、27、28、29、31 |\n| 临时表     |     17、34、35、36、37、43 |\n| 实用性           |   14、32、33、38、41、44、45   |\n\n## 基础篇\n\n- [[01｜基础架构：一条 SQL 查询语句是如何执行的？]]\n- [[02｜日志系统：一条 SQL 更新语句是如何执行的？]]\n- [[03｜事务隔离：为什么你改了为还看不见？]]\n- [[04｜深入浅出索引（上）]]\n- [[05｜深入浅出索引（下）]]\n- [[06｜全局锁和表锁：给表加个字段怎么有这么多阻碍？]]\n- [[07｜行锁功过：怎么减少锁对性能的影响？]]\n- [[08｜事务到底是隔离的还是不隔离的？]]\n\n## 实践篇\n\n- [[09｜普通索引和唯一索引，应该怎么选择？]]\n- [[10｜MySQL 为什么有时候会选错索引？]]\n- [[11｜怎么给字符串字段加索引？]]\n- [[12｜为什么我的 MySQL 会“抖”一下？]]\n- [[13｜为什么表数据删掉一半，表文件大小不变？]]\n- [[14｜count(*) 这么慢，我该怎么办？]]\n- [[15｜答疑文章（一）：日志和索引相关问题]]\n- [[16｜“order by”是怎么工作的？]]\n- [[17｜如何正确地显示随机消息？]]\n- [[18｜为什么这些 SQL 语句逻辑相同，性能却差异巨大？]]\n- [[19｜为什么我只查一行的语句，也执行这么慢？]]\n- [[20｜幻读是什么，幻读有什么问题？]]\n- [[21｜为什么我只改一行的语句，锁这么多？]]\n- [[22｜MySQL有哪些“饮鸩止渴”提高性能的方法？]]\n- [[23｜MySQL 是怎么保证数据不丢的？]]\n- [[24｜MySQL 是怎么保证主备一致的？]]\n- [[25｜MySQL 是怎么保证高可用的？]]\n- [[26｜备库为什么会延迟好几个小时？]]\n- [[27｜主库出问题了，从库怎么办？]]\n- [[28｜读写分离有哪些坑？]]\n- [[29｜如何判断一个数据库是不是出问题了？]]\n- [[30｜答疑文章（二）：用动态的观点看加锁]]\n- [[31｜误删数据后除了跑路，还能怎么办？]]\n- [[32｜为什么还有 kill 不掉的语句？]]\n- [[33｜我查这么多数据，会不会把数据库内存打爆？]]\n- [[34｜到底可不可以使用 join ？]]\n- [[35｜join 语句怎么优化？]]\n- [[36｜为什么临时表可以重名？]]\n- [[37｜什么时候会使用内部临时表？]]\n- [[38｜都说 InnoDB 好，那还要不要使用 Memory 引擎？]]\n- [[39｜自增主键为什么不是连续的？]]\n- [[40｜insert 语句的锁为什么这么多？]]\n- [[41｜怎么最快地复制一张表？]]\n- [[42｜grant 之后要跟着 flush privileges 吗？]]\n- [[43｜要不要使用分区表？]]\n- [[44｜答疑文章（三）：说一说这些好问题]]\n- [[45｜自增 id 用完怎么办？]]\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Obsidian":{"title":"Obsidian","content":"\n- [官网](https://obsidian.md/)\n- Obsidian 是一个功能强大且可扩展的知识库，它在您的本地纯文本文件文件夹之上运行。\n- 此数字花园的文本编辑器\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Obsidian-%E6%8F%92%E4%BB%B6":{"title":"Obsidian 插件","content":"\n## 推荐\n\n- [Enhancing Mindmap](https://github.com/MarkMindCkm/obsidian-enhancing-mindmap)：思维导图，只需修改文档头，没有额外学习成本\n\n## 其他\n\n- [2022年7月，obsidian 依然必装的 10 个插件](https://garden.oldwinter.top/2022%E5%B9%B47%E6%9C%88obsidian-%E4%BE%9D%E7%84%B6%E5%BF%85%E8%A3%85%E7%9A%84-10-%E4%B8%AA%E6%8F%92%E4%BB%B6)\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Oh-My-Zsh":{"title":"Oh My Zsh","content":"\nLinux 用户请看：[[Linux 安装 oh-my-zsh]]\n\n## 安装\n\n1. 切换到系统自带的 Zsh：`chsh -s /bin/zsh`\n2. [Oh My Zsh](https://ohmyz.sh/)\n\n## 系统终端的配色方案\n\n1. [Powerlevel10k](https://github.com/romkatv/powerlevel10k#getting-started)\n2. 下载\n\n     ```bash\n     cd ~/Downloads\n     git clone git://github.com/altercation/solarized.git\n     ```\n\n3. 打开终端，按「⌘ + ,」打开终端偏好设置，点击「描述文件 \u003e ⚙︎⌄ \u003e 导入」，选择「osx-terminal…ors-solarized/xterm 256 color」\n\n## 插件\n\n  ```bash\n  brew install autojump\n  brew install zsh-syntax-highlighting\n  brew install zsh-autosuggestions\n\n  # 添加以下内容到 .zshrc 文件末尾（上面三条命令运行结束会有提示）\n\n  # zsh plugins\n  source /opt/homebrew/share/zsh-autosuggestions/zsh-autosuggestions.zsh\n  source /opt/homebrew/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\n  [ -f /opt/homebrew/etc/profile.d/autojump.sh ] \u0026\u0026 . /opt/homebrew/etc/profile.d/autojump.sh\n  HIST_STAMPS=\"mm/dd/yyyy\"\n  ```\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/PHP-%E5%BC%80%E5%8F%91%E8%AE%BE%E7%BD%AE":{"title":"PHP 开发设置","content":"\n## Laravel Pint\n\n[如何在PHPSTORM 配置Laravel Pint 代码格式化包](https://learnku.com/articles/69376)\n\n[Laravel Pint](https://learnku.com/docs/laravel/10.x/pintmd/14912)\n\n## VSCode\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/PHP-%E9%94%99%E8%AF%AF%E7%A0%81%E8%AE%BE%E8%AE%A1":{"title":"PHP 错误码设计","content":"\n## 目标\n\n错误码包含：数字、英文、含义，还可以有 HTTP Status\n\n这些最好放到一起，不然添加时容易漏\n\n## 方案\n\n静态变量：数组\n\n多个名字类似的静态变量\n\n静态工厂方法\n\n枚举和注解\n\n## 讨论\n\n## 结论\n\n## 参考\n\n- [Using attributes to add value](https://laravel-news.com/using-attributes-to-add-value?utm_medium=email\u0026utm_campaign=Laravel%20News%20Daily%202023-04-27\u0026utm_content=Laravel%20News%20Daily%202023-04-27+CID_8d1e7adeaf80f59533f51d1e5bc52d9d\u0026utm_source=email%20marketing\u0026utm_term=Using%20attributes%20to%20add%20value)\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/PHP-FPM-%E9%85%8D%E7%BD%AE":{"title":"PHP-FPM 配置","content":"\n以下内容适用于 IO 密集型应用\n\n一个 PHP-FPM 进程大约占 30M 内存\n\n- 进程数量\n  - 计算公式：进程数 = 内存大小（M） * 0.6 / 30\n  - 举例：`8G * 1024 * 0.6 / 30 = 163.84`\n- `max_requests`\n  - 每个进程重启前可以处理的请求数\n  - 由 `pm.max_children` 的值和每秒的实际请求数量决定\n\n参考文章\n\n- [FastCGI 进程管理器（FPM）](https://www.php.net/manual/zh/install.fpm.php)\n- [PHP-FPM tuning: Using ‘pm static’ for Max Performance](https://www.sitepoint.com/php-fpm-tuning-using-pm-static-max-performance/)（[译文](https://learnku.com/php/t/14952/php-fpm-tuning-use-pm-static-to-maximize-your-server-load-capability)）\n- [PHP-FPM 配置](https://www.go365.tech/blog/4)\n- [PHP-FPM 进程数设置多少合适](https://zhuanlan.zhihu.com/p/94627701)\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/README":{"title":"README","content":"\n## 🪴 11ze's Garden\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Rate-Limit":{"title":"Rate Limit","content":"\n## 功能\n\n限制接口请求数\n\n## 缓存数据格式\n\n```JavaScript\nkey: {\n  current_count: number; // 也可以不要该字段，每次请求都算一次队列长度\n  started_at: date;\n  request_time_queue: date[];\n  time_range: number; // 时间窗口大小\n  count_limit: number;\n}\n```\n\n## 实现流程\n\n1. 请求进来\n2. 拼接出 key\n3. 查找 key 对应的缓存\n4. 取出队头，跟当前时间比较\n    a. 若超出时间窗口，则移除，继续取下一个\n1. 查看当前累积请求数量\n2. 跟 limit 比较，若大于等于，拒绝请求\n3. 若小于\n    a. 将当前时间加入队列\n    b. 当前请求数量 + 1\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Redis-%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98":{"title":"Redis 核心技术与实战","content":"\n\u003e 内容整理自极客时间[《Redis 核心技术与实战》](https://time.geekbang.org/column/intro/100056701))\n\n## 基础篇\n\n- [[00｜开篇词]]\n- [[01｜基础架构：一个键值数据库包含什么？]]\n- [[02｜数据结构：快速的 Redis 有哪些慢操作？]]\n- [[03｜高性能 IO 模型：为什么单线程 Redis 那么快？]]\n- [[04｜AOF 日志：宕机了，Redis 如何避免数据丢失？]]\n- [[05｜内存快照：宕机后，Redis 如何实现快速恢复？]]\n- [[06｜数据同步：主从库如何实现数据一致？]]\n- [[07｜哨兵机制：主库挂了，如何不间断服务？]]\n- [[08｜哨兵集群：哨兵挂了，主从库还能切换吗？]]\n- [[09｜切片集群：数据增多了，是该加内存还是加实例？]]\n\n## 实践篇\n\n- [[11｜“万金油”的 String，为什么不好用了？]]\n\n## 未来篇\n\n## 加餐篇\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Tips":{"title":"Tips","content":"\n- 想到什么点子就赶紧记下来，不然过一会就忘了，即使只是上个厕所洗个手也会忘。\n- 做一件事的时候，想象一下，最坏的情况能坏到哪呢。\n- 你花在挑选寝室用的电视机上的时间比你选择专业和学习领域的时间长。\n- 找出自己擅长和不擅长做的事。\n- 什么工作是我非做不可的。\n- 用搜索。\n","lastmodified":"2023-05-20T15:01:12.444019978Z","tags":null},"/Vault":{"title":"Vault","content":"\n\u003e 保管库是本地文件系统上的一个文件夹，Obsidian 将您的笔记存储在其中。您可以将所有笔记保存在一个保险库中，或为每个不同的项目创建多个保险库。\n\n[Create a vault - Obsidian Help](https://help.obsidian.md/Getting+started/Create+a+vault)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/iCloud-%E4%B8%8D%E5%90%8C%E6%AD%A5%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6":{"title":"iCloud 不同步指定文件","content":"\n## 说明\n\niCloud 不同步带有 .nosync 后缀的文件和文件夹\n\n## 使用场景\n\n### 在 iCloud 中忽略 .git 且 Git 命令可以正常使用\n\n```bash\ncd repo\nmv .git .git.nosync\nln -s .git.nosync .git\n```\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null},"/iCloud-%E5%90%8C%E6%AD%A5%E5%8D%A1%E4%BD%8F":{"title":"iCloud 同步卡住","content":"\n## 解决方案\n\n1. ~/.zshrc\n\n  ```bash\n  # ~/.zshrc\n  alias killicloud='killall bird \u0026\u0026 killall cloudd'\n  ```\n\n2. 终端执行命令 kill iCloud 进程\n\n  ```bash\n  killicloud\n  ```\n\n3. 点击访达侧边栏的 iCloud ，观察同步进度，若还是卡住，继续 kill iCloud 进程直到正常\n\n   - ![iCloud-sync-failed.png](https://cdn.jsdelivr.net/gh/11ze/static/images/iCloud-sync-failed.png)\n   - ![iCloud-sync-stuck.png](https://cdn.jsdelivr.net/gh/11ze/static/images/iCloud-sync-stuck.png)\n\n4. 每小时执行一次确保 iCloud 同步\n\n  ```bash\n  $ crontab -e\n  0 * * * * killall bird \u0026\u0026 killall cloudd # 每小时 kill 一次 iCloud 进程\n  ```\n\n## 参考\n\n- [一日一技 | Mac 上 iCloud 云盘同步卡住了？可以试试这样做](https://sspai.com/post/72882)\n","lastmodified":"2023-05-20T15:01:12.448019999Z","tags":null}}