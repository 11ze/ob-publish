<!DOCTYPE html>
<html><head><title>06｜数据同步：主从库如何实现数据一致？</title><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="06｜数据同步：主从库如何实现数据一致？"/><meta property="og:description" content="写操作：首先到主库执行，主库将写操作同步给从库 同步流程 主从库第一次同步的流程 增量复制流程 全量复制 第一次同步无法避免 一个实例的数据库不要太大（几 GB 级别合适） 通过 RDB 文件 二进制文件 不用 AOF 的原因 需要打开 AOF 功能 有很多场景数据不敏感不需要开启 AOF 功能 刷盘策略选择不当会严重影响 Redis 性能 比 RDB 文件大 在从库端进行恢复时，用 RDB 的恢复效率高于用 AOF 增量复制 通过命令传播的长连接复制 完成全量复制后，主库通过长连接将后续陆续收到的命令操作同步给从库，可以避免频繁建立连接的开销 网络断连时 repl_backlog_buffer 主 -&amp;gt; 从 -&amp;gt; 从 从库执行 replicaof IP PORT IP 上的实例执行 bgsave 命令生成 RDB 文件后发给从库 从库清空当前数据库 主库会在内存用专门的 replication buffer 记录 RDB 文件生成后收到的所有写操作 将 replication buffer 的修改操作发给从库 分担全量复制时的主库压力 replication buffer 和 repl_backlog_buffer 的区别 replication buffer：复制缓冲区 从库也相当于一个客户端，会单独分配一个 client buffer，这里用来传播用户的写命令到从库，通常把它叫做 replication buffer 主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区 作用：主节点向从节点发送 RDB 文件时，如果又接收写操作，会暂存在缓冲区，等 RDB 文件传输完成，且从节点加载完成后，主节点把缓冲区中的写命令发给从节点进行同步 对主从同步的影响：如果传输和加载 RDB 文件耗时长，同时主库接收的写命令操作较多，导致缓冲区写满溢出，主库会强制关闭和从库的网络连接，重新开始全量同步 通过 client-output-buffer-limit-slave 配置项增加缓冲区大小 client buffer 超过限制时，主库会强制断开这个 client 连接 此时从库再次发起复制请求，可能导致恶性循环 repl_backlog_buffer：复制积压缓冲区 是一个环形缓冲区：为了在从库断开之后能找到主从差异数据而设计 记录写操作 所有从库共享 不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步 主从断开太久，主库写操作节点越过从库在 repl_backlog_buffer 的读节点时，从库只能全量复制 repl_backlog_size = 缓冲空间大小 * 2 缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小 过小可能导致从库复制进度赶不上主库，触发全量复制 repl_backlog_buffer 的使用 主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步 父节点图2 ."/><meta property="og:image" content="https://wangze.tech/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="./static/icon.png"/><meta name="description" content="写操作：首先到主库执行，主库将写操作同步给从库 同步流程 主从库第一次同步的流程 增量复制流程 全量复制 第一次同步无法避免 一个实例的数据库不要太大（几 GB 级别合适） 通过 RDB 文件 二进制文件 不用 AOF 的原因 需要打开 AOF 功能 有很多场景数据不敏感不需要开启 AOF 功能 刷盘策略选择不当会严重影响 Redis 性能 比 RDB 文件大 在从库端进行恢复时，用 RDB 的恢复效率高于用 AOF 增量复制 通过命令传播的长连接复制 完成全量复制后，主库通过长连接将后续陆续收到的命令操作同步给从库，可以避免频繁建立连接的开销 网络断连时 repl_backlog_buffer 主 -&amp;gt; 从 -&amp;gt; 从 从库执行 replicaof IP PORT IP 上的实例执行 bgsave 命令生成 RDB 文件后发给从库 从库清空当前数据库 主库会在内存用专门的 replication buffer 记录 RDB 文件生成后收到的所有写操作 将 replication buffer 的修改操作发给从库 分担全量复制时的主库压力 replication buffer 和 repl_backlog_buffer 的区别 replication buffer：复制缓冲区 从库也相当于一个客户端，会单独分配一个 client buffer，这里用来传播用户的写命令到从库，通常把它叫做 replication buffer 主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区 作用：主节点向从节点发送 RDB 文件时，如果又接收写操作，会暂存在缓冲区，等 RDB 文件传输完成，且从节点加载完成后，主节点把缓冲区中的写命令发给从节点进行同步 对主从同步的影响：如果传输和加载 RDB 文件耗时长，同时主库接收的写命令操作较多，导致缓冲区写满溢出，主库会强制关闭和从库的网络连接，重新开始全量同步 通过 client-output-buffer-limit-slave 配置项增加缓冲区大小 client buffer 超过限制时，主库会强制断开这个 client 连接 此时从库再次发起复制请求，可能导致恶性循环 repl_backlog_buffer：复制积压缓冲区 是一个环形缓冲区：为了在从库断开之后能找到主从差异数据而设计 记录写操作 所有从库共享 不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步 主从断开太久，主库写操作节点越过从库在 repl_backlog_buffer 的读节点时，从库只能全量复制 repl_backlog_size = 缓冲空间大小 * 2 缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小 过小可能导致从库复制进度赶不上主库，触发全量复制 repl_backlog_buffer 的使用 主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步 父节点图2 ."/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="./index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="./prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch(`./static/contentIndex.json`).then(data => data.json())</script></head><body data-slug="06｜数据同步：主从库如何实现数据一致？"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title"><a href=".">🫧 11ze</a></h1><div class="spacer mobile-only"></div><div class="search"><div id="search-icon"><p>Search</p><div></div><svg tabIndex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="results-container"></div></div></div></div><div class="darkmode"><input class="toggle" id="darkmode-toggle" type="checkbox" tabIndex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xmlSpace="preserve"><title>Light mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xmlSpace="preserve"><title>Dark mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div></div><div class="center"><div class="page-header"><div class="popover-hint"><h1 class="article-title">06｜数据同步：主从库如何实现数据一致？</h1><p class="content-meta">Aug 25, 2023, 5 min read</p><ul class="tags"><li><a href="./tags/redis" class="internal tag-link">#redis</a></li></ul></div></div><article class="popover-hint"><ul>
<li>
<p>写操作：首先到主库执行，主库将写操作同步给从库</p>
</li>
<li>
<p>同步流程</p>
<ul>
<li>
<p>主从库第一次同步的流程</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-1.png" alt="image.png"/></li>
</ul>
</li>
<li>
<p>增量复制流程</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-2.png" alt="image.png"/></li>
</ul>
</li>
<li>
<ol>
<li>
<p>全量复制</p>
</li>
</ol>
<ul>
<li>
<p>第一次同步无法避免</p>
</li>
<li>
<p>一个实例的数据库不要太大（几 GB 级别合适）</p>
</li>
<li>
<p>通过 RDB 文件</p>
<ul>
<li>二进制文件</li>
</ul>
</li>
<li>
<p>不用 AOF 的原因</p>
<ul>
<li>
<p>需要打开 AOF 功能</p>
<ul>
<li>有很多场景数据不敏感不需要开启 AOF 功能</li>
<li>刷盘策略选择不当会严重影响 Redis 性能</li>
</ul>
</li>
<li>
<p>比 RDB 文件大</p>
</li>
<li>
<p>在从库端进行恢复时，用 RDB 的恢复效率高于用 AOF</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<ol start="2">
<li>
<p>增量复制</p>
</li>
</ol>
<ul>
<li>
<p>通过命令传播的长连接复制</p>
<ul>
<li>完成全量复制后，主库通过长连接将后续陆续收到的命令操作同步给从库，可以避免频繁建立连接的开销</li>
</ul>
</li>
<li>
<p>网络断连时</p>
<ul>
<li>repl_backlog_buffer</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>主 -> 从 -> 从</p>
<ul>
<li>
<p><img src="https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-3.png" alt="image.png"/></p>
</li>
<li>
<p>从库执行 replicaof IP PORT</p>
<ul>
<li>
<ol>
<li>IP 上的实例执行 bgsave 命令生成 RDB 文件后发给从库</li>
</ol>
</li>
<li>
<ol start="2">
<li>从库清空当前数据库</li>
</ol>
</li>
<li>
<ol start="3">
<li>主库会在内存用专门的 replication buffer 记录 RDB 文件生成后收到的所有写操作</li>
</ol>
</li>
<li>
<ol start="4">
<li>将 replication buffer 的修改操作发给从库</li>
</ol>
</li>
</ul>
</li>
<li>
<p>分担全量复制时的主库压力</p>
</li>
</ul>
</li>
<li>
<p>replication buffer 和 repl_backlog_buffer 的区别</p>
<ul>
<li>
<p>replication buffer：复制缓冲区</p>
<ul>
<li>
<p>从库也相当于一个客户端，会单独分配一个 client buffer，这里用来传播用户的写命令到从库，通常把它叫做 replication buffer</p>
</li>
<li>
<p>主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区</p>
</li>
<li>
<p>作用：主节点向从节点发送 RDB 文件时，如果又接收写操作，会暂存在缓冲区，等 RDB 文件传输完成，且从节点加载完成后，主节点把缓冲区中的写命令发给从节点进行同步</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-4.png" alt="image.png"/></li>
</ul>
</li>
<li>
<p>对主从同步的影响：如果传输和加载 RDB 文件耗时长，同时主库接收的写命令操作较多，导致缓冲区写满溢出，主库会强制关闭和从库的网络连接，重新开始全量同步</p>
</li>
<li>
<p>通过 client-output-buffer-limit-slave 配置项增加缓冲区大小</p>
</li>
</ul>
</li>
<li>
<p>client buffer 超过限制时，主库会强制断开这个 client 连接</p>
<ul>
<li>此时从库再次发起复制请求，可能导致恶性循环</li>
</ul>
</li>
<li>
<p>repl_backlog_buffer：复制积压缓冲区</p>
<ul>
<li>
<p>是一个环形缓冲区：为了在从库断开之后能找到主从差异数据而设计</p>
</li>
<li>
<p>记录写操作</p>
</li>
<li>
<p>所有从库共享</p>
</li>
<li>
<p>不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步</p>
</li>
<li>
<p>主从断开太久，主库写操作节点越过从库在 repl_backlog_buffer 的读节点时，从库只能全量复制</p>
</li>
<li>
<p>repl_backlog_size</p>
<ul>
<li>= 缓冲空间大小 * 2</li>
<li>缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小</li>
<li>过小可能导致从库复制进度赶不上主库，触发全量复制</li>
</ul>
</li>
<li>
<p>repl_backlog_buffer 的使用</p>
<ul>
<li>
<p><img src="https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-5.png" alt="image.png"/></p>
</li>
<li>
<p>主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-6.png" alt="image.png"/></li>
</ul>
</li>
<li>
<p>父节点图2</p>
<ul>
<li><img src="https://cdn.jsdelivr.net/gh/11ze/static/images/redis-06-7.png" alt="image.png"/></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul></article></div><div class="right sidebar"><div class="graph"><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xmlSpace="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1}"></div></div></div><div class="backlinks"><h3>Backlinks</h3><ul class="overflow"><li><a href="./Redis-核心技术与实战" class="internal">Redis 核心技术与实战</a></li></ul></div></div></div><footer><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.0.10</a>, © 2023</p><ul><li><a href="https://github.com/11ze/ob-publish">GitHub</a></li><li><a href="https://twitter.com/11ze4">Twitter</a></li></ul></footer></div></body><script type="application/javascript">// quartz/components/scripts/quartz/components/scripts/callout.inline.ts
function toggleCallout() {
  const outerBlock = this.parentElement;
  outerBlock.classList.toggle(`is-collapsed`);
  const collapsed = outerBlock.classList.contains(`is-collapsed`);
  const height = collapsed ? this.scrollHeight : outerBlock.scrollHeight;
  outerBlock.style.maxHeight = height + `px`;
  let current = outerBlock;
  let parent = outerBlock.parentElement;
  while (parent) {
    if (!parent.classList.contains(`callout`)) {
      return;
    }
    const collapsed2 = parent.classList.contains(`is-collapsed`);
    const height2 = collapsed2 ? parent.scrollHeight : parent.scrollHeight + current.scrollHeight;
    parent.style.maxHeight = height2 + `px`;
    current = parent;
    parent = parent.parentElement;
  }
}
function setupCallout() {
  const collapsible = document.getElementsByClassName(
    `callout is-collapsible`
  );
  for (const div of collapsible) {
    const title = div.firstElementChild;
    if (title) {
      title.removeEventListener(`click`, toggleCallout);
      title.addEventListener(`click`, toggleCallout);
      const collapsed = div.classList.contains(`is-collapsed`);
      const height = collapsed ? title.scrollHeight : div.scrollHeight;
      div.style.maxHeight = height + `px`;
    }
  }
}
document.addEventListener(`nav`, setupCallout);
window.addEventListener(`resize`, setupCallout);
</script><script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
          const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
          mermaid.initialize({ 
            startOnLoad: false,
            securityLevel: 'loose',
            theme: darkMode ? 'dark' : 'default'
          });
          document.addEventListener('nav', async () => {
            await mermaid.run({
              querySelector: '.mermaid'
            })
          });
          </script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script src="https://www.googletagmanager.com/gtag/js?id=G-SZZLS6FREP" type="application/javascript"></script><script src="./postscript.js" type="module"></script></html>