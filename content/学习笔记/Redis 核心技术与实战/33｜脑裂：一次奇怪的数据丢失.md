---

title: 33｜脑裂：一次奇怪的数据丢失
tags:
- Redis
- mindmap-plugin: basic
createdAt: 2023-05-24T21:12:29+08:00

---

- 脑裂：指在主从集群中，同时有两个主节点，都能接收写请求

  - 图 1
    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-33-1.png)

  - 图 2
    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/redis-33-2.png)

- 影响：客户端不知道该往哪个主节点写入数据，结果不同客户端往不同的主节点写数据，严重的会导致数据丢失
- 数据丢失排查过程

  - 1. 确认是不是数据同步出现问题

    - 主库的数据未同步到从库且发生了故障，从库升级为主库，未同步的数据丢失
    - 可以通过计算 master_repl_offset 和 slave_repl_offset 的差值做判断

  - 2. 排查客户端的操作日志，发现脑裂现象

    - 在主从切换后的一段时间内，有客户端仍然在和原主库通信，并没有和升级的新主库进行交互

- 原主库假故障导致的脑裂

  - 采用哨兵机制，如果超过预设数量的哨兵实例和主库的心跳都超时，才会把主库判断为客观下限，然后哨兵开始执行主从切换，切换完成后客户端会和新主库通信
  - 和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如 CPU 资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常
  - 主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap（复习下第 19 讲中总结的导致实例阻塞的原因），短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了

- 脑裂应对方案

  - min-slaves-to-write：设置主库能进行数据同步的最少从库数量
  - min-slaves-max-lag：设置主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）
  - 搭配两个配置项，假设为 N 和 T，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的请求

    - 只是减少数据的丢失

  - 建议：假设从库有 K 个，将 min-slaves-to-write 设置为 K/2+1（如果 K = 1，就设为 1），将 min-slaves-max-lag 设置为十几秒（如 10～20s），在这个配置下，如果有一半以上的从库和主库进行的 ACK 消息延迟超过十几秒，我们就禁止主库接收客户端写请求
