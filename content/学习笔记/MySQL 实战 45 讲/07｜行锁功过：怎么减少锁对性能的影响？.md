---

title: 07｜行锁功过：怎么减少锁对性能的影响？
tags:
- MySQL
createdAt: 2023-05-17T14:43:52+08:00

---

- MyISAM 不支持行锁

## InnoDB 的行锁

- 两阶段锁协议：事务中，行锁在需要的时候才加上，但要等到事务结束时释放。
- 如果你的事务中需要锁多个行，要把最可能造成锁冲突、影响并发度的锁尽量往后放。
- 当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。
  - 两种策略
    - 1. 直接进入等待，直到超时。
      - 超时时间可以通过 `innodb_lock_wait_timeout` 设置
      - 默认 50s。
    - 2. 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。
      - 将参数 `innodb_deadlock_detect` 设置为 on，表示开启这个逻辑。
      - 死锁：每当一个事务被锁，就要看看它所依赖的线程有没有被别的锁住，如此循环，最后判断是否出现连循环等待。
      - 假设现在已经有 999 个线程在同一行等锁，新来一个请求也要访问这个行，他要判断有没有死锁要判断 1000 次。然后这个结果乘以 1000。
    - 正常情况下采用第二种策略，默认也是第二种。
- 怎么解决热点行更新导致的性能问题？
  - 问题的症结：死锁检测要耗费大量的 CPU 资源。
  - 1. 确保业务一定不会出现死锁，关闭死锁检测（不推荐）
  - 2. 控制并发度。
    1. 在中间件或修改 MySQL 源码实现：对于相同行的更新，在进入引擎之前排队，这样 InnoDB 就不会有大量的死锁检测工作。
    2. 如果做不到第 1 点，可以考虑从设计上优化
      - 考虑通过将一行改成逻辑上的多行来减少锁冲突。
      - 以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1/10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。

## 思考题

- 如果要删除一个表里面的前 1w 行数据，选择哪一种方法（选 2）
  1. 直接执行 `delete from T limit 10000`;
    - 单个语句占用时间长，锁的时间也比较长；
    - 大事务会导致主从延迟。
  2. 在一个连接中循环执行 20 次 `delete from T limit 500`;
  3. 在 20 个连接中同时执行 `delete from T limit 500`;
    - 人为造成锁冲突。

## 评论区

- 关于思考题
  - 第二种方法难道不会引起数据一致性问题吗？如果在 InnoDB 中开启了自动事务并且没有显式用 begin, commit 来做的话，在上一次循环结束和下一次循环开始之间如果有其他事务插入了新数据，而且正好位置也在前面 500条，那不就不一致了么
    - 加个 order by id（假设 id 是表的主键）
    - 排序后新增的 id 肯定大于要删除的最大 id
- 如果有多种锁，必须全部不互斥才能并行。
- MySQL 没有嵌套事务，开启下一个会自动提交上一个
