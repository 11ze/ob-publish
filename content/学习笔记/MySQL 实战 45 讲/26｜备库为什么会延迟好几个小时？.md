---
title: 26｜备库为什么会延迟好几个小时？
tags:
  - MySQL
createdAt: 2023-05-17T21:30:23+08:00
updatedAt: 2023-08-17T14:21:58+08:00
---

- 为了解决备库一直追不上更新压力较大的主库的问题

## 多线程复制机制：将单线程 sql_thread 拆成多个线程

- ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-26-2.png)

- coordinator 就是原来的 sql_thread，但不再更新数据，只负责读取中转日志和分发事务真正更新日志的变成 worker 线程，个数由参数 slave_parallel_workers 决定一般设置 8～16 之间最好（32 核物理机的情况）需要留资源给读查询
  - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-26-1.png)

- 分发时的基本要求
  - 1. 不会造成更新覆盖。这就要求更新同一行的两个事务必须分发到同一个 worker 中
  - 2. 同一个事务不能被拆开

## MySQL 5.5 版本的并行复制策略

- 官方 5.5 版本不支持并行复制

  - 下面两个策略没有被合并

- 按表分发策略

  - 如果两个事务更新不同的表，就可以并行， 如果有跨表的事务就需要把两张表放在一起考虑
  - 按表并行复制线程模型
    - ![image.png](https://cdn.jsdelivr.net/gh/11ze/static/images/mysql45-26-3.png)

  - 每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。
  - 假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。此时事务 T 的分配规则：1. 由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。2. 按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。3. 事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。4. 每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。5. 这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。6. coordinator 继续读下一个中转日志，继续分配事务。
  - 每个事务在分发的时候，跟所有 worker 的冲突关系包括三种情况：

    - 1. 如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;
    - 2. 如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；
    - 3. 如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。

- 按行分发策略

  - 如果两个事务没有更新相同的行，它们在备库上可以并发执行
  - 需要同时考虑主键和唯一键
  - 执行 `update t1 set a=1 where id=2` 语句，在 binlog 里面记录了整行的数据修改前各个字段的值，和修改后各个字段的值。因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项
    1. `key=hash_func(db1+t1+“PRIMARY”+2), value=2`，这里 value=2 是因为修改前后的行 id 值不变，出现了两次。
    2. `key=hash_func(db1+t1+“a”+2), value=1`，表示会影响到这个表 a=2 的行。
    3. `key=hash_func(db1+t1+“a”+1), value=1`，表示会影响到这个表 a=1 的行。
  - 消耗更多的计算资源

- 两个方案有一些约束条件

  - 1. 要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；
  - 2. 表必须有主键；
  - 3. 不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。

- 按行策略遇到一个语句要删除 100 万行数据类似的情况时，hash 表要记录 100 万个项，耗内存解析 binlog 计算 hash 值，对于大事务，成本很高

  - 设置阈值，单个事务如果超过设置的行数阈值，就暂时退化为单线程模式
    1. coordinator 暂时先 hold 住这个事务；
    2. 等待所有 worker 都执行完成，变成空队列；
    3. coordinator 直接执行这个事务；
    4. 恢复并行模式。

## MySQL 5.6 版本的并行复制策略

- 按库并行
- hash 表的 key = 数据库名
- 不要求 binlog 的格式

## MariaDB 的并行复制策略

- 利用了 redo log 组提交优化（group commit）的特性
  - 1. 能够在同一组里提交的事务，一定不会修改同一行；
  - 2. 主库上可以并行执行的事务，备库上也一定是可以并行执行的。

- 实现
  - 1. 在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id + 1；
  - 2. commit_id 直接写到 binlog 里面；
  - 3. 传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；
  - 4. 这一组全部执行完成后，coordinator 再去取下一批。

- 之前的思路：分析 binlog，并拆分到 worker 上，MariaDB 的策略：模拟主库的并行模式
- 但是没有实现“真正的模拟主库并发度”目标主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的

## MySQL 5.7 的并行复制策略

- 由参数 slave-parallel-type 控制并行复制策略
  - 1. 配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；
  - 2. 配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。这个优化的思路也很有趣儿。
    - 同时处于“执行状态”的所有事务不可以并行因为可能由由于锁冲突而处于锁等待状态的事务
    - 这里的思想是：1. 同时处于 prepare 状态的事务，在备库执行时是可以并行的；2. 处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。
    - 备库如何知道事务的二阶段提交状态（依赖 redo log，备库接收到的是 binlog）
      - 主库在写 binlog 的时候会给这些 binlog 里面记 commit_id 和sequence_no，来说明事务之间在主库上并行 prepare 的状态；备库是通过解析 binlog 拿到 commit_id 和 sequence_no，来决定要怎么并发的。

- binlog 的组提交相关参数
  - 1. binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync；
  - 2. binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。
  - 用于故意拉长 binlog 从 write 到 fsync 的时间，减少 binlog 的写盘次数
  - 同时可以用来制造更多的“同时处于 prepare 阶段的事务”，增加备库复制的并行度

## MySQL 5.7.22 的并行复制策略

- MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。
- 相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。
  - 1. COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
  - 2. WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
  - 3. WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。

    - 基本用不到

- 2、3 的 hash 值 = 库名 + 表名 + 索引名 + 值，如果表上除了主键索引外，还有其他唯一索引，对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值

- 跟 MySQL 5.5 版本的按行分发策略差不多，但有优势

  - 1. writeset 是在主库生成后直接写入到 binlog 里面的，这样在备库执行的时候，不需要解析 binlog 内容（event 里的行数据），节省了很多计算量；
  - 2. 不需要把整个事务的 binlog 都扫一遍才能决定分发到哪个 worker，更省内存；
  - 3. 由于备库的分发策略不依赖于 binlog 内容，所以 binlog 是 statement 格式也是可以的。

- 对于“表上没主键”和“外键约束”的场景，WRITESET 策略也是没法并行的，也会暂时退化为单线程模型。

## ⚠️ 5.7 版本新增的备库并行策略修改了 binlog 的内容，说明 binlog 协议并不是向上兼容的，在主备切换、版本升级的时候需要考虑这个因素

## 思考题

- 假设一个 MySQL 5.7.22 版本的主库，单线程插入了很多数据，过了 3 个小时后，我们要给这个主库搭建一个相同版本的备库。
- 这时候，你为了更快地让备库追上主库，要开并行复制。在 binlog-transaction-dependency-tracking 参数的 COMMIT_ORDER、WRITESET 和 WRITE_SESSION 这三个取值中，你会选择哪一个呢？你选择的原因是什么？
  - WRITESET
- 如果设置另外两个参数，你认为会出现什么现象呢？
  - COMMIT_ORDER：由于主库是单线程压力模式，所以每个事务的 commit_id 不同
  - 由于 WRITESET_SESSION 模式要求在备库应用日志的时候，同一个线程的日志必须与主库上执行的先后顺序相同，也会导致主库单线程压力模式下退化成单线程复制。

## 评论区

- 存在主从的 binlog event 写入顺序不一致的情况
- 对同一行的修改会因为行锁而不能同时进入 commit 状态，所以 commit_id 不会相同
- 每个事务都有两个数字表示它在执行提交阶段的时间范围，构成区间 (c1, c2)。如果两个事务的区间有交集，就是可以并行的。这里 c1 是事务启动的时候，当前系统里最大的 commit_id；一个事务提交的时候，commit_id + 1.
  - 进入 prepare 的时候就给这个事务分配 commit_id，这个 commit_id 就是当前系统最大的一个 commit_id

- 作者回复: 我也建议尽量少使用外键
  1. 这个关系应该维护在开发系统的逻辑中，放在数据库里面，比较隐蔽，容易忘记
  2. 外键约束可能会导致有些更新失败
  3. 外键约束（尤其是级联更新）容易出现非预期的结果
