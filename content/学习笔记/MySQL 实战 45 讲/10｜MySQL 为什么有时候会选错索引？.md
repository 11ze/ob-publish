---

title: 10｜MySQL 为什么有时候会选错索引？
tags:
- MySQL
createdAt: 2023-05-17T15:18:30+08:00

---

## 优化器的逻辑

  - 扫描行数
    - 一个索引上不同的值越多，这个索引的区分度越好
    - 基数（cardinality）：一个索引上不同的值的个数。
      - 采样统计：InnoDB 默认选择索引的 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面树，就得到这个索引的基数。
      - 当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。
      - 两种存储索引统计的方式，通过设置参数 innodb_stats_persistent 的值选择
        - 设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。
        - 设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。
    - 从普通索引拿到一个值后，回到主键索引查出整行数据的代价也要算。
    - 由于索引统计信息不准确导致的问题，用 `analyze table` 命令来解决。
  - 是否使用临时表
  - 是否排序

## 解决其他优化器误判的情况

  - 可以在应用端用 `force index` 来强行指定索引；
  - 也可以通过修改语句来引导优化器；
    - 如，当 `xxx order by b limit 1;` 最终选择 b 索引而不是 a 索引，可能是因为判断使用 b 就可以不用再排序，此时将语句改成 `xxx order by b, a limit 1;` 是一个可考虑的解决方法
    - 前提是 SQL 语句语义不变
  - 还可以增加或者删除索引绕过问题

## 思考题

  - 前面我们在构造第一个例子的过程中，通过 session A 的配合，让 session B 删除数据后又重新插入了一遍数据，然后就发现 explain 结果中，rows 字段从 10001 变成 37000 多。而如果没有 session A 的配合，只是单独执行 `delete from t`、`call idata()`、`explain` 这三句话，会看到 rows 字段其实还是 10000 左右。你可以自己验证一下这个结果。
  - 这是什么原因呢？也请你分析一下吧。
    - session A 还没有提交，所以之前插入的 10 万行数据还不能删除。
    - 所以之前的数据每一行都有两个版本，旧版本是 delete 之前的数据，新版本是标记为 deleted 的数据。
    - 因为这个是主键，主键是直接按照表的行数来估计的，而表的行数，优化器直接用的是 show table status 的值（后面有章节详细讲解）。
