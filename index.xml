<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
    <channel>
      <title>🫧 11ze</title>
      <link>https://wangze.tech</link>
      <description>Last 10 notes on 🫧 11ze</description>
      <generator>Quartz -- quartz.jzhao.xyz</generator>
      <item>
    <title>03｜高性能 IO 模型：为什么单线程 Redis 那么快？</title>
    <link>https://wangze.tech/03%EF%BD%9C%E9%AB%98%E6%80%A7%E8%83%BD-IO-%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%95%E7%BA%BF%E7%A8%8B-Redis-%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F</link>
    <guid>https://wangze.tech/03%EF%BD%9C%E9%AB%98%E6%80%A7%E8%83%BD-IO-%E6%A8%A1%E5%9E%8B%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%8D%95%E7%BA%BF%E7%A8%8B-Redis-%E9%82%A3%E4%B9%88%E5%BF%AB%EF%BC%9F</guid>
    <description> Redis 的网络 IO 和键值对读写由一个线程完成 当客户端和 Reids 的网络连接断开时，Redis 不会等待客户端恢复连接 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，由额外的线程执行 单线程设计机制 多线程编程模式：共享资源的并发访问控制问题 在内存中完成大部分操作 + 高效的数据结构 多路复用机制（select/epoll 机制） 该机制允许内核中同时存在多个监听套接字和已连接套接字 内核监听这些套接字上的连接请求或数据请求，一旦有请求到达，就交给 Redis 处理 基于事件的回调机制 事件队列 基于多路复用的 Redis 高性能 IO 模型 .</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>04｜AOF 日志：宕机了，Redis 如何避免数据丢失？</title>
    <link>https://wangze.tech/04%EF%BD%9CAOF-%E6%97%A5%E5%BF%97%EF%BC%9A%E5%AE%95%E6%9C%BA%E4%BA%86%EF%BC%8CRedis-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%EF%BC%9F</link>
    <guid>https://wangze.tech/04%EF%BD%9CAOF-%E6%97%A5%E5%BF%97%EF%BC%9A%E5%AE%95%E6%9C%BA%E4%BA%86%EF%BC%8CRedis-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%EF%BC%9F</guid>
    <description> Redis 作为缓存使用 从数据库读取数据恢复 当需要恢复时数据库压力大、Redis 响应慢 写后日志：先执行命令把数据写入内存，再记录日志 不会阻塞当前的写操作 记录的命令没有错误 没来得及记录时，宕机会丢失数据 在主线程写，写盘压力大可能导致后续操作无法执行 日志格式示例 执行 set testkey testvalue AOF 文件（Append Only File） *3：命令有三个部分 $3：命令、键或值一共有多少字节 每个 $n 下一行跟着命令、键或值 三种写回策略 Always：同步写回 Everysec：每秒写回 优先使用，在可靠性和性能取了一个平衡 No：操作系统控制的写回 重写机制 多个操作同一个键值的命令合并为一个命令 避免重写日志过大 直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志 一个拷贝 由后台子进程 bgrewiteaof 完成，避免阻塞主线程 fork 创建 bgrewriteaof 子进程时，阻塞主线程，如果实例内存大，执行时间还会更长 共享主线程内存，主线程执行新写或修改操作时会申请新的内存空间保存新的数据，如果操作的是 bigkey，可能因为申请大空间而面临阻塞风险 两处日志 正在使用的 AOF 日志 + 新的重写日志 避免竞争文件系统的锁 减小日志大小 AOF 非阻塞重写过程 适用于读操作比较多的场景 .</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>05｜内存快照：宕机后，Redis 如何实现快速恢复？</title>
    <link>https://wangze.tech/05%EF%BD%9C%E5%86%85%E5%AD%98%E5%BF%AB%E7%85%A7%EF%BC%9A%E5%AE%95%E6%9C%BA%E5%90%8E%EF%BC%8CRedis-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D%EF%BC%9F</link>
    <guid>https://wangze.tech/05%EF%BD%9C%E5%86%85%E5%AD%98%E5%BF%AB%E7%85%A7%EF%BC%9A%E5%AE%95%E6%9C%BA%E5%90%8E%EF%BC%8CRedis-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D%EF%BC%9F</guid>
    <description> 和 AOF 相比，RDB 记录某一时刻的数据，恢复时直接把 RDB 文件读入内存 全量快照 生成 RDB 文件的方案 save：在主线程中执行，会导致阻塞 （默认）bgsave：创建一个子进程，复制主线程的页表，专门写入 RDB 文件，避免阻塞。 共享主线程的所有内存数据 快照时数据能修改吗？ 读操作：bgsave 子进程和主线程互不影响 能 写操作：生成被修改的一块数据的副本，bgsave 子进程继续写 RDB 文件，主线程在副本上进行修改 写时复制：主线程在有写操作时，才会把这个新写或修改后的数据写入到一个新的物理地址中，并修改自己的页表映射 可以每秒做一次快照吗？ 磁盘压力 fork bgsave 子进程的过程会阻塞主线程 混合使用 AOF 和内存快照 AOF 只保留从最后一次快照开始的改动 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择 如果允许分钟级别的数据丢失，可以只使用 RDB 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡 持久化有关的风险 服务器内存不足 写时复制为写、修改操作涉及的数据分配相同大小的内存副本 子进程也会占用 CPU 资源 需要开启定时 RDB 和 AOF 重写时进程一定不要绑定 CPU：子进程会与父进程争夺同一个 CPU 资源（具体搜索关键字找到后面有关绑定 CPU 的章节） .</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>06｜数据同步：主从库如何实现数据一致？</title>
    <link>https://wangze.tech/06%EF%BD%9C%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%EF%BC%9F</link>
    <guid>https://wangze.tech/06%EF%BD%9C%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%EF%BC%9A%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%EF%BC%9F</guid>
    <description> 写操作：首先到主库执行，主库将写操作同步给从库 同步流程 主从库第一次同步的流程 增量复制流程 全量复制 第一次同步无法避免 一个实例的数据库不要太大（几 GB 级别合适） 通过 RDB 文件 二进制文件 不用 AOF 的原因 需要打开 AOF 功能 有很多场景数据不敏感不需要开启 AOF 功能 刷盘策略选择不当会严重影响 Redis 性能 比 RDB 文件大 在从库端进行恢复时，用 RDB 的恢复效率高于用 AOF 增量复制 通过命令传播的长连接复制 完成全量复制后，主库通过长连接将后续陆续收到的命令操作同步给从库，可以避免频繁建立连接的开销 网络断连时 repl_backlog_buffer 主 → 从 → 从 从库执行 replicaof IP PORT IP 上的实例执行 bgsave 命令生成 RDB 文件后发给从库 从库清空当前数据库 主库会在内存用专门的 replication buffer 记录 RDB 文件生成后收到的所有写操作 将 replication buffer 的修改操作发给从库 从 → 从：分担全量复制时的主库压力 replication buffer 和 repl_backlog_buffer 的区别 replication buffer：复制缓冲区 从库也相当于一个客户端，会单独分配一个 client buffer，这里用来传播用户的写命令到从库，通常把它叫做 replication buffer 主节点开始和一个从节点进行全量同步时，会为从节点创建一个输出缓冲区，这个缓冲区就是复制缓冲区 作用：主节点向从节点发送 RDB 文件时，如果又接收写操作，会暂存在缓冲区，等 RDB 文件传输完成，且从节点加载完成后，主节点把缓冲区中的写命令发给从节点进行同步 对主从同步的影响：如果传输和加载 RDB 文件耗时长，同时主库接收的写命令操作较多，导致缓冲区写满溢出，主库会强制关闭和从库的网络连接，重新开始全量同步 通过 client-output-buffer-limit-slave 配置项增加缓冲区大小 client buffer 超过限制时，主库会强制断开这个 client 连接 此时从库再次发起复制请求，可能导致恶性循环 repl_backlog_buffer：复制积压缓冲区 是一个环形缓冲区：为了在从库断开之后能找到主从差异数据而设计 记录写操作 所有从库共享 不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步 主从断开太久，主库写操作节点越过从库在 repl_backlog_buffer 的读节点时，从库只能全量复制 repl_backlog_size = 缓冲空间大小 * 2 缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小 过小可能导致从库复制进度赶不上主库，触发全量复制 repl_backlog_buffer 的使用 主节点在把接收到的写命令同步给从节点时，同时会把这些写命令写入复制积压缓冲区。一旦从节点发生网络闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区中，读取断连期间主节点接收到的写命令，进而进行增量同步 父节点图2 .</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>07｜哨兵机制：主库挂了，如何不间断服务？</title>
    <link>https://wangze.tech/07%EF%BD%9C%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%EF%BC%9A%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%EF%BC%8C%E5%A6%82%E4%BD%95%E4%B8%8D%E9%97%B4%E6%96%AD%E6%9C%8D%E5%8A%A1%EF%BC%9F</link>
    <guid>https://wangze.tech/07%EF%BD%9C%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%EF%BC%9A%E4%B8%BB%E5%BA%93%E6%8C%82%E4%BA%86%EF%BC%8C%E5%A6%82%E4%BD%95%E4%B8%8D%E9%97%B4%E6%96%AD%E6%9C%8D%E5%8A%A1%EF%BC%9F</guid>
    <description> 哨兵机制的基本流程 监控：判断主从库下线 主观下线 哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。 如果哨兵发现主库或从库对 PING 命令的响应超时了，哨兵就会先把它标记为“主观下线”。 从库会被直接标记为“主观下线”。 客观下线 大多数的哨兵判断主库主观下线，主库才会标记为客观下线 减少误判 哨兵集群：哨兵机制通常采用多实例组成的集群模式部署 选主：选出新主库（筛选 + 打分） 按照一定的筛选条件去掉不符合条件的从库 在线状态 网络状态 配置项（ms）down-after-milliseconds * 10 如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了 如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好 此参数可以调节哨兵的敏感程度 按照一定的规则给剩下的从库逐个打分 从库优先级 通过 slave-priority 配置项设置 从库复制进度 和旧主库同步程度最接近的从库得分高 salve_repl_offset 最大 从库 ID 号 在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。 得分最高的作为新主库 选择新主库的过程 通知 让从库执行 replicaof 与新主库同步 4.</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>08｜哨兵集群：哨兵挂了，主从库还能切换吗？</title>
    <link>https://wangze.tech/08%EF%BD%9C%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%EF%BC%9A%E5%93%A8%E5%85%B5%E6%8C%82%E4%BA%86%EF%BC%8C%E4%B8%BB%E4%BB%8E%E5%BA%93%E8%BF%98%E8%83%BD%E5%88%87%E6%8D%A2%E5%90%97%EF%BC%9F</link>
    <guid>https://wangze.tech/08%EF%BD%9C%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%EF%BC%9A%E5%93%A8%E5%85%B5%E6%8C%82%E4%BA%86%EF%BC%8C%E4%B8%BB%E4%BB%8E%E5%BA%93%E8%BF%98%E8%83%BD%E5%88%87%E6%8D%A2%E5%90%97%EF%BC%9F</guid>
    <description> 本质上哨兵就是一个运行在特定模式下的 Redis 实例。 基于 pub/sub 机制的哨兵集群组成过程（发布/订阅机制） 只有订阅了同一个频道的应用才能通过发布的消息进行信息交换 哨兵通过 __sentinel__:hello 频道互相发现、通信 给主库发送 INFO 命令拿到从库列表，哨兵根据列表上的连接信息和从库建立连接并监控 基于哨兵自身的 pub/sub 功能，实现客户端和哨兵之间的事件通知 重要的频道汇总图 订阅例子：客户端执行 SUBSCRIBE * 订阅所有事件 由哪一个哨兵执行主从切换？ 和主库客观下线的判断过程类似，投票仲裁 标记主库“主观下线” 向其他哨兵实例要赞成票 获得仲裁所需的赞成票后，就可以标记主库为“客观下线”。 成功标记主库为客观下线的哨兵实例向其他哨兵发送命令，表明希望执行主从切换 投票（Y/N），确定 Leader 拿到半数以上赞成票 拿到的票数大于等于哨兵配置文件中的 quorum 值 每个哨兵只能投一个赞成票，可以给自己投，第一次必投 Y 所有哨兵同时判断主库主观下线，然后同时得到客观下线的结论时，每个哨兵各自一票（概率极低） 要保证所有哨兵实例的配置是一致的，尤其是主观下线的判断值 down-after-milliseconds 思考题 配置了包含 5 个哨兵实例的集群，quorum 值设为 2。在运行过程中，如果有 3 个哨兵实例都发生故障，此时，Redis 主库如果有故障，还能正确地判断主库“客观下线”吗？ 能，两个哨兵都给出主观下线的结果，达到了 quorum 的值 如果可以的话，还能进行主从库自动切换吗？ 不能主从切换，选举 Leader 拿不到超过半数的选票（5/2 + 1 = 3） 哨兵实例是不是越多越好呢？ 不是。通信次数增多，故障风险变大，选举时间变长 调大 down-after-milliseconds 值，对减少误判有没有好处？ 有好处，降低误判的概率，但主从切换时间变长，对业务影响时间变久 .</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>09｜切片集群：数据增多了，是该加内存还是加实例？</title>
    <link>https://wangze.tech/09%EF%BD%9C%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%A4%9A%E4%BA%86%EF%BC%8C%E6%98%AF%E8%AF%A5%E5%8A%A0%E5%86%85%E5%AD%98%E8%BF%98%E6%98%AF%E5%8A%A0%E5%AE%9E%E4%BE%8B%EF%BC%9F</link>
    <guid>https://wangze.tech/09%EF%BD%9C%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%EF%BC%9A%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%A4%9A%E4%BA%86%EF%BC%8C%E6%98%AF%E8%AF%A5%E5%8A%A0%E5%86%85%E5%AD%98%E8%BF%98%E6%98%AF%E5%8A%A0%E5%AE%9E%E4%BE%8B%EF%BC%9F</guid>
    <description>纵向扩展 升级单个 Redis 实例的资源配置，包括增加内存容量、增加磁盘容量、使用更高配置的 CPU 实施起来简单、直接 当使用 RDB 对数据进行持久化时，如果数据量增加，需要的内存也会增加，主线程 fork 子进程时就可能会阻塞（耗时长） 不要求持久化保存 Redis 数据时是一个不错的选择 受到硬件和成本的限制 横向扩展 增加当前 Redis 实例的个数 扩展性更好 数据切片后，在多个实例之间如何分布？ 客户端怎么确定想要访问的数据在哪个实例上？ 切片集群 是一种保存大量数据的通用机制，可以有不同的实现方案 Redis Cluster（官方） 采用哈希槽（Hash Slot）处理数据与实例之间的映射关系 共有 16384 个哈希槽，个数在客户端和服务端写死 根据键值对的 key，按照 CRC16 算法 计算一个 16 bit 的值 用值对 16384 取模，得到 0～16383 范围内的模数（哈希槽编号） 数据映射关系：键的哈希值 ⇒ 哈希槽 ⇒ 不同的实例 部署 手动或自动将所有槽分配完后，集群才能正常工作 cluster create 命令创建集群，自动将槽平均分布在实例上 cluster meet 手动建立实例间的连接形成集群，再使用 cluster addslots 制定每个实例上的哈希槽个数 客户端如何定位数据？ Redis 实例会把自己的哈希槽信息发给和它相连接的其他实例，实例相互连接后每个实例都有所有哈希槽的映射关系 客户端将哈希槽信息缓存在本地 先计算键对应的哈希槽 然后给相应的哈希槽发送请求 运维人员手动触发进行负载均衡和数据迁移 常见的变化 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍 重定向机制 当客户端把一个键值对的操作请求发给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，这个实例就会给客户端返回 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址 响应结果示例：GET hello:key｜(error) MOVED 13320 172.</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>11｜“万金油”的 String，为什么不好用了？</title>
    <link>https://wangze.tech/11%EF%BD%9C%E2%80%9C%E4%B8%87%E9%87%91%E6%B2%B9%E2%80%9D%E7%9A%84-String%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%A5%BD%E7%94%A8%E4%BA%86%EF%BC%9F</link>
    <guid>https://wangze.tech/11%EF%BD%9C%E2%80%9C%E4%B8%87%E9%87%91%E6%B2%B9%E2%80%9D%E7%9A%84-String%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%A5%BD%E7%94%A8%E4%BA%86%EF%BC%9F</guid>
    <description> Redis 容量预估工具 String 类型 元数据：内存空间记录数据长度、空间使用等信息 int 编码方式：当保存 64 位有符号整数时，会保存为 8 字节的 Long 类型整数 简单动态字符串（Simple Dynamic String，SDS）结构体的组成 buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销 len：占 4 个字节，表示 buf 的已用长度 alloc：也占 4 个字节，表示 buf 的实际分配长度，一般大于 len RedisObject 结构体 包含了 8 字节的元数据和一个 8 字节指针 指针指向实际数据，如 SDS int 编码：当保存 Long 类型整数时，指针直接赋值为整数数据 embstr 编码：保存 ⇐ 44 字节的字符串数据，元数据、指针和 SDS 是一块连续的内存区域 raw 编码：保存 &gt; 44 字节的字符串数据，给 SDS 分配独立的空间 哈希表的每一项是一个 dictEntry 的结构体，指向一个键值对 有三个 8 字节的指针 分别指向 key、value和下一个 dictEntry Redis 使用的内存分配库 jemalloc 根据申请的字节数 N，找一个比 N 大的最接近 N 的 2 的幂次数作为分配的空间 减少频繁分配的次数 压缩列表 ziplist 示例：用集合类型保存单值的键值对 图片 ID 1101000060 对象 ID 3302000080 二级编码：hset 1101000 060 3302000080 查找时会遍历压缩列表 Sorted Set 也可以达到类似的效果，不过插入时性能没 Hash 高 需排序，而 Hash 直接插入尾部 Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据 hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数 hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度 数据一旦用了哈希表保存就不会自动转回成压缩列表 选用 Hash 和 Sorted Set 存储时，节省空间，但设置过期会变得困难 选用 String 存储时，可以单独设置每个 key 的过期时间，还可以设置 maxmemory 和淘汰策略，以这种方式控制整个实例的内存上限 .</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>12｜有一亿个 keys 要统计，应该用哪种集合？</title>
    <link>https://wangze.tech/12%EF%BD%9C%E6%9C%89%E4%B8%80%E4%BA%BF%E4%B8%AA-keys-%E8%A6%81%E7%BB%9F%E8%AE%A1%EF%BC%8C%E5%BA%94%E8%AF%A5%E7%94%A8%E5%93%AA%E7%A7%8D%E9%9B%86%E5%90%88%EF%BC%9F</link>
    <guid>https://wangze.tech/12%EF%BD%9C%E6%9C%89%E4%B8%80%E4%BA%BF%E4%B8%AA-keys-%E8%A6%81%E7%BB%9F%E8%AE%A1%EF%BC%8C%E5%BA%94%E8%AF%A5%E7%94%A8%E5%93%AA%E7%A7%8D%E9%9B%86%E5%90%88%EF%BC%9F</guid>
    <description>数据类型汇总表格 聚合统计 统计多个集合元素的聚合结果，包括： 统计多个集合的共有元素（交集统计） 把两个集合相比，统计其中一个集合独有的元素（差集统计） 统计多个集合的所有元素（并集统计） 使用 Set 并集：SUNIONSTORE user:new user:id user:id:20200803 差集：SDIFFSTORE user:new user:id:20200804 user:id 交集：SINTERSTORE user:id:rem user:id:20200803 user:id:20200804 计算复杂度较高，数据量较大时会导致 Redis 实例阻塞 三个命令都会生成新 key，但从库一般是 readonly（不建议开写），想在从库操作需使用 SUNION、SDIFF、SINTER，这些命令可以计算出结果，但不会生成新 key 可以从主从集群中选择一个从库专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计，这样就可以规避阻塞主库实例和其他从库实例的风险了 排序统计 使用有序集合：List、Sorted Set List 是按照元素进入 List 的顺序进行排序，而 Sorted Set 可以根据元素的权重来排序 数据更新频繁或需要分页显示，优先考虑使用 Sorted Set 二值状态统计 指集合元素的取值就只有 0 和 1 两种 Bitmap 对多个以日期为 key，位值为每个学生签到情况的 Bitmap，执行按位与操作可以统计出连续签到的学生数量 亦或者 uid:sign:3000:202008 2 1 可以统计学生在某段时间的签到情况 优势：节省内存空间 基数统计 指统计一个集合中不重复的元素个数，如统计网页的 UV Set 和 Hash 消耗比较多的内存空间 HyperLogLog 用于统计基数的数据类型 会用就行 标准误算率：0.</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item><item>
    <title>13｜GEO 是什么？还可以定义新的数据类型吗？</title>
    <link>https://wangze.tech/13%EF%BD%9CGEO-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E8%BF%98%E5%8F%AF%E4%BB%A5%E5%AE%9A%E4%B9%89%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%90%97%EF%BC%9F</link>
    <guid>https://wangze.tech/13%EF%BD%9CGEO-%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E8%BF%98%E5%8F%AF%E4%BB%A5%E5%AE%9A%E4%B9%89%E6%96%B0%E7%9A%84%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%90%97%EF%BC%9F</guid>
    <description> LBS：位置信息服务（Location-Based Service） GEO：数据类型 底层数据结构：Sorted Set GeoHash 编码方法 基本原理：二分区间，区间编码 对经纬度分别编码，再组合 经度范围 [-180, 180]，纬度范围 [-90, 90] 做 N 次二分区操作，N 可以自定义 根据经纬度值落在左还是右分区得到 1 位编码值 重复 N 次，得到一个 N bit 的数 例：116.</description>
    <pubDate>Mon, 12 Feb 2024 14:31:00 GMT</pubDate>
  </item>
    </channel>
  </rss>